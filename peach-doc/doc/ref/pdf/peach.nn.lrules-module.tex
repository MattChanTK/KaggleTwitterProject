%
% API Documentation for Peach - Computational Intelligence for Python
% Module peach.nn.lrules
%
% Generated by epydoc 3.0.1
% [Sun Jul 31 17:00:40 2011]
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                          Module Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}|(}
\section{Module peach.nn.lrules}

    \label{peach:nn:lrules}

Learning rules for neural networks and base classes for custom learning.

This sub-package implements learning methods commonly used with neural networks.
There are a lot of different topologies and different learning methods for each
one. It is very difficult to find a consistent framework for defining learning
methods, in consequence. This method defines some base classes that are coupled
with the neural networks that they are supposed to work with. Also, based on
these classes, some of the traditional methods are implemented.

If you want to implement a different learning method, you must subclass the
correct base class. Consult the classes below. Also, pay attention to how the
implementation is expected to behave. Since learning algorithms are usually
somewhat complex, care should be taken to make everything work accordingly.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               Variables                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsection{Variables}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright \_\-\_\-d\-o\-c\-\_\-\_\- & \raggedright \textbf{Value:} 
{\tt \texttt{...}}&\\
\cline{1-2}
\raggedright \_\-\_\-p\-a\-c\-k\-a\-g\-e\-\_\-\_\- & \raggedright \textbf{Value:} 
{\tt \texttt{'}\texttt{peach.nn}\texttt{'}}&\\
\cline{1-2}
\end{longtable}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.FFLearning \textit{(class)}|(}
\subsection{Class FFLearning}

    \label{peach:nn:lrules:FFLearning}
\begin{tabular}{cccccc}
% Line for object, linespec=[False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
  \\
&&\multicolumn{2}{l}{\textbf{peach.nn.lrules.FFLearning}}
\end{tabular}

\textbf{Known Subclasses:}
peach.nn.lrules.BackPropagation,
    peach.nn.lrules.LMS


Base class for FeedForwarding Multilayer neural networks.

As a base class, this class doesn't do anything. You should subclass this
class if you want to implement a learning method for multilayer networks.

A learning method for a neural net of this kind must deal with a
\texttt{FeedForward} instance. A \texttt{FeedForward} object is a list of \texttt{Layers}
(consulting the documentation of these classes is important!). Each layer is
a bidimensional array, where each line represents the synaptic weights of a
single neuron. So, a multilayer network is actually a three-dimensional
array, if you will. Usually, though, learning methods for this kind of net
propagate some measure of the error from the output back to the input (the
\texttt{BackPropagation} method, for instance).

A class implementing a learning method should have at least two methods:
%
\begin{quote}
%
\begin{description}
\item[{\_\_init\_\_}] \leavevmode 
The \texttt{\_\_init\_\_} method should initialize the object. It is in general
used to configure some property of the learning algorithm, such as the
learning rate.

\item[{\_\_call\_\_}] \leavevmode 
The \texttt{\_\_call\_\_} interface is how the method should interact with the
neural network. It should have the following signature:
%
\begin{quote}{\ttfamily \raggedright \noindent
\_\_call\_\_(self,~nn,~x,~d)
}
\end{quote}

where \texttt{nn} is the \texttt{FeedForward} instance to be modified \emph{in loco},
\texttt{x} is the input vector and \texttt{d} is the desired response of the net
for that particular input vector. It should return nothing.

\end{description}

\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \label{peach:nn:lrules:FFLearning:__call__}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.FFLearning \textit{(class)}!peach.nn.lrules.FFLearning.\_\_call\_\_ \textit{(method)}}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self}, \textit{nn}, \textit{x}, \textit{d})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

The \texttt{\_\_call\_\_} interface.

Read the documentation for this class for more information. A call to
the class should have the following parameters:
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xx}

          \item[nn]


A \texttt{FeedForward} neural network instance that is going to be
modified by the learning algorithm. The modification is made \emph{in
loco}, that is, the synaptic weights of \texttt{nn} should be modified
in place, and not returned from this function.
          \item[x]


The input vector from the training set.
          \item[d]


The desired response for the given input vector.
        \end{Ventry}

      \end{quote}

    \end{boxedminipage}


\large{\textbf{\textit{Inherited from object}}}

\begin{quote}
\_\_delattr\_\_(), \_\_format\_\_(), \_\_getattribute\_\_(), \_\_hash\_\_(), \_\_init\_\_(), \_\_new\_\_(), \_\_reduce\_\_(), \_\_reduce\_ex\_\_(), \_\_repr\_\_(), \_\_setattr\_\_(), \_\_sizeof\_\_(), \_\_str\_\_(), \_\_subclasshook\_\_()
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\multicolumn{2}{|l|}{\textit{Inherited from object}}\\
\multicolumn{2}{|p{\varwidth}|}{\raggedright \_\_class\_\_}\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.FFLearning \textit{(class)}|)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.LMS \textit{(class)}|(}
\subsection{Class LMS}

    \label{peach:nn:lrules:LMS}
\begin{tabular}{cccccccc}
% Line for object, linespec=[False, False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
&&
  \\
% Line for peach.nn.lrules.FFLearning, linespec=[False]
\multicolumn{4}{r}{\settowidth{\BCL}{peach.nn.lrules.FFLearning}\multirow{2}{\BCL}{peach.nn.lrules.FFLearning}}
&&
  \\\cline{5-5}
  &&&&\multicolumn{1}{c|}{}
&&
  \\
&&&&\multicolumn{2}{l}{\textbf{peach.nn.lrules.LMS}}
\end{tabular}


The Least-Mean-Square (LMS) learning method.

The LMS method is a very simple method of learning, thoroughly described in
virtually every book about the subject. Please, consult a good book on
neural networks for more information. This implementation tries to use the
\texttt{numpy} routines as much as possible for better efficiency.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_init\_\_}(\textit{self}, \textit{lrate}={\tt 0.05})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Initializes the object.
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xxxxx}

          \item[lrate]


Learning rate to be used in the algorithm. Defaults to 0.05.
        \end{Ventry}

      \end{quote}

      Overrides: object.\_\_init\_\_

    \end{boxedminipage}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self}, \textit{nn}, \textit{x}, \textit{d})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

The \texttt{\_\_call\_\_} interface.

The learning implementation. Read the documentation for the base class
for more information. A call to the class should have the following
parameters:
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xx}

          \item[nn]


A \texttt{FeedForward} neural network instance that is going to be
modified by the learning algorithm. The modification is made \emph{in
loco}, that is, the synaptic weights of \texttt{nn} should be modified
in place, and not returned from this function.
          \item[x]


The input vector from the training set.
          \item[d]


The desired response for the given input vector.
        \end{Ventry}

      \end{quote}

      Overrides: peach.nn.lrules.FFLearning.\_\_call\_\_

    \end{boxedminipage}


\large{\textbf{\textit{Inherited from object}}}

\begin{quote}
\_\_delattr\_\_(), \_\_format\_\_(), \_\_getattribute\_\_(), \_\_hash\_\_(), \_\_new\_\_(), \_\_reduce\_\_(), \_\_reduce\_ex\_\_(), \_\_repr\_\_(), \_\_setattr\_\_(), \_\_sizeof\_\_(), \_\_str\_\_(), \_\_subclasshook\_\_()
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\multicolumn{2}{|l|}{\textit{Inherited from object}}\\
\multicolumn{2}{|p{\varwidth}|}{\raggedright \_\_class\_\_}\\
\cline{1-2}
\end{longtable}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                          Instance Variables                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Instance Variables}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright l\-r\-a\-t\-e\- & Learning rate used in the algorithm.&\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.LMS \textit{(class)}|)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.LMS \textit{(class)}|(}
\subsection{Class LMS}

    \label{peach:nn:lrules:LMS}
\begin{tabular}{cccccccc}
% Line for object, linespec=[False, False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
&&
  \\
% Line for peach.nn.lrules.FFLearning, linespec=[False]
\multicolumn{4}{r}{\settowidth{\BCL}{peach.nn.lrules.FFLearning}\multirow{2}{\BCL}{peach.nn.lrules.FFLearning}}
&&
  \\\cline{5-5}
  &&&&\multicolumn{1}{c|}{}
&&
  \\
&&&&\multicolumn{2}{l}{\textbf{peach.nn.lrules.LMS}}
\end{tabular}


The Least-Mean-Square (LMS) learning method.

The LMS method is a very simple method of learning, thoroughly described in
virtually every book about the subject. Please, consult a good book on
neural networks for more information. This implementation tries to use the
\texttt{numpy} routines as much as possible for better efficiency.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_init\_\_}(\textit{self}, \textit{lrate}={\tt 0.05})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Initializes the object.
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xxxxx}

          \item[lrate]


Learning rate to be used in the algorithm. Defaults to 0.05.
        \end{Ventry}

      \end{quote}

      Overrides: object.\_\_init\_\_

    \end{boxedminipage}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self}, \textit{nn}, \textit{x}, \textit{d})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

The \texttt{\_\_call\_\_} interface.

The learning implementation. Read the documentation for the base class
for more information. A call to the class should have the following
parameters:
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xx}

          \item[nn]


A \texttt{FeedForward} neural network instance that is going to be
modified by the learning algorithm. The modification is made \emph{in
loco}, that is, the synaptic weights of \texttt{nn} should be modified
in place, and not returned from this function.
          \item[x]


The input vector from the training set.
          \item[d]


The desired response for the given input vector.
        \end{Ventry}

      \end{quote}

      Overrides: peach.nn.lrules.FFLearning.\_\_call\_\_

    \end{boxedminipage}


\large{\textbf{\textit{Inherited from object}}}

\begin{quote}
\_\_delattr\_\_(), \_\_format\_\_(), \_\_getattribute\_\_(), \_\_hash\_\_(), \_\_new\_\_(), \_\_reduce\_\_(), \_\_reduce\_ex\_\_(), \_\_repr\_\_(), \_\_setattr\_\_(), \_\_sizeof\_\_(), \_\_str\_\_(), \_\_subclasshook\_\_()
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\multicolumn{2}{|l|}{\textit{Inherited from object}}\\
\multicolumn{2}{|p{\varwidth}|}{\raggedright \_\_class\_\_}\\
\cline{1-2}
\end{longtable}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                          Instance Variables                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Instance Variables}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright l\-r\-a\-t\-e\- & Learning rate used in the algorithm.&\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.LMS \textit{(class)}|)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.LMS \textit{(class)}|(}
\subsection{Class LMS}

    \label{peach:nn:lrules:LMS}
\begin{tabular}{cccccccc}
% Line for object, linespec=[False, False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
&&
  \\
% Line for peach.nn.lrules.FFLearning, linespec=[False]
\multicolumn{4}{r}{\settowidth{\BCL}{peach.nn.lrules.FFLearning}\multirow{2}{\BCL}{peach.nn.lrules.FFLearning}}
&&
  \\\cline{5-5}
  &&&&\multicolumn{1}{c|}{}
&&
  \\
&&&&\multicolumn{2}{l}{\textbf{peach.nn.lrules.LMS}}
\end{tabular}


The Least-Mean-Square (LMS) learning method.

The LMS method is a very simple method of learning, thoroughly described in
virtually every book about the subject. Please, consult a good book on
neural networks for more information. This implementation tries to use the
\texttt{numpy} routines as much as possible for better efficiency.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_init\_\_}(\textit{self}, \textit{lrate}={\tt 0.05})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Initializes the object.
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xxxxx}

          \item[lrate]


Learning rate to be used in the algorithm. Defaults to 0.05.
        \end{Ventry}

      \end{quote}

      Overrides: object.\_\_init\_\_

    \end{boxedminipage}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self}, \textit{nn}, \textit{x}, \textit{d})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

The \texttt{\_\_call\_\_} interface.

The learning implementation. Read the documentation for the base class
for more information. A call to the class should have the following
parameters:
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xx}

          \item[nn]


A \texttt{FeedForward} neural network instance that is going to be
modified by the learning algorithm. The modification is made \emph{in
loco}, that is, the synaptic weights of \texttt{nn} should be modified
in place, and not returned from this function.
          \item[x]


The input vector from the training set.
          \item[d]


The desired response for the given input vector.
        \end{Ventry}

      \end{quote}

      Overrides: peach.nn.lrules.FFLearning.\_\_call\_\_

    \end{boxedminipage}


\large{\textbf{\textit{Inherited from object}}}

\begin{quote}
\_\_delattr\_\_(), \_\_format\_\_(), \_\_getattribute\_\_(), \_\_hash\_\_(), \_\_new\_\_(), \_\_reduce\_\_(), \_\_reduce\_ex\_\_(), \_\_repr\_\_(), \_\_setattr\_\_(), \_\_sizeof\_\_(), \_\_str\_\_(), \_\_subclasshook\_\_()
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\multicolumn{2}{|l|}{\textit{Inherited from object}}\\
\multicolumn{2}{|p{\varwidth}|}{\raggedright \_\_class\_\_}\\
\cline{1-2}
\end{longtable}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                          Instance Variables                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Instance Variables}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright l\-r\-a\-t\-e\- & Learning rate used in the algorithm.&\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.LMS \textit{(class)}|)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.BackPropagation \textit{(class)}|(}
\subsection{Class BackPropagation}

    \label{peach:nn:lrules:BackPropagation}
\begin{tabular}{cccccccc}
% Line for object, linespec=[False, False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
&&
  \\
% Line for peach.nn.lrules.FFLearning, linespec=[False]
\multicolumn{4}{r}{\settowidth{\BCL}{peach.nn.lrules.FFLearning}\multirow{2}{\BCL}{peach.nn.lrules.FFLearning}}
&&
  \\\cline{5-5}
  &&&&\multicolumn{1}{c|}{}
&&
  \\
&&&&\multicolumn{2}{l}{\textbf{peach.nn.lrules.BackPropagation}}
\end{tabular}


The BackPropagation learning method.

The backpropagation method is a very simple method of learning, thoroughly
described in virtually every book about the subject. Please, consult a good
book on neural networks for more information. This implementation tries to
use the \texttt{numpy} routines as much as possible for better efficiency.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_init\_\_}(\textit{self}, \textit{lrate}={\tt 0.05})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Initializes the object.
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xxxxx}

          \item[lrate]


Learning rate to be used in the algorithm. Defaults to 0.05.
        \end{Ventry}

      \end{quote}

      Overrides: object.\_\_init\_\_

    \end{boxedminipage}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self}, \textit{nn}, \textit{x}, \textit{d})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

The \texttt{\_\_call\_\_} interface.

The learning implementation. Read the documentation for the base class
for more information. A call to the class should have the following
parameters:
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xx}

          \item[nn]


A \texttt{FeedForward} neural network instance that is going to be
modified by the learning algorithm. The modification is made \emph{in
loco}, that is, the synaptic weights of \texttt{nn} should be modified
in place, and not returned from this function.
          \item[x]


The input vector from the training set.
          \item[d]


The desired response for the given input vector.
        \end{Ventry}

      \end{quote}

      Overrides: peach.nn.lrules.FFLearning.\_\_call\_\_

    \end{boxedminipage}


\large{\textbf{\textit{Inherited from object}}}

\begin{quote}
\_\_delattr\_\_(), \_\_format\_\_(), \_\_getattribute\_\_(), \_\_hash\_\_(), \_\_new\_\_(), \_\_reduce\_\_(), \_\_reduce\_ex\_\_(), \_\_repr\_\_(), \_\_setattr\_\_(), \_\_sizeof\_\_(), \_\_str\_\_(), \_\_subclasshook\_\_()
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\multicolumn{2}{|l|}{\textit{Inherited from object}}\\
\multicolumn{2}{|p{\varwidth}|}{\raggedright \_\_class\_\_}\\
\cline{1-2}
\end{longtable}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                          Instance Variables                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Instance Variables}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright l\-r\-a\-t\-e\- & Learning rate used in the algorithm.&\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.BackPropagation \textit{(class)}|)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.SOMLearning \textit{(class)}|(}
\subsection{Class SOMLearning}

    \label{peach:nn:lrules:SOMLearning}
\begin{tabular}{cccccc}
% Line for object, linespec=[False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
  \\
&&\multicolumn{2}{l}{\textbf{peach.nn.lrules.SOMLearning}}
\end{tabular}

\textbf{Known Subclasses:}
peach.nn.lrules.Competitive,
    peach.nn.lrules.Cooperative,
    peach.nn.lrules.WinnerTakesAll


Base class for Self-Organizing Maps.

As a base class, this class doesn't do anything. You should subclass this
class if you want to implement a learning method for self-organizing maps.

A learning method for a neural net of this kind must deal with a \texttt{SOM}
instance. A \texttt{SOM} object is a \texttt{Layer} (consulting the documentation of
these classes is important!).

A class implementing a learning method should have at least two methods:
%
\begin{quote}
%
\begin{description}
\item[{\_\_init\_\_}] \leavevmode 
The \texttt{\_\_init\_\_} method should initialize the object. It is in general
used to configure some property of the learning algorithm, such as the
learning rate.

\item[{\_\_call\_\_}] \leavevmode 
The \texttt{\_\_call\_\_} interface is how the method should interact with the
neural network. It should have the following signature:
%
\begin{quote}{\ttfamily \raggedright \noindent
\_\_call\_\_(self,~nn,~x)
}
\end{quote}

where \texttt{nn} is the \texttt{SOM} instance to be modified \emph{in loco}, and \texttt{x}
is the input vector. It should return nothing.

\end{description}

\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \label{peach:nn:lrules:SOMLearning:__call__}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.SOMLearning \textit{(class)}!peach.nn.lrules.SOMLearning.\_\_call\_\_ \textit{(method)}}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self}, \textit{nn}, \textit{x}, \textit{d})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

The \texttt{\_\_call\_\_} interface.

Read the documentation for this class for more information. A call to
the class should have the following parameters:
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xx}

          \item[nn]


A \texttt{SOM} neural network instance that is going to be modified by
the learning algorithm. The modification is made \emph{in loco}, that is,
the synaptic weights of \texttt{nn} should be modified in place, and not
returned from this function.
          \item[x]


The input vector from the training set.
        \end{Ventry}

      \end{quote}

    \end{boxedminipage}


\large{\textbf{\textit{Inherited from object}}}

\begin{quote}
\_\_delattr\_\_(), \_\_format\_\_(), \_\_getattribute\_\_(), \_\_hash\_\_(), \_\_init\_\_(), \_\_new\_\_(), \_\_reduce\_\_(), \_\_reduce\_ex\_\_(), \_\_repr\_\_(), \_\_setattr\_\_(), \_\_sizeof\_\_(), \_\_str\_\_(), \_\_subclasshook\_\_()
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\multicolumn{2}{|l|}{\textit{Inherited from object}}\\
\multicolumn{2}{|p{\varwidth}|}{\raggedright \_\_class\_\_}\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.SOMLearning \textit{(class)}|)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.WinnerTakesAll \textit{(class)}|(}
\subsection{Class WinnerTakesAll}

    \label{peach:nn:lrules:WinnerTakesAll}
\begin{tabular}{cccccccc}
% Line for object, linespec=[False, False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
&&
  \\
% Line for peach.nn.lrules.SOMLearning, linespec=[False]
\multicolumn{4}{r}{\settowidth{\BCL}{peach.nn.lrules.SOMLearning}\multirow{2}{\BCL}{peach.nn.lrules.SOMLearning}}
&&
  \\\cline{5-5}
  &&&&\multicolumn{1}{c|}{}
&&
  \\
&&&&\multicolumn{2}{l}{\textbf{peach.nn.lrules.WinnerTakesAll}}
\end{tabular}


Purely competitive learning method without learning rate adjust.

A winner-takes-all strategy detects the winner on the self-organizing map
and adjusts it in the direction of the input vector, scaled by the learning
rate. Its tendency is to cluster around the gravity center of the points in
the training set.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_init\_\_}(\textit{self}, \textit{lrate}={\tt 0.05})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Initializes the object.
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xxxxx}

          \item[lrate]


Learning rate to be used in the algorithm. Defaults to 0.05.
        \end{Ventry}

      \end{quote}

      Overrides: object.\_\_init\_\_

    \end{boxedminipage}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self}, \textit{nn}, \textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

The \texttt{\_\_call\_\_} interface.

The learning implementation. Read the documentation for the base class
for more information. A call to the class should have the following
parameters:
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xx}

          \item[nn]


A \texttt{SOM} neural network instance that is going to be modified by
the learning algorithm. The modification is made \emph{in loco}, that is,
the synaptic weights of \texttt{nn} should be modified in place, and not
returned from this function.
          \item[x]


The input vector from the training set.
        \end{Ventry}

      \end{quote}

      Overrides: peach.nn.lrules.SOMLearning.\_\_call\_\_

    \end{boxedminipage}


\large{\textbf{\textit{Inherited from object}}}

\begin{quote}
\_\_delattr\_\_(), \_\_format\_\_(), \_\_getattribute\_\_(), \_\_hash\_\_(), \_\_new\_\_(), \_\_reduce\_\_(), \_\_reduce\_ex\_\_(), \_\_repr\_\_(), \_\_setattr\_\_(), \_\_sizeof\_\_(), \_\_str\_\_(), \_\_subclasshook\_\_()
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\multicolumn{2}{|l|}{\textit{Inherited from object}}\\
\multicolumn{2}{|p{\varwidth}|}{\raggedright \_\_class\_\_}\\
\cline{1-2}
\end{longtable}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                          Instance Variables                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Instance Variables}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright l\-r\-a\-t\-e\- & Learning rate used with the algorithm.&\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.WinnerTakesAll \textit{(class)}|)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.WinnerTakesAll \textit{(class)}|(}
\subsection{Class WinnerTakesAll}

    \label{peach:nn:lrules:WinnerTakesAll}
\begin{tabular}{cccccccc}
% Line for object, linespec=[False, False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
&&
  \\
% Line for peach.nn.lrules.SOMLearning, linespec=[False]
\multicolumn{4}{r}{\settowidth{\BCL}{peach.nn.lrules.SOMLearning}\multirow{2}{\BCL}{peach.nn.lrules.SOMLearning}}
&&
  \\\cline{5-5}
  &&&&\multicolumn{1}{c|}{}
&&
  \\
&&&&\multicolumn{2}{l}{\textbf{peach.nn.lrules.WinnerTakesAll}}
\end{tabular}


Purely competitive learning method without learning rate adjust.

A winner-takes-all strategy detects the winner on the self-organizing map
and adjusts it in the direction of the input vector, scaled by the learning
rate. Its tendency is to cluster around the gravity center of the points in
the training set.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_init\_\_}(\textit{self}, \textit{lrate}={\tt 0.05})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Initializes the object.
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xxxxx}

          \item[lrate]


Learning rate to be used in the algorithm. Defaults to 0.05.
        \end{Ventry}

      \end{quote}

      Overrides: object.\_\_init\_\_

    \end{boxedminipage}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self}, \textit{nn}, \textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

The \texttt{\_\_call\_\_} interface.

The learning implementation. Read the documentation for the base class
for more information. A call to the class should have the following
parameters:
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xx}

          \item[nn]


A \texttt{SOM} neural network instance that is going to be modified by
the learning algorithm. The modification is made \emph{in loco}, that is,
the synaptic weights of \texttt{nn} should be modified in place, and not
returned from this function.
          \item[x]


The input vector from the training set.
        \end{Ventry}

      \end{quote}

      Overrides: peach.nn.lrules.SOMLearning.\_\_call\_\_

    \end{boxedminipage}


\large{\textbf{\textit{Inherited from object}}}

\begin{quote}
\_\_delattr\_\_(), \_\_format\_\_(), \_\_getattribute\_\_(), \_\_hash\_\_(), \_\_new\_\_(), \_\_reduce\_\_(), \_\_reduce\_ex\_\_(), \_\_repr\_\_(), \_\_setattr\_\_(), \_\_sizeof\_\_(), \_\_str\_\_(), \_\_subclasshook\_\_()
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\multicolumn{2}{|l|}{\textit{Inherited from object}}\\
\multicolumn{2}{|p{\varwidth}|}{\raggedright \_\_class\_\_}\\
\cline{1-2}
\end{longtable}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                          Instance Variables                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Instance Variables}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright l\-r\-a\-t\-e\- & Learning rate used with the algorithm.&\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.WinnerTakesAll \textit{(class)}|)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.Competitive \textit{(class)}|(}
\subsection{Class Competitive}

    \label{peach:nn:lrules:Competitive}
\begin{tabular}{cccccccc}
% Line for object, linespec=[False, False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
&&
  \\
% Line for peach.nn.lrules.SOMLearning, linespec=[False]
\multicolumn{4}{r}{\settowidth{\BCL}{peach.nn.lrules.SOMLearning}\multirow{2}{\BCL}{peach.nn.lrules.SOMLearning}}
&&
  \\\cline{5-5}
  &&&&\multicolumn{1}{c|}{}
&&
  \\
&&&&\multicolumn{2}{l}{\textbf{peach.nn.lrules.Competitive}}
\end{tabular}


Competitive learning with time adjust of the learning rate.

A competitive strategy detects the winner on the self-organizing map and
adjusts it in the direction of the input vector, scaled by the learning
rate. Its tendency is to cluster around the gravity center of the points in
the training set. As time passes, the learning rate grows smaller, this
allows for better adjustment of the synaptic weights.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_init\_\_}(\textit{self}, \textit{lrate}={\tt 0.05}, \textit{tl}={\tt 1000.0})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Initializes the object.
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xxxxx}

          \item[lrate]


Learning rate to be used in the algorithm. Defaults to 0.05.
          \item[tl]


Time constant that measures how many iterations will be needed to
reduce the learning rate to a small value. Defaults to 1000.
        \end{Ventry}

      \end{quote}

      Overrides: object.\_\_init\_\_

    \end{boxedminipage}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self}, \textit{nn}, \textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

The \texttt{\_\_call\_\_} interface.

The learning implementation. Read the documentation for the base class
for more information. A call to the class should have the following
parameters:
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xx}

          \item[nn]


A \texttt{SOM} neural network instance that is going to be modified by
the learning algorithm. The modification is made \emph{in loco}, that is,
the synaptic weights of \texttt{nn} should be modified in place, and not
returned from this function.
          \item[x]


The input vector from the training set.
        \end{Ventry}

      \end{quote}

      Overrides: peach.nn.lrules.SOMLearning.\_\_call\_\_

    \end{boxedminipage}


\large{\textbf{\textit{Inherited from object}}}

\begin{quote}
\_\_delattr\_\_(), \_\_format\_\_(), \_\_getattribute\_\_(), \_\_hash\_\_(), \_\_new\_\_(), \_\_reduce\_\_(), \_\_reduce\_ex\_\_(), \_\_repr\_\_(), \_\_setattr\_\_(), \_\_sizeof\_\_(), \_\_str\_\_(), \_\_subclasshook\_\_()
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\multicolumn{2}{|l|}{\textit{Inherited from object}}\\
\multicolumn{2}{|p{\varwidth}|}{\raggedright \_\_class\_\_}\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.Competitive \textit{(class)}|)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.Cooperative \textit{(class)}|(}
\subsection{Class Cooperative}

    \label{peach:nn:lrules:Cooperative}
\begin{tabular}{cccccccc}
% Line for object, linespec=[False, False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
&&
  \\
% Line for peach.nn.lrules.SOMLearning, linespec=[False]
\multicolumn{4}{r}{\settowidth{\BCL}{peach.nn.lrules.SOMLearning}\multirow{2}{\BCL}{peach.nn.lrules.SOMLearning}}
&&
  \\\cline{5-5}
  &&&&\multicolumn{1}{c|}{}
&&
  \\
&&&&\multicolumn{2}{l}{\textbf{peach.nn.lrules.Cooperative}}
\end{tabular}


Cooperative learning with time adjust of the learning rate and neighborhood
function to propagate cooperation

A cooperative strategy detects the winner on the self-organizing map and
adjusts it in the direction of the input vector, scaled by the learning
rate. Its tendency is to cluster around the gravity center of the points in
the training set. As time passes, the learning rate grows smaller, this
allows for better adjustment of the synaptic weights.

Also, a neighborhood is defined on the winner. Neurons close to the winner
are also updated in the direction of the input vector, although with a
smaller scale determined by the neighborhood function. A neighborhood
function is 1. at 0., and decreases monotonically as the distance increases.

\emph{There are issues with this class!} -{}- some of the class capabilities are
yet to be developed.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_init\_\_}(\textit{self}, \textit{lrate}={\tt 0.05}, \textit{tl}={\tt 1000}, \textit{tn}={\tt 1000})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Initializes the object.
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xxxxx}

          \item[lrate]


Learning rate to be used in the algorithm. Defaults to 0.05.
          \item[tl]


Time constant that measures how many iterations will be needed to
reduce the learning rate to a small value. Defaults to 1000.
          \item[tn]


Time constant that measures how many iterations will be needed to
shrink the neighborhood. Defaults to 1000.
        \end{Ventry}

      \end{quote}

      Overrides: object.\_\_init\_\_

    \end{boxedminipage}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self}, \textit{nn}, \textit{x})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

The \texttt{\_\_call\_\_} interface.

The learning implementation. Read the documentation for the base class
for more information. A call to the class should have the following
parameters:
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xx}

          \item[nn]


A \texttt{SOM} neural network instance that is going to be modified by
the learning algorithm. The modification is made \emph{in loco}, that is,
the synaptic weights of \texttt{nn} should be modified in place, and not
returned from this function.
          \item[x]


The input vector from the training set.
        \end{Ventry}

      \end{quote}

      Overrides: peach.nn.lrules.SOMLearning.\_\_call\_\_

    \end{boxedminipage}


\large{\textbf{\textit{Inherited from object}}}

\begin{quote}
\_\_delattr\_\_(), \_\_format\_\_(), \_\_getattribute\_\_(), \_\_hash\_\_(), \_\_new\_\_(), \_\_reduce\_\_(), \_\_reduce\_ex\_\_(), \_\_repr\_\_(), \_\_setattr\_\_(), \_\_sizeof\_\_(), \_\_str\_\_(), \_\_subclasshook\_\_()
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\multicolumn{2}{|l|}{\textit{Inherited from object}}\\
\multicolumn{2}{|p{\varwidth}|}{\raggedright \_\_class\_\_}\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}!peach.nn.lrules.Cooperative \textit{(class)}|)}
    \index{peach \textit{(package)}!peach.nn \textit{(package)}!peach.nn.lrules \textit{(module)}|)}
