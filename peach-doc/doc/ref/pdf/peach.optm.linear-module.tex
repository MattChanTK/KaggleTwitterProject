%
% API Documentation for Peach - Computational Intelligence for Python
% Module peach.optm.linear
%
% Generated by epydoc 3.0.1
% [Sun Jul 31 17:00:41 2011]
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                          Module Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.linear \textit{(module)}|(}
\section{Module peach.optm.linear}

    \label{peach:optm:linear}

This package implements basic one variable only optimizers.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               Variables                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsection{Variables}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright \_\-\_\-d\-o\-c\-\_\-\_\- & \raggedright \textbf{Value:} 
{\tt \texttt{...}}&\\
\cline{1-2}
\raggedright \_\-\_\-p\-a\-c\-k\-a\-g\-e\-\_\-\_\- & \raggedright \textbf{Value:} 
{\tt \texttt{'}\texttt{peach.optm}\texttt{'}}&\\
\cline{1-2}
\end{longtable}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.linear \textit{(module)}!peach.optm.linear.Direct1D \textit{(class)}|(}
\subsection{Class Direct1D}

    \label{peach:optm:linear:Direct1D}
\begin{tabular}{cccccccc}
% Line for object, linespec=[False, False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
&&
  \\
% Line for peach.optm.base.Optimizer, linespec=[False]
\multicolumn{4}{r}{\settowidth{\BCL}{peach.optm.base.Optimizer}\multirow{2}{\BCL}{peach.optm.base.Optimizer}}
&&
  \\\cline{5-5}
  &&&&\multicolumn{1}{c|}{}
&&
  \\
&&&&\multicolumn{2}{l}{\textbf{peach.optm.linear.Direct1D}}
\end{tabular}


1-D direct search.

This methods 'oscilates' around the function minimum, reducing the updating
step until it achieves the maximum error or the maximum number of steps.
This is a very inefficient method, and should be used only at times where no
other methods are able to converge (eg., if a function has a lot of
discontinuities, or similar conditions).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_init\_\_}(\textit{self}, \textit{f}, \textit{x0}, \textit{range}={\tt None}, \textit{h}={\tt 0.5}, \textit{emax}={\tt 1e-08}, \textit{imax}={\tt 1000})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Initializes the optimizer.

To create an optimizer of this type, instantiate the class with the
parameters given below:
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xxxxx}

          \item[f]


A one variable only function to be optimized. The function should
have only one parameter and return the function value.
          \item[x0]


First estimate of the minimum. Since this is a linear method, this
should be a \texttt{float} or \texttt{int}.
          \item[range]


A range of values might be passed to the algorithm, but it is not
necessary. If supplied, this parameter should be a tuples of two
values, \texttt{(x0, x1)}, where \texttt{x0} is the start of the interval, and
\texttt{x1} its end. Obviously, \texttt{x0} should be smaller than \texttt{x1}.
When this parameter is present, the algorithm will not let the
estimates fall outside the given interval.
          \item[h]


The initial step of the search. Defaults to 0.5
          \item[emax]


Maximum allowed error. The algorithm stops as soon as the error is
below this level. The error is absolute.
          \item[imax]


Maximum number of iterations, the algorithm stops as soon this
number of iterations are executed, no matter what the error is at
the moment.
        \end{Ventry}

      \end{quote}

      Overrides: object.\_\_init\_\_

    \end{boxedminipage}

    \label{peach:optm:linear:Direct1D:restart}
    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.linear \textit{(module)}!peach.optm.linear.Direct1D \textit{(class)}!peach.optm.linear.Direct1D.restart \textit{(method)}}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{restart}(\textit{self}, \textit{x0}, \textit{h}={\tt None})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Resets the optimizer, returning to its original state, and allowing to
use a new first estimate.
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xx}

          \item[x0]


The new initial value of the estimate of the minimum. Since this is
a linear method, this should be a \texttt{float} or \texttt{int}.
          \item[h]


The initial step of the search. Defaults to 0.5
        \end{Ventry}

      \end{quote}

    \end{boxedminipage}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{step}(\textit{self})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

One step of the search.

In this method, the result of the step is highly dependent of the steps
executed before, as the search step is updated at each call to this
method.
\setlength{\parskip}{1ex}
      \textbf{Return Value}
    \vspace{-1ex}

      \begin{quote}

This method returns a tuple \texttt{(x, e)}, where \texttt{x} is the updated
estimate of the minimum, and \texttt{e} is the estimated error.
      \end{quote}

      Overrides: peach.optm.base.Optimizer.step

    \end{boxedminipage}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Transparently executes the search until the minimum is found. The stop
criteria are the maximum error or the maximum number of iterations,
whichever is reached first. Note that this is a \texttt{\_\_call\_\_} method, so
the object is called as a function. This method returns a tuple
\texttt{(x, e)}, with the best estimate of the minimum and the error.
\setlength{\parskip}{1ex}
      \textbf{Return Value}
    \vspace{-1ex}

      \begin{quote}

This method returns a tuple \texttt{(x, e)}, where \texttt{x} is the best
estimate of the minimum, and \texttt{e} is the estimated error.
      \end{quote}

      Overrides: peach.optm.base.Optimizer.\_\_call\_\_

    \end{boxedminipage}


\large{\textbf{\textit{Inherited from object}}}

\begin{quote}
\_\_delattr\_\_(), \_\_format\_\_(), \_\_getattribute\_\_(), \_\_hash\_\_(), \_\_new\_\_(), \_\_reduce\_\_(), \_\_reduce\_ex\_\_(), \_\_repr\_\_(), \_\_setattr\_\_(), \_\_sizeof\_\_(), \_\_str\_\_(), \_\_subclasshook\_\_()
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright x\- & &\\
\cline{1-2}
\multicolumn{2}{|l|}{\textit{Inherited from object}}\\
\multicolumn{2}{|p{\varwidth}|}{\raggedright \_\_class\_\_}\\
\cline{1-2}
\end{longtable}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                          Instance Variables                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Instance Variables}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright r\-a\-n\-g\-e\- & Holds the range for the estimates. If this attribute is set, the
algorithm will never let the estimates fall outside the given
interval.&\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.linear \textit{(module)}!peach.optm.linear.Direct1D \textit{(class)}|)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.linear \textit{(module)}!peach.optm.linear.Interpolation \textit{(class)}|(}
\subsection{Class Interpolation}

    \label{peach:optm:linear:Interpolation}
\begin{tabular}{cccccccc}
% Line for object, linespec=[False, False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
&&
  \\
% Line for peach.optm.base.Optimizer, linespec=[False]
\multicolumn{4}{r}{\settowidth{\BCL}{peach.optm.base.Optimizer}\multirow{2}{\BCL}{peach.optm.base.Optimizer}}
&&
  \\\cline{5-5}
  &&&&\multicolumn{1}{c|}{}
&&
  \\
&&&&\multicolumn{2}{l}{\textbf{peach.optm.linear.Interpolation}}
\end{tabular}


Optimization by quadractic interpolation.

This methods takes three estimates and finds the parabolic function that
fits them, and returns as a new estimate the vertex of the parabola. The
procedure can be repeated until a good approximation is found.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_init\_\_}(\textit{self}, \textit{f}, \textit{x0}, \textit{emax}={\tt 1e-08}, \textit{imax}={\tt 1000})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Initializes the optimizer.

To create an optimizer of this type, instantiate the class with the
parameters given below:
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xxxx}

          \item[f]


A one variable only function to be optimized. The function should
have only one parameter and return the function value.
          \item[x0]


First estimate of the minimum. The interpolation search needs three
estimates to approximate the parabolic function. Thus, the first
estimate must be a triple \texttt{(xl, xm, xh)}, with the property that
\texttt{xl < xm < xh}. Be aware, however, that no checking is done -{}- if
the estimate doesn't correspond to this condition, in some point an
exception will be raised.

Notice that, given the nature of the estimate of the interpolation
method, it is not necessary to have a specific parameter to restrict
the range of acceptable values -{}- it is already embedded in the
estimate. If you need to restrict your estimate between an interval,
just use its limits as \texttt{xl} and \texttt{xh} in the estimate.
          \item[emax]


Maximum allowed error. The algorithm stops as soon as the error is
below this level. The error is absolute.
          \item[imax]


Maximum number of iterations, the algorithm stops as soon this
number of iterations are executed, no matter what the error is at
the moment.
        \end{Ventry}

      \end{quote}

      Overrides: object.\_\_init\_\_

    \end{boxedminipage}

    \label{peach:optm:linear:Interpolation:restart}
    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.linear \textit{(module)}!peach.optm.linear.Interpolation \textit{(class)}!peach.optm.linear.Interpolation.restart \textit{(method)}}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{restart}(\textit{self}, \textit{x0})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Resets the optimizer, returning to its original state, and allowing to
use a new first estimate.
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xx}

          \item[x0]


The new initial value of the estimate of the minimum. The
interpolation search needs three estimates to approximate the
parabolic function. Thus, the estimate must be a triple
\texttt{(xl, xm, xh)}, with the property that \texttt{xl < xm < xh}. Be aware,
however, that no checking is done -{}- if the estimate doesn't
correspond to this condition, in some point an exception will be
raised.
        \end{Ventry}

      \end{quote}

    \end{boxedminipage}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{step}(\textit{self})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

One step of the search.

In this method, the result of the step is dependent only of the given
estimated, so it can be used for different kind of investigations on the
same cost function.
\setlength{\parskip}{1ex}
      \textbf{Return Value}
    \vspace{-1ex}

      \begin{quote}

This method returns a tuple \texttt{(x, e)}, where \texttt{x} is the updated
triplet of estimates of the minimum, and \texttt{e} is the estimated error.
      \end{quote}

      Overrides: peach.optm.base.Optimizer.step

    \end{boxedminipage}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Transparently executes the search until the minimum is found. The stop
criteria are the maximum error or the maximum number of iterations,
whichever is reached first. Note that this is a \texttt{\_\_call\_\_} method, so
the object is called as a function. This method returns a tuple
\texttt{(x, e)}, with the best estimate of the minimum and the error.
\setlength{\parskip}{1ex}
      \textbf{Return Value}
    \vspace{-1ex}

      \begin{quote}

This method returns a tuple \texttt{(x, e)}, where \texttt{x} is the best
estimate of the minimum, and \texttt{e} is the estimated error.
      \end{quote}

      Overrides: peach.optm.base.Optimizer.\_\_call\_\_

    \end{boxedminipage}


\large{\textbf{\textit{Inherited from object}}}

\begin{quote}
\_\_delattr\_\_(), \_\_format\_\_(), \_\_getattribute\_\_(), \_\_hash\_\_(), \_\_new\_\_(), \_\_reduce\_\_(), \_\_reduce\_ex\_\_(), \_\_repr\_\_(), \_\_setattr\_\_(), \_\_sizeof\_\_(), \_\_str\_\_(), \_\_subclasshook\_\_()
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright x\- & &\\
\cline{1-2}
\multicolumn{2}{|l|}{\textit{Inherited from object}}\\
\multicolumn{2}{|p{\varwidth}|}{\raggedright \_\_class\_\_}\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.linear \textit{(module)}!peach.optm.linear.Interpolation \textit{(class)}|)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.linear \textit{(module)}!peach.optm.linear.GoldenRule \textit{(class)}|(}
\subsection{Class GoldenRule}

    \label{peach:optm:linear:GoldenRule}
\begin{tabular}{cccccccc}
% Line for object, linespec=[False, False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
&&
  \\
% Line for peach.optm.base.Optimizer, linespec=[False]
\multicolumn{4}{r}{\settowidth{\BCL}{peach.optm.base.Optimizer}\multirow{2}{\BCL}{peach.optm.base.Optimizer}}
&&
  \\\cline{5-5}
  &&&&\multicolumn{1}{c|}{}
&&
  \\
&&&&\multicolumn{2}{l}{\textbf{peach.optm.linear.GoldenRule}}
\end{tabular}


Optimizer by the Golden Section Rule

This optimizer uses the golden rule to section an interval in search of the
minimum. Using a simple heuristic, the interval is refined until an interval
small enough to satisfy the error requirements is found.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_init\_\_}(\textit{self}, \textit{f}, \textit{x0}, \textit{emax}={\tt 1e-08}, \textit{imax}={\tt 1000})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Initializes the optimizer.

To create an optimizer of this type, instantiate the class with the
parameters given below:
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xxxx}

          \item[f]


A one variable only function to be optimized. The function should
have only one parameter and return the function value.
          \item[x0]


First estimate of the minimum. The golden rule search needs two
estimates to partition the interval. Thus, the first estimate must
be a duple \texttt{(xl, xh)}, with the property that \texttt{xl < xh}. Be
aware, however, that no checking is done -{}- if the estimate doesn't
correspond to this condition, in some point an exception will be
raised.

Notice that, given the nature of the estimate of the golden rule
method, it is not necessary to have a specific parameter to restrict
the range of acceptable values -{}- it is already embedded in the
estimate. If you need to restrict your estimate between an interval,
just use its limits as \texttt{xl} and \texttt{xh} in the estimate.
          \item[emax]


Maximum allowed error. The algorithm stops as soon as the error is
below this level. The error is absolute.
          \item[imax]


Maximum number of iterations, the algorithm stops as soon this
number of iterations are executed, no matter what the error is at
the moment.
        \end{Ventry}

      \end{quote}

      Overrides: object.\_\_init\_\_

    \end{boxedminipage}

    \label{peach:optm:linear:GoldenRule:restart}
    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.linear \textit{(module)}!peach.optm.linear.GoldenRule \textit{(class)}!peach.optm.linear.GoldenRule.restart \textit{(method)}}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{restart}(\textit{self}, \textit{x0})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Resets the optimizer, returning to its original state, and allowing to
use a new first estimate.
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xx}

          \item[x0]


The new value of the estimate of the minimum. The golden rule search
needs two estimates to partition the interval. Thus, the estimate
must be a duple \texttt{(xl, xh)}, with the property that \texttt{xl < xh}.
        \end{Ventry}

      \end{quote}

    \end{boxedminipage}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{step}(\textit{self})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

One step of the search.

In this method, the result of the step is dependent only of the given
estimated, so it can be used for different kind of investigations on the
same cost function.
\setlength{\parskip}{1ex}
      \textbf{Return Value}
    \vspace{-1ex}

      \begin{quote}

This method returns a tuple \texttt{(x, e)}, where \texttt{x} is the updated
duple of estimates of the minimum, and \texttt{e} is the estimated error.
      \end{quote}

      Overrides: peach.optm.base.Optimizer.step

    \end{boxedminipage}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Transparently executes the search until the minimum is found. The stop
criteria are the maximum error or the maximum number of iterations,
whichever is reached first. Note that this is a \texttt{\_\_call\_\_} method, so
the object is called as a function. This method returns a tuple
\texttt{(x, e)}, with the best estimate of the minimum and the error.
\setlength{\parskip}{1ex}
      \textbf{Return Value}
    \vspace{-1ex}

      \begin{quote}

This method returns a tuple \texttt{(x, e)}, where \texttt{x} is the best
estimate of the minimum, and \texttt{e} is the estimated error.
      \end{quote}

      Overrides: peach.optm.base.Optimizer.\_\_call\_\_

    \end{boxedminipage}


\large{\textbf{\textit{Inherited from object}}}

\begin{quote}
\_\_delattr\_\_(), \_\_format\_\_(), \_\_getattribute\_\_(), \_\_hash\_\_(), \_\_new\_\_(), \_\_reduce\_\_(), \_\_reduce\_ex\_\_(), \_\_repr\_\_(), \_\_setattr\_\_(), \_\_sizeof\_\_(), \_\_str\_\_(), \_\_subclasshook\_\_()
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright x\- & &\\
\cline{1-2}
\multicolumn{2}{|l|}{\textit{Inherited from object}}\\
\multicolumn{2}{|p{\varwidth}|}{\raggedright \_\_class\_\_}\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.linear \textit{(module)}!peach.optm.linear.GoldenRule \textit{(class)}|)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.linear \textit{(module)}!peach.optm.linear.Fibonacci \textit{(class)}|(}
\subsection{Class Fibonacci}

    \label{peach:optm:linear:Fibonacci}
\begin{tabular}{cccccccc}
% Line for object, linespec=[False, False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
&&
  \\
% Line for peach.optm.base.Optimizer, linespec=[False]
\multicolumn{4}{r}{\settowidth{\BCL}{peach.optm.base.Optimizer}\multirow{2}{\BCL}{peach.optm.base.Optimizer}}
&&
  \\\cline{5-5}
  &&&&\multicolumn{1}{c|}{}
&&
  \\
&&&&\multicolumn{2}{l}{\textbf{peach.optm.linear.Fibonacci}}
\end{tabular}


Optimization by the Golden Rule Section, estimated by Fibonacci numbers.

This optimizer uses the golden rule to section an interval in search of the
minimum. Using a simple heuristic, the interval is refined until an interval
small enough to satisfy the error requirements is found. The golden section
is estimated at each step using Fibonacci numbers. This can be useful in
situations where only integer numbers should be used.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_init\_\_}(\textit{self}, \textit{f}, \textit{x0}, \textit{emax}={\tt 1e-08}, \textit{imax}={\tt 1000})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Initializes the optimizer.

To create an optimizer of this type, instantiate the class with the
parameters given below:
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xxxx}

          \item[f]


A one variable only function to be optimized. The function should
have only one parameter and return the function value.
          \item[x0]


First estimate of the minimum. The Fibonacci search needs two
estimates to partition the interval. Thus, the first estimate must
be a duple \texttt{(xl, xh)}, with the property that \texttt{xl < xh}. Be
aware, however, that no checking is done -{}- if the estimate doesn't
correspond to this condition, in some point an exception will be
raised.

Notice that, given the nature of the estimate of the Fibonacci
method, it is not necessary to have a specific parameter to restrict
the range of acceptable values -{}- it is already embedded in the
estimate. If you need to restrict your estimate between an interval,
just use its limits as \texttt{xl} and \texttt{xh} in the estimate.
          \item[emax]


Maximum allowed error. The algorithm stops as soon as the error is
below this level. The error is absolute.
          \item[imax]


Maximum number of iterations, the algorithm stops as soon this
number of iterations are executed, no matter what the error is at
the moment.
        \end{Ventry}

      \end{quote}

      Overrides: object.\_\_init\_\_

    \end{boxedminipage}

    \label{peach:optm:linear:Fibonacci:restart}
    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.linear \textit{(module)}!peach.optm.linear.Fibonacci \textit{(class)}!peach.optm.linear.Fibonacci.restart \textit{(method)}}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{restart}(\textit{self}, \textit{x0})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Resets the optimizer, returning to its original state, and allowing to
use a new first estimate.
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xx}

          \item[x0]


The new value of the estimate of the minimum. The Fibonacci search
needs two estimates to partition the interval. Thus, the estimate
must be a duple \texttt{(xl, xh)}, with the property that \texttt{xl < xh}. Be
aware, however, that no checking is done -{}- if the estimate doesn't
correspond to this condition, in some point an exception will be
raised.
        \end{Ventry}

      \end{quote}

    \end{boxedminipage}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{step}(\textit{self})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

One step of the search.

In this method, the result of the step is highly dependent of the steps
executed before, as the estimate of the golden ratio is updated at each
call to this method.
\setlength{\parskip}{1ex}
      \textbf{Return Value}
    \vspace{-1ex}

      \begin{quote}

This method returns a tuple \texttt{(x, e)}, where \texttt{x} is the updated
duple of estimates of the minimum, and \texttt{e} is the estimated error.
      \end{quote}

      Overrides: peach.optm.base.Optimizer.step

    \end{boxedminipage}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Transparently executes the search until the minimum is found. The stop
criteria are the maximum error or the maximum number of iterations,
whichever is reached first. Note that this is a \texttt{\_\_call\_\_} method, so
the object is called as a function. This method returns a tuple
\texttt{(x, e)}, with the best estimate of the minimum and the error.
\setlength{\parskip}{1ex}
      \textbf{Return Value}
    \vspace{-1ex}

      \begin{quote}

This method returns a tuple \texttt{(x, e)}, where \texttt{x} is the best
estimate of the minimum, and \texttt{e} is the estimated error.
      \end{quote}

      Overrides: peach.optm.base.Optimizer.\_\_call\_\_

    \end{boxedminipage}


\large{\textbf{\textit{Inherited from object}}}

\begin{quote}
\_\_delattr\_\_(), \_\_format\_\_(), \_\_getattribute\_\_(), \_\_hash\_\_(), \_\_new\_\_(), \_\_reduce\_\_(), \_\_reduce\_ex\_\_(), \_\_repr\_\_(), \_\_setattr\_\_(), \_\_sizeof\_\_(), \_\_str\_\_(), \_\_subclasshook\_\_()
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\multicolumn{2}{|l|}{\textit{Inherited from object}}\\
\multicolumn{2}{|p{\varwidth}|}{\raggedright \_\_class\_\_}\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.linear \textit{(module)}!peach.optm.linear.Fibonacci \textit{(class)}|)}
    \index{peach \textit{(package)}!peach.optm \textit{(package)}!peach.optm.linear \textit{(module)}|)}
