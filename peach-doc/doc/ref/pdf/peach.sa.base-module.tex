%
% API Documentation for Peach - Computational Intelligence for Python
% Module peach.sa.base
%
% Generated by epydoc 3.0.1
% [Sun Jul 31 17:00:42 2011]
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                          Module Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.sa \textit{(package)}!peach.sa.base \textit{(module)}|(}
\section{Module peach.sa.base}

    \label{peach:sa:base}

This package implements two versions of simulated annealing optimization. One
works with numeric data, and the other with a codified bit string. This last
method can be used in discrete optimization problems.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               Functions                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsection{Functions}

    \label{peach:sa:base:standard_normal}
    \index{peach \textit{(package)}!peach.sa \textit{(package)}!peach.sa.base \textit{(module)}!peach.sa.base.standard\_normal \textit{(function)}}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{standard\_normal}(\textit{size}={\tt None})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Returns samples from a Standard Normal distribution (mean=0, stdev=1).


%___________________________________________________________________________

\paragraph*{Parameters%
  \phantomsection%
  \addcontentsline{toc}{paragraph}{Parameters}%
  \label{parameters}%
}
%
\begin{description}
\item[{size}] \leavevmode (\textbf{int, shape tuple, optional})

Returns the number of samples required to satisfy the \texttt{size} parameter.
If not given or 'None' indicates to return one sample.

\end{description}


%___________________________________________________________________________

\paragraph*{Returns%
  \phantomsection%
  \addcontentsline{toc}{paragraph}{Returns}%
  \label{returns}%
}
%
\begin{description}
\item[{out}] \leavevmode (\textbf{float, ndarray})

Samples the Standard Normal distribution with a shape satisfying the
\texttt{size} parameter.

\end{description}
\setlength{\parskip}{1ex}
    \end{boxedminipage}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               Variables                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsection{Variables}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright \_\-\_\-d\-o\-c\-\_\-\_\- & \raggedright \textbf{Value:} 
{\tt \texttt{...}}&\\
\cline{1-2}
\raggedright \_\-\_\-p\-a\-c\-k\-a\-g\-e\-\_\-\_\- & \raggedright \textbf{Value:} 
{\tt \texttt{'}\texttt{peach.sa}\texttt{'}}&\\
\cline{1-2}
\end{longtable}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.sa \textit{(package)}!peach.sa.base \textit{(module)}!peach.sa.base.ContinuousSA \textit{(class)}|(}
\subsection{Class ContinuousSA}

    \label{peach:sa:base:ContinuousSA}
\begin{tabular}{cccccc}
% Line for object, linespec=[False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
  \\
&&\multicolumn{2}{l}{\textbf{peach.sa.base.ContinuousSA}}
\end{tabular}


Simulated Annealing continuous optimization.

This is a simulated annealing optimizer implemented to work with vectors of
continuous variables (obviouslly, implemented as floating point numbers). In
general, simulated annealing methods searches for neighbors of one estimate,
which makes a lot more sense in discrete problems. While in this class the
method is implemented in a different way (to deal with continuous
variables), the principle is pretty much the same -{}- the neighbor is found
based on a gaussian neighborhood.

A simulated annealing algorithm adapted to deal with continuous variables
has an enhancement that can be used: a gradient vector can be given and, in
case the neighbor is not accepted, the estimate is updated in the downhill
direction.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_init\_\_}(\textit{self}, \textit{f}, \textit{x0}, \textit{ranges}={\tt None}, \textit{neighbor}={\tt {\textless}class 'peach.sa.neighbor.GaussianNeighbor'{\textgreater}}, \textit{optm}={\tt None}, \textit{T0}={\tt 1000.0}, \textit{rt}={\tt 0.95}, \textit{emax}={\tt 1e-08}, \textit{imax}={\tt 1000})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Initializes the optimizer.

To create an optimizer of this type, instantiate the class with the
parameters given below:
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xxxxxxxx}

          \item[f]


A multivariable function to be optimized. The function should have
only one parameter, a multidimensional line-vector, and return the
function value, a scalar.
          \item[x0]


First estimate of the minimum. Estimates can be given in any format,
but internally they are converted to a one-dimension vector, where
each component corresponds to the estimate of that particular
variable. The vector is computed by flattening the array.
          \item[ranges]


A range of values might be passed to the algorithm, but it is not
necessary. If supplied, this parameter should be a list of ranges
for each variable of the objective function. It is specified as a
list of tuples of two values, \texttt{(x0, x1)}, where \texttt{x0} is the
start of the interval, and \texttt{x1} its end. Obviously, \texttt{x0} should
be smaller than \texttt{x1}. It can also be given as a list with a simple
tuple in the same format. In that case, the same range will be
applied for every variable in the optimization.
          \item[neighbor]


Neighbor function. This is a function used to compute the neighbor
of the present estimate. You can use the ones defined in the
\texttt{neighbor} module, or you can implement your own. In any case, the
\texttt{neighbor} parameter must be an instance of \texttt{ContinuousNeighbor}
or of a subclass. Please, see the documentation on the \texttt{neighbor}
module for more information. The default is \texttt{GaussianNeighbor},
which computes the new estimate based on a gaussian distribution
around the present estimate.
          \item[optm]


A standard optimizer such as gradient or Newton. This is used in
case the estimate is not accepted by the algorithm -{}- in this case,
a new estimate is computed in a standard way, providing a little
improvement in any case. It defaults to None; in that case, no
standard optimizatiion will be used. Notice that, if you want to use
a standard optimizer, you must create it before you instantiate this
class. By doing it this way, you can configure the optimizer in any
way you want. Please, consult the documentation in \texttt{Gradient},
\texttt{Newton} and others.
          \item[T0]


Initial temperature of the system. The temperature is, of course, an
analogy. Defaults to 1000.
          \item[rt]


Temperature decreasing rate. The temperature must slowly decrease in
simulated annealing algorithms. In this implementation, this is
controlled by this parameter. At each step, the temperature is
multiplied by this value, so it is necessary that \texttt{0 < rt < 1}.
Defaults to 0.95, smaller values make the temperature decay faster,
while larger values make the temperature decay slower.
          \item[h]


Convergence step. In the case that the neighbor estimate is not
accepted, a simple gradient step is executed. This parameter is the
convergence step to the gradient step.
          \item[emax]


Maximum allowed error. The algorithm stops as soon as the error is
below this level. The error is absolute.
          \item[imax]


Maximum number of iterations, the algorithm stops as soon this
number of iterations are executed, no matter what the error is at
the moment.
        \end{Ventry}

      \end{quote}

      Overrides: object.\_\_init\_\_

    \end{boxedminipage}

    \label{peach:sa:base:ContinuousSA:restart}
    \index{peach \textit{(package)}!peach.sa \textit{(package)}!peach.sa.base \textit{(module)}!peach.sa.base.ContinuousSA \textit{(class)}!peach.sa.base.ContinuousSA.restart \textit{(method)}}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{restart}(\textit{self}, \textit{x0}, \textit{T0}={\tt 1000.0}, \textit{rt}={\tt 0.95}, \textit{h}={\tt 0.5})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Resets the optimizer, returning to its original state, and allowing to
use a new first estimate. Restartings are essential to the working of
simulated annealing algorithms, to allow them to leave local minima.
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xx}

          \item[x0]


New estimate of the minimum. Estimates can be given in any format,
but internally they are converted to a one-dimension vector, where
each component corresponds to the estimate of that particular
variable. The vector is computed by flattening the array.
          \item[T0]


Initial temperature of the system. The temperature is, of course, an
analogy. Defaults to 1000.
          \item[rt]


Temperature decreasing rate. The temperature must slowly decrease in
simulated annealing algorithms. In this implementation, this is
controlled by this parameter. At each step, the temperature is
multiplied by this value, so it is necessary that \texttt{0 < rt < 1}.
Defaults to 0.95, smaller values make the temperature decay faster,
while larger values make the temperature decay slower.
          \item[h]


The initial step of the search. Defaults to 0.5
        \end{Ventry}

      \end{quote}

    \end{boxedminipage}

    \label{peach:sa:base:ContinuousSA:step}
    \index{peach \textit{(package)}!peach.sa \textit{(package)}!peach.sa.base \textit{(module)}!peach.sa.base.ContinuousSA \textit{(class)}!peach.sa.base.ContinuousSA.step \textit{(method)}}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{step}(\textit{self})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

One step of the search.

In this method, a neighbor of the given estimate is chosen at random,
using a gaussian neighborhood. It is accepted as a new estimate if it
performs better in the cost function \emph{or} if the temperature is high
enough. In case it is not accepted, a gradient step is executed.
\setlength{\parskip}{1ex}
      \textbf{Return Value}
    \vspace{-1ex}

      \begin{quote}

This method returns a tuple \texttt{(x, e)}, where \texttt{x} is the updated
estimate of the minimum, and \texttt{e} is the estimated error.
      \end{quote}

    \end{boxedminipage}

    \label{peach:sa:base:ContinuousSA:__call__}
    \index{peach \textit{(package)}!peach.sa \textit{(package)}!peach.sa.base \textit{(module)}!peach.sa.base.ContinuousSA \textit{(class)}!peach.sa.base.ContinuousSA.\_\_call\_\_ \textit{(method)}}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Transparently executes the search until the minimum is found. The stop
criteria are the maximum error or the maximum number of iterations,
whichever is reached first. Note that this is a \texttt{\_\_call\_\_} method, so
the object is called as a function. This method returns a tuple
\texttt{(x, e)}, with the best estimate of the minimum and the error.
\setlength{\parskip}{1ex}
      \textbf{Return Value}
    \vspace{-1ex}

      \begin{quote}

This method returns a tuple \texttt{(x, e)}, where \texttt{x} is the best
estimate of the minimum, and \texttt{e} is the estimated error.
      \end{quote}

    \end{boxedminipage}


\large{\textbf{\textit{Inherited from object}}}

\begin{quote}
\_\_delattr\_\_(), \_\_format\_\_(), \_\_getattribute\_\_(), \_\_hash\_\_(), \_\_new\_\_(), \_\_reduce\_\_(), \_\_reduce\_ex\_\_(), \_\_repr\_\_(), \_\_setattr\_\_(), \_\_sizeof\_\_(), \_\_str\_\_(), \_\_subclasshook\_\_()
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright x\- & &\\
\cline{1-2}
\raggedright f\-x\- & &\\
\cline{1-2}
\multicolumn{2}{|l|}{\textit{Inherited from object}}\\
\multicolumn{2}{|p{\varwidth}|}{\raggedright \_\_class\_\_}\\
\cline{1-2}
\end{longtable}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                          Instance Variables                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Instance Variables}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright r\-a\-n\-g\-e\-s\- & Holds the ranges for every variable. Although it is a writable
property, care should be taken in changing parameters before ending the
convergence.&\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.sa \textit{(package)}!peach.sa.base \textit{(module)}!peach.sa.base.ContinuousSA \textit{(class)}|)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                           Class Description                           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \index{peach \textit{(package)}!peach.sa \textit{(package)}!peach.sa.base \textit{(module)}!peach.sa.base.BinarySA \textit{(class)}|(}
\subsection{Class BinarySA}

    \label{peach:sa:base:BinarySA}
\begin{tabular}{cccccc}
% Line for object, linespec=[False]
\multicolumn{2}{r}{\settowidth{\BCL}{object}\multirow{2}{\BCL}{object}}
&&
  \\\cline{3-3}
  &&\multicolumn{1}{c|}{}
&&
  \\
&&\multicolumn{2}{l}{\textbf{peach.sa.base.BinarySA}}
\end{tabular}


Simulated Annealing binary optimization.

This is a simulated annealing optimizer implemented to work with vectors of
bits, which can be floating point or integer numbers, characters or anything
allowed by the \texttt{struct} module of the Python standard library. The
neighborhood of an estimate is calculated by an appropriate method given in
the class instantiation. Given the nature of this implementation, no
alternate convergence can be used in the case of rejection of an estimate.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                Methods                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Methods}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_init\_\_}(\textit{self}, \textit{f}, \textit{x0}, \textit{ranges}={\tt \texttt{[}\texttt{]}}, \textit{fmt}={\tt None}, \textit{neighbor}={\tt {\textless}class 'peach.sa.neighbor.InvertBitsNeighbor'{\textgreater}}, \textit{T0}={\tt 1000.0}, \textit{rt}={\tt 0.95}, \textit{emax}={\tt 1e-08}, \textit{imax}={\tt 1000})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Initializes the optimizer.

To create an optimizer of this type, instantiate the class with the
parameters given below:
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xxxxxxxx}

          \item[f]


A multivariable function to be optimized. The function should have
only one parameter, a multidimensional line-vector, and return the
function value, a scalar.
          \item[x0]


First estimate of the minimum. Estimates can be given in any format,
but internally they are converted to a one-dimension vector, where
each component corresponds to the estimate of that particular
variable. The vector is computed by flattening the array.
          \item[ranges]


Ranges of values allowed for each component of the input vector. If
given, ranges are checked and a new estimate is generated in case
any of the components fall beyond the value. \texttt{range} can be a
tuple containing the inferior and superior limits of the interval;
in that case, the same range is used for every variable in the input
vector. \texttt{range} can also be a list of tuples of the same format,
inferior and superior limits; in that case, the first tuple is
assumed as the range allowed for the first variable, the second
tuple is assumed as the range allowed for the second variable and so
on.
          \item[fmt]


A \texttt{struct}-module string with the format of the data used. Please,
consult the \texttt{struct} documentation, since what is explained there
is exactly what is used here. For example, if you are going to use
the optimizer to deal with three-dimensional vectors of continuous
variables, the format would be something like:
%
\begin{quote}{\ttfamily \raggedright \noindent
fmt~=~'fff'
}
\end{quote}

Default value is an empty string. Notice that this is implemented as
a \texttt{bitarray}, so this module must be present.

It is strongly recommended that integer numbers are used! Floating
point numbers can be simulated with long integers. The reason for
this is that random bit sequences can have no representation as
floating point numbers, and that can make the algorithm not perform
adequatelly.

The default value for this parameter is \texttt{None}, meaning that a
default format is not supplied. If a format is not supplied, then
the estimate will be passed as a bitarray to the objective function.
This means that your function must take care to decode the bit
stream to extract meaning from it.
          \item[neighbor]


Neighbor function. This is a function used to compute the neighbor
of the present estimate. You can use the ones defined in the
\texttt{neighbor} module, or you can implement your own. In any case, the
\texttt{neighbor} parameter must be an instance of \texttt{BinaryNeighbor} or
of a subclass. Please, see the documentation on the \texttt{neighbor}
module for more information. The default is \texttt{InvertBitsNeighbor},
which computes the new estimate by inverting some bits in the
present estimate.
          \item[T0]


Initial temperature of the system. The temperature is, of course, an
analogy. Defaults to 1000.
          \item[rt]


Temperature decreasing rate. The temperature must slowly decrease in
simulated annealing algorithms. In this implementation, this is
controlled by this parameter. At each step, the temperature is
multiplied by this value, so it is necessary that \texttt{0 < rt < 1}.
Defaults to 0.95, smaller values make the temperature decay faster,
while larger values make the temperature decay slower.
          \item[emax]


Maximum allowed error. The algorithm stops as soon as the error is
below this level. The error is absolute.
          \item[imax]


Maximum number of iterations, the algorithm stops as soon this
number of iterations are executed, no matter what the error is at
the moment.
        \end{Ventry}

      \end{quote}

      Overrides: object.\_\_init\_\_

    \end{boxedminipage}

    \label{peach:sa:base:BinarySA:restart}
    \index{peach \textit{(package)}!peach.sa \textit{(package)}!peach.sa.base \textit{(module)}!peach.sa.base.BinarySA \textit{(class)}!peach.sa.base.BinarySA.restart \textit{(method)}}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{restart}(\textit{self}, \textit{x0}, \textit{ranges}={\tt None}, \textit{T0}={\tt 1000.0}, \textit{rt}={\tt 0.95}, \textit{h}={\tt 0.5})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Resets the optimizer, returning to its original state, and allowing to
use a new first estimate. Restartings are essential to the working of
simulated annealing algorithms, to allow them to leave local minima.
\setlength{\parskip}{1ex}
      \textbf{Parameters}
      \vspace{-1ex}

      \begin{quote}
        \begin{Ventry}{xxxxxx}

          \item[x0]


New estimate of the minimum. Estimates can be given in any format,
but internally they are converted to a one-dimension vector, where
each component corresponds to the estimate of that particular
variable. The vector is computed by flattening the array.
          \item[ranges]


Ranges of values allowed for each component of the input vector. If
given, ranges are checked and a new estimate is generated in case
any of the components fall beyond the value. \texttt{range} can be a
tuple containing the inferior and superior limits of the interval;
in that case, the same range is used for every variable in the input
vector. \texttt{range} can also be a list of tuples of the same format,
inferior and superior limits; in that case, the first tuple is
assumed as the range allowed for the first variable, the second
tuple is assumed as the range allowed for the second variable and so
on.
          \item[T0]


Initial temperature of the system. The temperature is, of course, an
analogy. Defaults to 1000.
          \item[rt]


Temperature decreasing rate. The temperature must slowly decrease in
simulated annealing algorithms. In this implementation, this is
controlled by this parameter. At each step, the temperature is
multiplied by this value, so it is necessary that \texttt{0 < rt < 1}.
Defaults to 0.95, smaller values make the temperature decay faster,
while larger values make the temperature decay slower.
        \end{Ventry}

      \end{quote}

    \end{boxedminipage}

    \label{peach:sa:base:BinarySA:step}
    \index{peach \textit{(package)}!peach.sa \textit{(package)}!peach.sa.base \textit{(module)}!peach.sa.base.BinarySA \textit{(class)}!peach.sa.base.BinarySA.step \textit{(method)}}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{step}(\textit{self})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

One step of the search.

In this method, a neighbor of the given estimate is obtained from the
present estimate by choosing \texttt{nb} bits and inverting them. It is
accepted as a new estimate if it performs better in the cost function
\emph{or} if the temperature is high enough. In case it is not accepted, the
previous estimate is mantained.
\setlength{\parskip}{1ex}
      \textbf{Return Value}
    \vspace{-1ex}

      \begin{quote}

This method returns a tuple \texttt{(x, e)}, where \texttt{x} is the updated
estimate of the minimum, and \texttt{e} is the estimated error.
      \end{quote}

    \end{boxedminipage}

    \label{peach:sa:base:BinarySA:__call__}
    \index{peach \textit{(package)}!peach.sa \textit{(package)}!peach.sa.base \textit{(module)}!peach.sa.base.BinarySA \textit{(class)}!peach.sa.base.BinarySA.\_\_call\_\_ \textit{(method)}}

    \vspace{0.5ex}

\hspace{.8\funcindent}\begin{boxedminipage}{\funcwidth}

    \raggedright \textbf{\_\_call\_\_}(\textit{self})

    \vspace{-1.5ex}

    \rule{\textwidth}{0.5\fboxrule}
\setlength{\parskip}{2ex}

Transparently executes the search until the minimum is found. The stop
criteria are the maximum error or the maximum number of iterations,
whichever is reached first. Note that this is a \texttt{\_\_call\_\_} method, so
the object is called as a function. This method returns a tuple
\texttt{(x, e)}, with the best estimate of the minimum and the error.
\setlength{\parskip}{1ex}
      \textbf{Return Value}
    \vspace{-1ex}

      \begin{quote}

This method returns a tuple \texttt{(x, e)}, where \texttt{x} is the best
estimate of the minimum, and \texttt{e} is the estimated error.
      \end{quote}

    \end{boxedminipage}


\large{\textbf{\textit{Inherited from object}}}

\begin{quote}
\_\_delattr\_\_(), \_\_format\_\_(), \_\_getattribute\_\_(), \_\_hash\_\_(), \_\_new\_\_(), \_\_reduce\_\_(), \_\_reduce\_ex\_\_(), \_\_repr\_\_(), \_\_setattr\_\_(), \_\_sizeof\_\_(), \_\_str\_\_(), \_\_subclasshook\_\_()
\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                              Properties                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \subsubsection{Properties}

    \vspace{-1cm}
\hspace{\varindent}\begin{longtable}{|p{\varnamewidth}|p{\vardescrwidth}|l}
\cline{1-2}
\cline{1-2} \centering \textbf{Name} & \centering \textbf{Description}& \\
\cline{1-2}
\endhead\cline{1-2}\multicolumn{3}{r}{\small\textit{continued on next page}}\\\endfoot\cline{1-2}
\endlastfoot\raggedright x\- & \raggedright Getter for the estimate. The estimate is decoded as the format supplied.
If no format was supplied, then the estimate is returned as a bitarray.&\\
\cline{1-2}
\raggedright b\-e\-s\-t\- & \raggedright Getter for the best value so far. Returns a tuple containing both the
best estimate and its value.&\\
\cline{1-2}
\multicolumn{2}{|l|}{\textit{Inherited from object}}\\
\multicolumn{2}{|p{\varwidth}|}{\raggedright \_\_class\_\_}\\
\cline{1-2}
\end{longtable}

    \index{peach \textit{(package)}!peach.sa \textit{(package)}!peach.sa.base \textit{(module)}!peach.sa.base.BinarySA \textit{(class)}|)}
    \index{peach \textit{(package)}!peach.sa \textit{(package)}!peach.sa.base \textit{(module)}|)}
