<?xml version="1.0" encoding="ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
          "DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <title>peach.nn.nnet</title>
  <link rel="stylesheet" href="epydoc.css" type="text/css" />
  <script type="text/javascript" src="epydoc.js"></script>
</head>

<body bgcolor="white" text="black" link="blue" vlink="#204080"
      alink="#204080">
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="peach-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Project homepage -->
      <th class="navbar" align="right" width="100%">
        <table border="0" cellpadding="0" cellspacing="0">
          <tr><th class="navbar" align="center"
            ><a href="http://code.google.com/p/peach">Peach - Computational Intelligence for Python</a></th>
          </tr></table></th>
  </tr>
</table>
<table width="100%" cellpadding="0" cellspacing="0">
  <tr valign="top">
    <td width="100%">
      <span class="breadcrumbs">
        <a href="peach-module.html">Package&nbsp;peach</a> ::
        <a href="peach.nn-module.html">Package&nbsp;nn</a> ::
        Module&nbsp;nnet
      </span>
    </td>
    <td>
      <table cellpadding="0" cellspacing="0">
        <!-- hide/show private -->
        <tr><td align="right"><span class="options">[<a href="javascript:void(0);" class="privatelink"
    onclick="toggle_private();">hide&nbsp;private</a>]</span></td></tr>
        <tr><td align="right"><span class="options"
            >[<a href="frames.html" target="_top">frames</a
            >]&nbsp;|&nbsp;<a href="peach.nn.nnet-pysrc.html"
            target="_top">no&nbsp;frames</a>]</span></td></tr>
      </table>
    </td>
  </tr>
</table>
<h1 class="epydoc">Source Code for <a href="peach.nn.nnet-module.html">Module peach.nn.nnet</a></h1>
<pre class="py-src">
<a name="L1"></a><tt class="py-lineno">  1</tt>  <tt class="py-line"><tt class="py-comment">################################################################################</tt> </tt>
<a name="L2"></a><tt class="py-lineno">  2</tt>  <tt class="py-line"><tt class="py-comment"># Peach - Computational Intelligence for Python</tt> </tt>
<a name="L3"></a><tt class="py-lineno">  3</tt>  <tt class="py-line"><tt class="py-comment"># Jose Alexandre Nalon</tt> </tt>
<a name="L4"></a><tt class="py-lineno">  4</tt>  <tt class="py-line"><tt class="py-comment">#</tt> </tt>
<a name="L5"></a><tt class="py-lineno">  5</tt>  <tt class="py-line"><tt class="py-comment"># This file: nn/nn.py</tt> </tt>
<a name="L6"></a><tt class="py-lineno">  6</tt>  <tt class="py-line"><tt class="py-comment"># Basic topologies of neural networks</tt> </tt>
<a name="L7"></a><tt class="py-lineno">  7</tt>  <tt class="py-line"><tt class="py-comment">################################################################################</tt> </tt>
<a name="L8"></a><tt class="py-lineno">  8</tt>  <tt class="py-line"> </tt>
<a name="L9"></a><tt class="py-lineno">  9</tt>  <tt class="py-line"><tt class="py-comment"># Doc string, reStructuredText formatted:</tt> </tt>
<a name="L10"></a><tt class="py-lineno"> 10</tt>  <tt class="py-line"><tt id="link-0" class="py-name" targets="Variable peach.__doc__=peach-module.html#__doc__,Variable peach.fuzzy.__doc__=peach.fuzzy-module.html#__doc__,Variable peach.fuzzy.base.__doc__=peach.fuzzy.base-module.html#__doc__,Variable peach.fuzzy.cmeans.__doc__=peach.fuzzy.cmeans-module.html#__doc__,Variable peach.fuzzy.control.__doc__=peach.fuzzy.control-module.html#__doc__,Variable peach.fuzzy.defuzzy.__doc__=peach.fuzzy.defuzzy-module.html#__doc__,Variable peach.fuzzy.mf.__doc__=peach.fuzzy.mf-module.html#__doc__,Variable peach.fuzzy.norms.__doc__=peach.fuzzy.norms-module.html#__doc__,Variable peach.ga.__doc__=peach.ga-module.html#__doc__,Variable peach.ga.base.__doc__=peach.ga.base-module.html#__doc__,Variable peach.ga.chromosome.__doc__=peach.ga.chromosome-module.html#__doc__,Variable peach.ga.crossover.__doc__=peach.ga.crossover-module.html#__doc__,Variable peach.ga.fitness.__doc__=peach.ga.fitness-module.html#__doc__,Variable peach.ga.mutation.__doc__=peach.ga.mutation-module.html#__doc__,Variable peach.ga.selection.__doc__=peach.ga.selection-module.html#__doc__,Variable peach.nn.__doc__=peach.nn-module.html#__doc__,Variable peach.nn.af.__doc__=peach.nn.af-module.html#__doc__,Variable peach.nn.base.__doc__=peach.nn.base-module.html#__doc__,Variable peach.nn.kmeans.__doc__=peach.nn.kmeans-module.html#__doc__,Variable peach.nn.lrules.__doc__=peach.nn.lrules-module.html#__doc__,Variable peach.nn.mem.__doc__=peach.nn.mem-module.html#__doc__,Variable peach.nn.nnet.__doc__=peach.nn.nnet-module.html#__doc__,Variable peach.nn.rbfn.__doc__=peach.nn.rbfn-module.html#__doc__,Variable peach.optm.__doc__=peach.optm-module.html#__doc__,Variable peach.optm.base.__doc__=peach.optm.base-module.html#__doc__,Variable peach.optm.linear.__doc__=peach.optm.linear-module.html#__doc__,Variable peach.optm.multivar.__doc__=peach.optm.multivar-module.html#__doc__,Variable peach.optm.quasinewton.__doc__=peach.optm.quasinewton-module.html#__doc__,Variable peach.optm.stochastic.__doc__=peach.optm.stochastic-module.html#__doc__,Variable peach.pso.__doc__=peach.pso-module.html#__doc__,Variable peach.pso.acc.__doc__=peach.pso.acc-module.html#__doc__,Variable peach.pso.base.__doc__=peach.pso.base-module.html#__doc__,Variable peach.sa.__doc__=peach.sa-module.html#__doc__,Variable peach.sa.base.__doc__=peach.sa.base-module.html#__doc__,Variable peach.sa.neighbor.__doc__=peach.sa.neighbor-module.html#__doc__"><a title="peach.__doc__
peach.fuzzy.__doc__
peach.fuzzy.base.__doc__
peach.fuzzy.cmeans.__doc__
peach.fuzzy.control.__doc__
peach.fuzzy.defuzzy.__doc__
peach.fuzzy.mf.__doc__
peach.fuzzy.norms.__doc__
peach.ga.__doc__
peach.ga.base.__doc__
peach.ga.chromosome.__doc__
peach.ga.crossover.__doc__
peach.ga.fitness.__doc__
peach.ga.mutation.__doc__
peach.ga.selection.__doc__
peach.nn.__doc__
peach.nn.af.__doc__
peach.nn.base.__doc__
peach.nn.kmeans.__doc__
peach.nn.lrules.__doc__
peach.nn.mem.__doc__
peach.nn.nnet.__doc__
peach.nn.rbfn.__doc__
peach.optm.__doc__
peach.optm.base.__doc__
peach.optm.linear.__doc__
peach.optm.multivar.__doc__
peach.optm.quasinewton.__doc__
peach.optm.stochastic.__doc__
peach.pso.__doc__
peach.pso.acc.__doc__
peach.pso.base.__doc__
peach.sa.__doc__
peach.sa.base.__doc__
peach.sa.neighbor.__doc__" class="py-name" href="#" onclick="return doclink('link-0', '__doc__', 'link-0');">__doc__</a></tt> <tt class="py-op">=</tt> <tt class="py-docstring">"""</tt> </tt>
<a name="L11"></a><tt class="py-lineno"> 11</tt>  <tt class="py-line"><tt class="py-docstring">Basic topologies of neural networks.</tt> </tt>
<a name="L12"></a><tt class="py-lineno"> 12</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L13"></a><tt class="py-lineno"> 13</tt>  <tt class="py-line"><tt class="py-docstring">This sub-package implements various neural network topologies, see the complete</tt> </tt>
<a name="L14"></a><tt class="py-lineno"> 14</tt>  <tt class="py-line"><tt class="py-docstring">list below. These topologies are implemented using the ``Layer`` class of the</tt> </tt>
<a name="L15"></a><tt class="py-lineno"> 15</tt>  <tt class="py-line"><tt class="py-docstring">``base`` sub-package. Please, consult the documentation of that module for more</tt> </tt>
<a name="L16"></a><tt class="py-lineno"> 16</tt>  <tt class="py-line"><tt class="py-docstring">information on layers of neurons. The neural nets implemented here don't derive</tt> </tt>
<a name="L17"></a><tt class="py-lineno"> 17</tt>  <tt class="py-line"><tt class="py-docstring">from the ``Layer`` class, instead, they have instance variables to take control</tt> </tt>
<a name="L18"></a><tt class="py-lineno"> 18</tt>  <tt class="py-line"><tt class="py-docstring">of them. Thus, there is no base class for networks. While subclassing the</tt> </tt>
<a name="L19"></a><tt class="py-lineno"> 19</tt>  <tt class="py-line"><tt class="py-docstring">classes of this module is usually safe, it is recomended that a new kind of</tt> </tt>
<a name="L20"></a><tt class="py-lineno"> 20</tt>  <tt class="py-line"><tt class="py-docstring">net is developed from the ground up.</tt> </tt>
<a name="L21"></a><tt class="py-lineno"> 21</tt>  <tt class="py-line"><tt class="py-docstring">"""</tt> </tt>
<a name="L22"></a><tt class="py-lineno"> 22</tt>  <tt class="py-line"> </tt>
<a name="L23"></a><tt class="py-lineno"> 23</tt>  <tt class="py-line"><tt class="py-comment">################################################################################</tt> </tt>
<a name="L24"></a><tt class="py-lineno"> 24</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt class="py-name">numpy</tt> <tt class="py-keyword">import</tt> <tt class="py-name">array</tt><tt class="py-op">,</tt> <tt class="py-name">sum</tt><tt class="py-op">,</tt> <tt id="link-1" class="py-name" targets="Variable peach.nn.rbfn.abs=peach.nn.rbfn-module.html#abs,Variable peach.pso.base.abs=peach.pso.base-module.html#abs"><a title="peach.nn.rbfn.abs
peach.pso.base.abs" class="py-name" href="#" onclick="return doclink('link-1', 'abs', 'link-1');">abs</a></tt><tt class="py-op">,</tt> <tt class="py-name">reshape</tt><tt class="py-op">,</tt> <tt id="link-2" class="py-name" targets="Variable peach.nn.rbfn.sqrt=peach.nn.rbfn-module.html#sqrt,Variable peach.pso.base.sqrt=peach.pso.base-module.html#sqrt"><a title="peach.nn.rbfn.sqrt
peach.pso.base.sqrt" class="py-name" href="#" onclick="return doclink('link-2', 'sqrt', 'link-2');">sqrt</a></tt><tt class="py-op">,</tt> <tt class="py-name">argmin</tt><tt class="py-op">,</tt> <tt class="py-name">zeros</tt><tt class="py-op">,</tt> <tt class="py-name">dot</tt> </tt>
<a name="L25"></a><tt class="py-lineno"> 25</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt class="py-name">random</tt> </tt>
<a name="L26"></a><tt class="py-lineno"> 26</tt>  <tt class="py-line"> </tt>
<a name="L27"></a><tt class="py-lineno"> 27</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt id="link-3" class="py-name" targets="Module peach.fuzzy.base=peach.fuzzy.base-module.html,Module peach.ga.base=peach.ga.base-module.html,Module peach.nn.base=peach.nn.base-module.html,Module peach.optm.base=peach.optm.base-module.html,Module peach.pso.base=peach.pso.base-module.html,Module peach.sa.base=peach.sa.base-module.html"><a title="peach.fuzzy.base
peach.ga.base
peach.nn.base
peach.optm.base
peach.pso.base
peach.sa.base" class="py-name" href="#" onclick="return doclink('link-3', 'base', 'link-3');">base</a></tt> <tt class="py-keyword">import</tt> <tt class="py-op">*</tt> </tt>
<a name="L28"></a><tt class="py-lineno"> 28</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt id="link-4" class="py-name" targets="Module peach.nn.af=peach.nn.af-module.html"><a title="peach.nn.af" class="py-name" href="#" onclick="return doclink('link-4', 'af', 'link-4');">af</a></tt> <tt class="py-keyword">import</tt> <tt class="py-op">*</tt> </tt>
<a name="L29"></a><tt class="py-lineno"> 29</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt id="link-5" class="py-name" targets="Module peach.nn.lrules=peach.nn.lrules-module.html"><a title="peach.nn.lrules" class="py-name" href="#" onclick="return doclink('link-5', 'lrules', 'link-5');">lrules</a></tt> <tt class="py-keyword">import</tt> <tt class="py-op">*</tt> </tt>
<a name="L30"></a><tt class="py-lineno"> 30</tt>  <tt class="py-line"> </tt>
<a name="L31"></a><tt class="py-lineno"> 31</tt>  <tt class="py-line">         </tt>
<a name="L32"></a><tt class="py-lineno"> 32</tt>  <tt class="py-line"><tt class="py-comment">################################################################################</tt> </tt>
<a name="FeedForward"></a><div id="FeedForward-def"><a name="L33"></a><tt class="py-lineno"> 33</tt> <a class="py-toggle" href="#" id="FeedForward-toggle" onclick="return toggle('FeedForward');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="peach.nn.nnet.FeedForward-class.html">FeedForward</a><tt class="py-op">(</tt><tt class="py-base-class">list</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="FeedForward-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="FeedForward-expanded"><a name="L34"></a><tt class="py-lineno"> 34</tt>  <tt class="py-line">    <tt class="py-docstring">'''</tt> </tt>
<a name="L35"></a><tt class="py-lineno"> 35</tt>  <tt class="py-line"><tt class="py-docstring">    Classic completely connected neural network.</tt> </tt>
<a name="L36"></a><tt class="py-lineno"> 36</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L37"></a><tt class="py-lineno"> 37</tt>  <tt class="py-line"><tt class="py-docstring">    A feedforward neural network is implemented as a list of layers, each layer</tt> </tt>
<a name="L38"></a><tt class="py-lineno"> 38</tt>  <tt class="py-line"><tt class="py-docstring">    being a ``Layer`` object (please consult the documentation on the ``base``</tt> </tt>
<a name="L39"></a><tt class="py-lineno"> 39</tt>  <tt class="py-line"><tt class="py-docstring">    module for more information on layers). The layers are completely connected,</tt> </tt>
<a name="L40"></a><tt class="py-lineno"> 40</tt>  <tt class="py-line"><tt class="py-docstring">    which means that every neuron in one layers is connected to every other</tt> </tt>
<a name="L41"></a><tt class="py-lineno"> 41</tt>  <tt class="py-line"><tt class="py-docstring">    neuron in the following layer.</tt> </tt>
<a name="L42"></a><tt class="py-lineno"> 42</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L43"></a><tt class="py-lineno"> 43</tt>  <tt class="py-line"><tt class="py-docstring">    There is a number of learning methods that are already implemented, but in</tt> </tt>
<a name="L44"></a><tt class="py-lineno"> 44</tt>  <tt class="py-line"><tt class="py-docstring">    general, any learning class derived from ``FFLearning`` can be used. No</tt> </tt>
<a name="L45"></a><tt class="py-lineno"> 45</tt>  <tt class="py-line"><tt class="py-docstring">    other kind of learning can be used. Please, consult the documentation on the</tt> </tt>
<a name="L46"></a><tt class="py-lineno"> 46</tt>  <tt class="py-line"><tt class="py-docstring">    ``lrules`` (*learning rules*) module.</tt> </tt>
<a name="L47"></a><tt class="py-lineno"> 47</tt>  <tt class="py-line"><tt class="py-docstring">    '''</tt> </tt>
<a name="FeedForward.__init__"></a><div id="FeedForward.__init__-def"><a name="L48"></a><tt class="py-lineno"> 48</tt> <a class="py-toggle" href="#" id="FeedForward.__init__-toggle" onclick="return toggle('FeedForward.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.FeedForward-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">layers</tt><tt class="py-op">,</tt> <tt class="py-param">phi</tt><tt class="py-op">=</tt><tt id="link-6" class="py-name" targets="Class peach.nn.af.Linear=peach.nn.af.Linear-class.html"><a title="peach.nn.af.Linear" class="py-name" href="#" onclick="return doclink('link-6', 'Linear', 'link-6');">Linear</a></tt><tt class="py-op">,</tt> <tt class="py-param">lrule</tt><tt class="py-op">=</tt><tt id="link-7" class="py-name" targets="Class peach.nn.lrules.BackPropagation=peach.nn.lrules.BackPropagation-class.html"><a title="peach.nn.lrules.BackPropagation" class="py-name" href="#" onclick="return doclink('link-7', 'BackPropagation', 'link-7');">BackPropagation</a></tt><tt class="py-op">,</tt> <tt class="py-param">bias</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="FeedForward.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="FeedForward.__init__-expanded"><a name="L49"></a><tt class="py-lineno"> 49</tt>  <tt class="py-line">        <tt class="py-docstring">'''</tt> </tt>
<a name="L50"></a><tt class="py-lineno"> 50</tt>  <tt class="py-line"><tt class="py-docstring">        Initializes a feedforward neural network.</tt> </tt>
<a name="L51"></a><tt class="py-lineno"> 51</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L52"></a><tt class="py-lineno"> 52</tt>  <tt class="py-line"><tt class="py-docstring">        A feedforward network is implemented as a list of layers, completely</tt> </tt>
<a name="L53"></a><tt class="py-lineno"> 53</tt>  <tt class="py-line"><tt class="py-docstring">        connected.</tt> </tt>
<a name="L54"></a><tt class="py-lineno"> 54</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L55"></a><tt class="py-lineno"> 55</tt>  <tt class="py-line"><tt class="py-docstring">        :Parameters:</tt> </tt>
<a name="L56"></a><tt class="py-lineno"> 56</tt>  <tt class="py-line"><tt class="py-docstring">          layers</tt> </tt>
<a name="L57"></a><tt class="py-lineno"> 57</tt>  <tt class="py-line"><tt class="py-docstring">            A list of integers containing the shape of the network. The first</tt> </tt>
<a name="L58"></a><tt class="py-lineno"> 58</tt>  <tt class="py-line"><tt class="py-docstring">            element of the list is the number of inputs of the network (or, as</tt> </tt>
<a name="L59"></a><tt class="py-lineno"> 59</tt>  <tt class="py-line"><tt class="py-docstring">            somebody prefer, the number of input neurons); the number of outputs</tt> </tt>
<a name="L60"></a><tt class="py-lineno"> 60</tt>  <tt class="py-line"><tt class="py-docstring">            is the number of neurons in the last layer. Thus, at least two</tt> </tt>
<a name="L61"></a><tt class="py-lineno"> 61</tt>  <tt class="py-line"><tt class="py-docstring">            numbers should be given.</tt> </tt>
<a name="L62"></a><tt class="py-lineno"> 62</tt>  <tt class="py-line"><tt class="py-docstring">          phi</tt> </tt>
<a name="L63"></a><tt class="py-lineno"> 63</tt>  <tt class="py-line"><tt class="py-docstring">            The activation functions to be used with each layer of the network.</tt> </tt>
<a name="L64"></a><tt class="py-lineno"> 64</tt>  <tt class="py-line"><tt class="py-docstring">            Please consult the ``Layer`` documentation in the ``base`` module</tt> </tt>
<a name="L65"></a><tt class="py-lineno"> 65</tt>  <tt class="py-line"><tt class="py-docstring">            for more information. This parameter can be a single function or a</tt> </tt>
<a name="L66"></a><tt class="py-lineno"> 66</tt>  <tt class="py-line"><tt class="py-docstring">            list of functions. If only one function is given, then the same</tt> </tt>
<a name="L67"></a><tt class="py-lineno"> 67</tt>  <tt class="py-line"><tt class="py-docstring">            function is used in every layer. If a list of functions is given,</tt> </tt>
<a name="L68"></a><tt class="py-lineno"> 68</tt>  <tt class="py-line"><tt class="py-docstring">            then the layers use the functions in the sequence given. Note that</tt> </tt>
<a name="L69"></a><tt class="py-lineno"> 69</tt>  <tt class="py-line"><tt class="py-docstring">            heterogeneous networks can be created that way. Defaults to</tt> </tt>
<a name="L70"></a><tt class="py-lineno"> 70</tt>  <tt class="py-line"><tt class="py-docstring">            ``Linear``.</tt> </tt>
<a name="L71"></a><tt class="py-lineno"> 71</tt>  <tt class="py-line"><tt class="py-docstring">          lrule</tt> </tt>
<a name="L72"></a><tt class="py-lineno"> 72</tt>  <tt class="py-line"><tt class="py-docstring">            The learning rule used. Only ``FFLearning`` objects (instances of</tt> </tt>
<a name="L73"></a><tt class="py-lineno"> 73</tt>  <tt class="py-line"><tt class="py-docstring">            the class or of the subclasses) are allowed. Defaults to</tt> </tt>
<a name="L74"></a><tt class="py-lineno"> 74</tt>  <tt class="py-line"><tt class="py-docstring">            ``BackPropagation``. Check the ``lrules`` documentation for more</tt> </tt>
<a name="L75"></a><tt class="py-lineno"> 75</tt>  <tt class="py-line"><tt class="py-docstring">            information.</tt> </tt>
<a name="L76"></a><tt class="py-lineno"> 76</tt>  <tt class="py-line"><tt class="py-docstring">          bias</tt> </tt>
<a name="L77"></a><tt class="py-lineno"> 77</tt>  <tt class="py-line"><tt class="py-docstring">            If ``True``, then the neurons are biased.</tt> </tt>
<a name="L78"></a><tt class="py-lineno"> 78</tt>  <tt class="py-line"><tt class="py-docstring">        '''</tt> </tt>
<a name="L79"></a><tt class="py-lineno"> 79</tt>  <tt class="py-line">        <tt class="py-name">list</tt><tt class="py-op">.</tt><tt id="link-8" class="py-name" targets="Method peach.fuzzy.base.FuzzySet.__init__()=peach.fuzzy.base.FuzzySet-class.html#__init__,Method peach.fuzzy.cmeans.FuzzyCMeans.__init__()=peach.fuzzy.cmeans.FuzzyCMeans-class.html#__init__,Method peach.fuzzy.control.Controller.__init__()=peach.fuzzy.control.Controller-class.html#__init__,Method peach.fuzzy.control.Parametric.__init__()=peach.fuzzy.control.Parametric-class.html#__init__,Method peach.fuzzy.mf.Bell.__init__()=peach.fuzzy.mf.Bell-class.html#__init__,Method peach.fuzzy.mf.DecreasingRamp.__init__()=peach.fuzzy.mf.DecreasingRamp-class.html#__init__,Method peach.fuzzy.mf.DecreasingSigmoid.__init__()=peach.fuzzy.mf.DecreasingSigmoid-class.html#__init__,Method peach.fuzzy.mf.Gaussian.__init__()=peach.fuzzy.mf.Gaussian-class.html#__init__,Method peach.fuzzy.mf.IncreasingRamp.__init__()=peach.fuzzy.mf.IncreasingRamp-class.html#__init__,Method peach.fuzzy.mf.IncreasingSigmoid.__init__()=peach.fuzzy.mf.IncreasingSigmoid-class.html#__init__,Method peach.fuzzy.mf.Membership.__init__()=peach.fuzzy.mf.Membership-class.html#__init__,Method peach.fuzzy.mf.RaisedCosine.__init__()=peach.fuzzy.mf.RaisedCosine-class.html#__init__,Method peach.fuzzy.mf.Smf.__init__()=peach.fuzzy.mf.Smf-class.html#__init__,Method peach.fuzzy.mf.Trapezoid.__init__()=peach.fuzzy.mf.Trapezoid-class.html#__init__,Method peach.fuzzy.mf.Triangle.__init__()=peach.fuzzy.mf.Triangle-class.html#__init__,Method peach.fuzzy.mf.Zmf.__init__()=peach.fuzzy.mf.Zmf-class.html#__init__,Method peach.ga.base.GeneticAlgorithm.__init__()=peach.ga.base.GeneticAlgorithm-class.html#__init__,Method peach.ga.chromosome.Chromosome.__init__()=peach.ga.chromosome.Chromosome-class.html#__init__,Method peach.ga.crossover.OnePoint.__init__()=peach.ga.crossover.OnePoint-class.html#__init__,Method peach.ga.crossover.TwoPoint.__init__()=peach.ga.crossover.TwoPoint-class.html#__init__,Method peach.ga.crossover.Uniform.__init__()=peach.ga.crossover.Uniform-class.html#__init__,Method peach.ga.fitness.Fitness.__init__()=peach.ga.fitness.Fitness-class.html#__init__,Method peach.ga.fitness.Ranking.__init__()=peach.ga.fitness.Ranking-class.html#__init__,Method peach.ga.mutation.BitToBit.__init__()=peach.ga.mutation.BitToBit-class.html#__init__,Method peach.nn.af.Activation.__init__()=peach.nn.af.Activation-class.html#__init__,Method peach.nn.af.ArcTan.__init__()=peach.nn.af.ArcTan-class.html#__init__,Method peach.nn.af.Gaussian.__init__()=peach.nn.af.Gaussian-class.html#__init__,Method peach.nn.af.Linear.__init__()=peach.nn.af.Linear-class.html#__init__,Method peach.nn.af.Ramp.__init__()=peach.nn.af.Ramp-class.html#__init__,Method peach.nn.af.Sigmoid.__init__()=peach.nn.af.Sigmoid-class.html#__init__,Method peach.nn.af.Signum.__init__()=peach.nn.af.Signum-class.html#__init__,Method peach.nn.af.TanH.__init__()=peach.nn.af.TanH-class.html#__init__,Method peach.nn.af.Threshold.__init__()=peach.nn.af.Threshold-class.html#__init__,Method peach.nn.base.Layer.__init__()=peach.nn.base.Layer-class.html#__init__,Method peach.nn.kmeans.KMeans.__init__()=peach.nn.kmeans.KMeans-class.html#__init__,Method peach.nn.lrules.BackPropagation.__init__()=peach.nn.lrules.BackPropagation-class.html#__init__,Method peach.nn.lrules.Competitive.__init__()=peach.nn.lrules.Competitive-class.html#__init__,Method peach.nn.lrules.Cooperative.__init__()=peach.nn.lrules.Cooperative-class.html#__init__,Method peach.nn.lrules.LMS.__init__()=peach.nn.lrules.LMS-class.html#__init__,Method peach.nn.lrules.WinnerTakesAll.__init__()=peach.nn.lrules.WinnerTakesAll-class.html#__init__,Method peach.nn.mem.Hopfield.__init__()=peach.nn.mem.Hopfield-class.html#__init__,Method peach.nn.nnet.FeedForward.__init__()=peach.nn.nnet.FeedForward-class.html#__init__,Method peach.nn.nnet.GRNN.__init__()=peach.nn.nnet.GRNN-class.html#__init__,Method peach.nn.nnet.PNN.__init__()=peach.nn.nnet.PNN-class.html#__init__,Method peach.nn.nnet.SOM.__init__()=peach.nn.nnet.SOM-class.html#__init__,Method peach.nn.rbfn.RBFN.__init__()=peach.nn.rbfn.RBFN-class.html#__init__,Method peach.optm.base.Optimizer.__init__()=peach.optm.base.Optimizer-class.html#__init__,Method peach.optm.linear.Direct1D.__init__()=peach.optm.linear.Direct1D-class.html#__init__,Method peach.optm.linear.Fibonacci.__init__()=peach.optm.linear.Fibonacci-class.html#__init__,Method peach.optm.linear.GoldenRule.__init__()=peach.optm.linear.GoldenRule-class.html#__init__,Method peach.optm.linear.Interpolation.__init__()=peach.optm.linear.Interpolation-class.html#__init__,Method peach.optm.multivar.Direct.__init__()=peach.optm.multivar.Direct-class.html#__init__,Method peach.optm.multivar.Gradient.__init__()=peach.optm.multivar.Gradient-class.html#__init__,Method peach.optm.multivar.MomentumGradient.__init__()=peach.optm.multivar.MomentumGradient-class.html#__init__,Method peach.optm.multivar.Newton.__init__()=peach.optm.multivar.Newton-class.html#__init__,Method peach.optm.quasinewton.BFGS.__init__()=peach.optm.quasinewton.BFGS-class.html#__init__,Method peach.optm.quasinewton.DFP.__init__()=peach.optm.quasinewton.DFP-class.html#__init__,Method peach.optm.quasinewton.SR1.__init__()=peach.optm.quasinewton.SR1-class.html#__init__,Method peach.optm.stochastic.CrossEntropy.__init__()=peach.optm.stochastic.CrossEntropy-class.html#__init__,Method peach.pso.acc.Accelerator.__init__()=peach.pso.acc.Accelerator-class.html#__init__,Method peach.pso.acc.StandardPSO.__init__()=peach.pso.acc.StandardPSO-class.html#__init__,Method peach.pso.base.ParticleSwarmOptimizer.__init__()=peach.pso.base.ParticleSwarmOptimizer-class.html#__init__,Method peach.sa.base.BinarySA.__init__()=peach.sa.base.BinarySA-class.html#__init__,Method peach.sa.base.ContinuousSA.__init__()=peach.sa.base.ContinuousSA-class.html#__init__,Method peach.sa.neighbor.BinaryNeighbor.__init__()=peach.sa.neighbor.BinaryNeighbor-class.html#__init__,Method peach.sa.neighbor.ContinuousNeighbor.__init__()=peach.sa.neighbor.ContinuousNeighbor-class.html#__init__,Method peach.sa.neighbor.GaussianNeighbor.__init__()=peach.sa.neighbor.GaussianNeighbor-class.html#__init__,Method peach.sa.neighbor.InvertBitsNeighbor.__init__()=peach.sa.neighbor.InvertBitsNeighbor-class.html#__init__,Method peach.sa.neighbor.UniformNeighbor.__init__()=peach.sa.neighbor.UniformNeighbor-class.html#__init__"><a title="peach.fuzzy.base.FuzzySet.__init__
peach.fuzzy.cmeans.FuzzyCMeans.__init__
peach.fuzzy.control.Controller.__init__
peach.fuzzy.control.Parametric.__init__
peach.fuzzy.mf.Bell.__init__
peach.fuzzy.mf.DecreasingRamp.__init__
peach.fuzzy.mf.DecreasingSigmoid.__init__
peach.fuzzy.mf.Gaussian.__init__
peach.fuzzy.mf.IncreasingRamp.__init__
peach.fuzzy.mf.IncreasingSigmoid.__init__
peach.fuzzy.mf.Membership.__init__
peach.fuzzy.mf.RaisedCosine.__init__
peach.fuzzy.mf.Smf.__init__
peach.fuzzy.mf.Trapezoid.__init__
peach.fuzzy.mf.Triangle.__init__
peach.fuzzy.mf.Zmf.__init__
peach.ga.base.GeneticAlgorithm.__init__
peach.ga.chromosome.Chromosome.__init__
peach.ga.crossover.OnePoint.__init__
peach.ga.crossover.TwoPoint.__init__
peach.ga.crossover.Uniform.__init__
peach.ga.fitness.Fitness.__init__
peach.ga.fitness.Ranking.__init__
peach.ga.mutation.BitToBit.__init__
peach.nn.af.Activation.__init__
peach.nn.af.ArcTan.__init__
peach.nn.af.Gaussian.__init__
peach.nn.af.Linear.__init__
peach.nn.af.Ramp.__init__
peach.nn.af.Sigmoid.__init__
peach.nn.af.Signum.__init__
peach.nn.af.TanH.__init__
peach.nn.af.Threshold.__init__
peach.nn.base.Layer.__init__
peach.nn.kmeans.KMeans.__init__
peach.nn.lrules.BackPropagation.__init__
peach.nn.lrules.Competitive.__init__
peach.nn.lrules.Cooperative.__init__
peach.nn.lrules.LMS.__init__
peach.nn.lrules.WinnerTakesAll.__init__
peach.nn.mem.Hopfield.__init__
peach.nn.nnet.FeedForward.__init__
peach.nn.nnet.GRNN.__init__
peach.nn.nnet.PNN.__init__
peach.nn.nnet.SOM.__init__
peach.nn.rbfn.RBFN.__init__
peach.optm.base.Optimizer.__init__
peach.optm.linear.Direct1D.__init__
peach.optm.linear.Fibonacci.__init__
peach.optm.linear.GoldenRule.__init__
peach.optm.linear.Interpolation.__init__
peach.optm.multivar.Direct.__init__
peach.optm.multivar.Gradient.__init__
peach.optm.multivar.MomentumGradient.__init__
peach.optm.multivar.Newton.__init__
peach.optm.quasinewton.BFGS.__init__
peach.optm.quasinewton.DFP.__init__
peach.optm.quasinewton.SR1.__init__
peach.optm.stochastic.CrossEntropy.__init__
peach.pso.acc.Accelerator.__init__
peach.pso.acc.StandardPSO.__init__
peach.pso.base.ParticleSwarmOptimizer.__init__
peach.sa.base.BinarySA.__init__
peach.sa.base.ContinuousSA.__init__
peach.sa.neighbor.BinaryNeighbor.__init__
peach.sa.neighbor.ContinuousNeighbor.__init__
peach.sa.neighbor.GaussianNeighbor.__init__
peach.sa.neighbor.InvertBitsNeighbor.__init__
peach.sa.neighbor.UniformNeighbor.__init__" class="py-name" href="#" onclick="return doclink('link-8', '__init__', 'link-8');">__init__</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-op">[</tt> <tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L80"></a><tt class="py-lineno"> 80</tt>  <tt class="py-line">        <tt class="py-name">layers</tt> <tt class="py-op">=</tt> <tt class="py-name">list</tt><tt class="py-op">(</tt><tt class="py-name">layers</tt><tt class="py-op">)</tt> </tt>
<a name="L81"></a><tt class="py-lineno"> 81</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">m</tt> <tt class="py-keyword">in</tt> <tt class="py-name">zip</tt><tt class="py-op">(</tt><tt class="py-name">layers</tt><tt class="py-op">[</tt><tt class="py-op">:</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-name">layers</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-op">]</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L82"></a><tt class="py-lineno"> 82</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt id="link-9" class="py-name" targets="Class peach.nn.base.Layer=peach.nn.base.Layer-class.html"><a title="peach.nn.base.Layer" class="py-name" href="#" onclick="return doclink('link-9', 'Layer', 'link-9');">Layer</a></tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">m</tt><tt class="py-op">,</tt> <tt class="py-name">n</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt id="link-10" class="py-name" targets="Variable peach.nn.base.Layer.bias=peach.nn.base.Layer-class.html#bias,Variable peach.nn.nnet.FeedForward.bias=peach.nn.nnet.FeedForward-class.html#bias"><a title="peach.nn.base.Layer.bias
peach.nn.nnet.FeedForward.bias" class="py-name" href="#" onclick="return doclink('link-10', 'bias', 'link-10');">bias</a></tt><tt class="py-op">=</tt><tt id="link-11" class="py-name"><a title="peach.nn.base.Layer.bias
peach.nn.nnet.FeedForward.bias" class="py-name" href="#" onclick="return doclink('link-11', 'bias', 'link-10');">bias</a></tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L83"></a><tt class="py-lineno"> 83</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-12" class="py-name" targets="Variable peach.nn.base.Layer.phi=peach.nn.base.Layer-class.html#phi,Variable peach.nn.nnet.FeedForward.phi=peach.nn.nnet.FeedForward-class.html#phi,Variable peach.nn.rbfn.RBFN.phi=peach.nn.rbfn.RBFN-class.html#phi"><a title="peach.nn.base.Layer.phi
peach.nn.nnet.FeedForward.phi
peach.nn.rbfn.RBFN.phi" class="py-name" href="#" onclick="return doclink('link-12', 'phi', 'link-12');">phi</a></tt> <tt class="py-op">=</tt> <tt id="link-13" class="py-name"><a title="peach.nn.base.Layer.phi
peach.nn.nnet.FeedForward.phi
peach.nn.rbfn.RBFN.phi" class="py-name" href="#" onclick="return doclink('link-13', 'phi', 'link-12');">phi</a></tt> </tt>
<a name="L84"></a><tt class="py-lineno"> 84</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__n</tt> <tt class="py-op">=</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
<a name="L85"></a><tt class="py-lineno"> 85</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__lrule</tt> <tt class="py-op">=</tt> <tt class="py-name">lrule</tt> </tt>
<a name="L86"></a><tt class="py-lineno"> 86</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">lrule</tt><tt class="py-op">,</tt> <tt id="link-14" class="py-name" targets="Class peach.nn.lrules.FFLearning=peach.nn.lrules.FFLearning-class.html"><a title="peach.nn.lrules.FFLearning" class="py-name" href="#" onclick="return doclink('link-14', 'FFLearning', 'link-14');">FFLearning</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L87"></a><tt class="py-lineno"> 87</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__lrule</tt> <tt class="py-op">=</tt> <tt class="py-name">lrule</tt> </tt>
<a name="L88"></a><tt class="py-lineno"> 88</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L89"></a><tt class="py-lineno"> 89</tt>  <tt class="py-line">            <tt class="py-keyword">try</tt><tt class="py-op">:</tt> </tt>
<a name="L90"></a><tt class="py-lineno"> 90</tt>  <tt class="py-line">                <tt class="py-name">issubclass</tt><tt class="py-op">(</tt><tt class="py-name">lrule</tt><tt class="py-op">,</tt> <tt id="link-15" class="py-name"><a title="peach.nn.lrules.FFLearning" class="py-name" href="#" onclick="return doclink('link-15', 'FFLearning', 'link-14');">FFLearning</a></tt><tt class="py-op">)</tt> </tt>
<a name="L91"></a><tt class="py-lineno"> 91</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__lrule</tt> <tt class="py-op">=</tt> <tt class="py-name">lrule</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L92"></a><tt class="py-lineno"> 92</tt>  <tt class="py-line">            <tt class="py-keyword">except</tt> <tt class="py-name">TypeError</tt><tt class="py-op">:</tt> </tt>
<a name="L93"></a><tt class="py-lineno"> 93</tt>  <tt class="py-line">                <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">,</tt> <tt class="py-string">'uncompatible learning rule'</tt> </tt>
</div><a name="L94"></a><tt class="py-lineno"> 94</tt>  <tt class="py-line"> </tt>
<a name="L95"></a><tt class="py-lineno"> 95</tt>  <tt class="py-line"> </tt>
<a name="FeedForward.__getnlayers"></a><div id="FeedForward.__getnlayers-def"><a name="L96"></a><tt class="py-lineno"> 96</tt> <a class="py-toggle" href="#" id="FeedForward.__getnlayers-toggle" onclick="return toggle('FeedForward.__getnlayers');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.FeedForward-class.html#__getnlayers">__getnlayers</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="FeedForward.__getnlayers-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="FeedForward.__getnlayers-expanded"><a name="L97"></a><tt class="py-lineno"> 97</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__n</tt> </tt>
</div><a name="L98"></a><tt class="py-lineno"> 98</tt>  <tt class="py-line">    <tt id="link-16" class="py-name" targets="Variable peach.nn.nnet.FeedForward.nlayers=peach.nn.nnet.FeedForward-class.html#nlayers"><a title="peach.nn.nnet.FeedForward.nlayers" class="py-name" href="#" onclick="return doclink('link-16', 'nlayers', 'link-16');">nlayers</a></tt> <tt class="py-op">=</tt> <tt class="py-name">property</tt><tt class="py-op">(</tt><tt id="link-17" class="py-name" targets="Method peach.nn.nnet.FeedForward.__getnlayers()=peach.nn.nnet.FeedForward-class.html#__getnlayers"><a title="peach.nn.nnet.FeedForward.__getnlayers" class="py-name" href="#" onclick="return doclink('link-17', '__getnlayers', 'link-17');">__getnlayers</a></tt><tt class="py-op">,</tt> <tt class="py-name">None</tt><tt class="py-op">)</tt> </tt>
<a name="L99"></a><tt class="py-lineno"> 99</tt>  <tt class="py-line">    <tt class="py-string">'''Number of layers of the neural network. Not writable.'''</tt> </tt>
<a name="L100"></a><tt class="py-lineno">100</tt>  <tt class="py-line"> </tt>
<a name="L101"></a><tt class="py-lineno">101</tt>  <tt class="py-line"> </tt>
<a name="FeedForward.__getbias"></a><div id="FeedForward.__getbias-def"><a name="L102"></a><tt class="py-lineno">102</tt> <a class="py-toggle" href="#" id="FeedForward.__getbias-toggle" onclick="return toggle('FeedForward.__getbias');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.FeedForward-class.html#__getbias">__getbias</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="FeedForward.__getbias-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="FeedForward.__getbias-expanded"><a name="L103"></a><tt class="py-lineno">103</tt>  <tt class="py-line">        <tt class="py-name">r</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt> <tt class="py-op">]</tt> </tt>
<a name="L104"></a><tt class="py-lineno">104</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">l</tt> <tt class="py-keyword">in</tt> <tt class="py-name">self</tt><tt class="py-op">:</tt> </tt>
<a name="L105"></a><tt class="py-lineno">105</tt>  <tt class="py-line">            <tt class="py-name">r</tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt class="py-name">l</tt><tt class="py-op">.</tt><tt id="link-18" class="py-name"><a title="peach.nn.base.Layer.bias
peach.nn.nnet.FeedForward.bias" class="py-name" href="#" onclick="return doclink('link-18', 'bias', 'link-10');">bias</a></tt><tt class="py-op">)</tt> </tt>
<a name="L106"></a><tt class="py-lineno">106</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">tuple</tt><tt class="py-op">(</tt><tt class="py-name">r</tt><tt class="py-op">)</tt> </tt>
</div><a name="L107"></a><tt class="py-lineno">107</tt>  <tt class="py-line">    <tt id="link-19" class="py-name"><a title="peach.nn.base.Layer.bias
peach.nn.nnet.FeedForward.bias" class="py-name" href="#" onclick="return doclink('link-19', 'bias', 'link-10');">bias</a></tt> <tt class="py-op">=</tt> <tt class="py-name">property</tt><tt class="py-op">(</tt><tt id="link-20" class="py-name" targets="Method peach.nn.base.Layer.__getbias()=peach.nn.base.Layer-class.html#__getbias,Method peach.nn.nnet.FeedForward.__getbias()=peach.nn.nnet.FeedForward-class.html#__getbias"><a title="peach.nn.base.Layer.__getbias
peach.nn.nnet.FeedForward.__getbias" class="py-name" href="#" onclick="return doclink('link-20', '__getbias', 'link-20');">__getbias</a></tt><tt class="py-op">,</tt> <tt class="py-name">None</tt><tt class="py-op">)</tt> </tt>
<a name="L108"></a><tt class="py-lineno">108</tt>  <tt class="py-line">    <tt class="py-string">'''A tuple containing the bias of each layer. Not writable.'''</tt> </tt>
<a name="L109"></a><tt class="py-lineno">109</tt>  <tt class="py-line"> </tt>
<a name="L110"></a><tt class="py-lineno">110</tt>  <tt class="py-line"> </tt>
<a name="FeedForward.__gety"></a><div id="FeedForward.__gety-def"><a name="L111"></a><tt class="py-lineno">111</tt> <a class="py-toggle" href="#" id="FeedForward.__gety-toggle" onclick="return toggle('FeedForward.__gety');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.FeedForward-class.html#__gety">__gety</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="FeedForward.__gety-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="FeedForward.__gety-expanded"><a name="L112"></a><tt class="py-lineno">112</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">[</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt id="link-21" class="py-name" targets="Variable peach.fuzzy.control.Controller.y=peach.fuzzy.control.Controller-class.html#y,Variable peach.nn.base.Layer.y=peach.nn.base.Layer-class.html#y,Variable peach.nn.nnet.FeedForward.y=peach.nn.nnet.FeedForward-class.html#y,Variable peach.nn.nnet.SOM.y=peach.nn.nnet.SOM-class.html#y,Variable peach.nn.rbfn.RBFN.y=peach.nn.rbfn.RBFN-class.html#y"><a title="peach.fuzzy.control.Controller.y
peach.nn.base.Layer.y
peach.nn.nnet.FeedForward.y
peach.nn.nnet.SOM.y
peach.nn.rbfn.RBFN.y" class="py-name" href="#" onclick="return doclink('link-21', 'y', 'link-21');">y</a></tt> </tt>
</div><a name="L113"></a><tt class="py-lineno">113</tt>  <tt class="py-line">    <tt id="link-22" class="py-name"><a title="peach.fuzzy.control.Controller.y
peach.nn.base.Layer.y
peach.nn.nnet.FeedForward.y
peach.nn.nnet.SOM.y
peach.nn.rbfn.RBFN.y" class="py-name" href="#" onclick="return doclink('link-22', 'y', 'link-21');">y</a></tt> <tt class="py-op">=</tt> <tt class="py-name">property</tt><tt class="py-op">(</tt><tt id="link-23" class="py-name" targets="Method peach.fuzzy.control.Controller.__gety()=peach.fuzzy.control.Controller-class.html#__gety,Method peach.nn.base.Layer.__gety()=peach.nn.base.Layer-class.html#__gety,Method peach.nn.nnet.FeedForward.__gety()=peach.nn.nnet.FeedForward-class.html#__gety,Method peach.nn.nnet.SOM.__gety()=peach.nn.nnet.SOM-class.html#__gety,Method peach.nn.rbfn.RBFN.__gety()=peach.nn.rbfn.RBFN-class.html#__gety"><a title="peach.fuzzy.control.Controller.__gety
peach.nn.base.Layer.__gety
peach.nn.nnet.FeedForward.__gety
peach.nn.nnet.SOM.__gety
peach.nn.rbfn.RBFN.__gety" class="py-name" href="#" onclick="return doclink('link-23', '__gety', 'link-23');">__gety</a></tt><tt class="py-op">,</tt> <tt class="py-name">None</tt><tt class="py-op">)</tt> </tt>
<a name="L114"></a><tt class="py-lineno">114</tt>  <tt class="py-line">    <tt class="py-string">'''A list of activation values for each neuron in the last layer of the</tt> </tt>
<a name="L115"></a><tt class="py-lineno">115</tt>  <tt class="py-line"><tt class="py-string">    network, ie., the answer of the network. This property is available only</tt> </tt>
<a name="L116"></a><tt class="py-lineno">116</tt>  <tt class="py-line"><tt class="py-string">    after the network is fed some input.'''</tt> </tt>
<a name="L117"></a><tt class="py-lineno">117</tt>  <tt class="py-line"> </tt>
<a name="L118"></a><tt class="py-lineno">118</tt>  <tt class="py-line"> </tt>
<a name="FeedForward.__getphi"></a><div id="FeedForward.__getphi-def"><a name="L119"></a><tt class="py-lineno">119</tt> <a class="py-toggle" href="#" id="FeedForward.__getphi-toggle" onclick="return toggle('FeedForward.__getphi');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.FeedForward-class.html#__getphi">__getphi</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="FeedForward.__getphi-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="FeedForward.__getphi-expanded"><a name="L120"></a><tt class="py-lineno">120</tt>  <tt class="py-line">        <tt class="py-name">r</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt> <tt class="py-op">]</tt> </tt>
<a name="L121"></a><tt class="py-lineno">121</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">l</tt> <tt class="py-keyword">in</tt> <tt class="py-name">self</tt><tt class="py-op">:</tt> </tt>
<a name="L122"></a><tt class="py-lineno">122</tt>  <tt class="py-line">            <tt class="py-name">r</tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt class="py-name">l</tt><tt class="py-op">.</tt><tt id="link-24" class="py-name"><a title="peach.nn.base.Layer.phi
peach.nn.nnet.FeedForward.phi
peach.nn.rbfn.RBFN.phi" class="py-name" href="#" onclick="return doclink('link-24', 'phi', 'link-12');">phi</a></tt><tt class="py-op">)</tt> </tt>
<a name="L123"></a><tt class="py-lineno">123</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">tuple</tt><tt class="py-op">(</tt><tt class="py-name">r</tt><tt class="py-op">)</tt> </tt>
</div><a name="FeedForward.__setphi"></a><div id="FeedForward.__setphi-def"><a name="L124"></a><tt class="py-lineno">124</tt> <a class="py-toggle" href="#" id="FeedForward.__setphi-toggle" onclick="return toggle('FeedForward.__setphi');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.FeedForward-class.html#__setphi">__setphi</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">phis</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="FeedForward.__setphi-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="FeedForward.__setphi-expanded"><a name="L125"></a><tt class="py-lineno">125</tt>  <tt class="py-line">        <tt class="py-keyword">try</tt><tt class="py-op">:</tt> </tt>
<a name="L126"></a><tt class="py-lineno">126</tt>  <tt class="py-line">            <tt class="py-name">phis</tt> <tt class="py-op">=</tt> <tt class="py-name">tuple</tt><tt class="py-op">(</tt><tt class="py-name">phis</tt><tt class="py-op">)</tt> </tt>
<a name="L127"></a><tt class="py-lineno">127</tt>  <tt class="py-line">            <tt class="py-keyword">for</tt> <tt class="py-name">w</tt><tt class="py-op">,</tt> <tt id="link-25" class="py-name" targets="Variable peach.nn.base.Layer.v=peach.nn.base.Layer-class.html#v"><a title="peach.nn.base.Layer.v" class="py-name" href="#" onclick="return doclink('link-25', 'v', 'link-25');">v</a></tt> <tt class="py-keyword">in</tt> <tt class="py-name">zip</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-name">phis</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L128"></a><tt class="py-lineno">128</tt>  <tt class="py-line">                <tt class="py-name">w</tt><tt class="py-op">.</tt><tt id="link-26" class="py-name"><a title="peach.nn.base.Layer.phi
peach.nn.nnet.FeedForward.phi
peach.nn.rbfn.RBFN.phi" class="py-name" href="#" onclick="return doclink('link-26', 'phi', 'link-12');">phi</a></tt> <tt class="py-op">=</tt> <tt id="link-27" class="py-name"><a title="peach.nn.base.Layer.v" class="py-name" href="#" onclick="return doclink('link-27', 'v', 'link-25');">v</a></tt> </tt>
<a name="L129"></a><tt class="py-lineno">129</tt>  <tt class="py-line">        <tt class="py-keyword">except</tt> <tt class="py-name">TypeError</tt><tt class="py-op">:</tt> </tt>
<a name="L130"></a><tt class="py-lineno">130</tt>  <tt class="py-line">            <tt class="py-keyword">for</tt> <tt class="py-name">w</tt> <tt class="py-keyword">in</tt> <tt class="py-name">self</tt><tt class="py-op">:</tt> </tt>
<a name="L131"></a><tt class="py-lineno">131</tt>  <tt class="py-line">                <tt class="py-name">w</tt><tt class="py-op">.</tt><tt id="link-28" class="py-name"><a title="peach.nn.base.Layer.phi
peach.nn.nnet.FeedForward.phi
peach.nn.rbfn.RBFN.phi" class="py-name" href="#" onclick="return doclink('link-28', 'phi', 'link-12');">phi</a></tt> <tt class="py-op">=</tt> <tt class="py-name">phis</tt> </tt>
</div><a name="L132"></a><tt class="py-lineno">132</tt>  <tt class="py-line">    <tt id="link-29" class="py-name"><a title="peach.nn.base.Layer.phi
peach.nn.nnet.FeedForward.phi
peach.nn.rbfn.RBFN.phi" class="py-name" href="#" onclick="return doclink('link-29', 'phi', 'link-12');">phi</a></tt> <tt class="py-op">=</tt> <tt class="py-name">property</tt><tt class="py-op">(</tt><tt id="link-30" class="py-name" targets="Method peach.nn.base.Layer.__getphi()=peach.nn.base.Layer-class.html#__getphi,Method peach.nn.nnet.FeedForward.__getphi()=peach.nn.nnet.FeedForward-class.html#__getphi,Method peach.nn.rbfn.RBFN.__getphi()=peach.nn.rbfn.RBFN-class.html#__getphi"><a title="peach.nn.base.Layer.__getphi
peach.nn.nnet.FeedForward.__getphi
peach.nn.rbfn.RBFN.__getphi" class="py-name" href="#" onclick="return doclink('link-30', '__getphi', 'link-30');">__getphi</a></tt><tt class="py-op">,</tt> <tt id="link-31" class="py-name" targets="Method peach.nn.base.Layer.__setphi()=peach.nn.base.Layer-class.html#__setphi,Method peach.nn.nnet.FeedForward.__setphi()=peach.nn.nnet.FeedForward-class.html#__setphi,Method peach.nn.rbfn.RBFN.__setphi()=peach.nn.rbfn.RBFN-class.html#__setphi"><a title="peach.nn.base.Layer.__setphi
peach.nn.nnet.FeedForward.__setphi
peach.nn.rbfn.RBFN.__setphi" class="py-name" href="#" onclick="return doclink('link-31', '__setphi', 'link-31');">__setphi</a></tt><tt class="py-op">)</tt> </tt>
<a name="L133"></a><tt class="py-lineno">133</tt>  <tt class="py-line">    <tt class="py-string">'''Activation functions for every layer in the network. It is a list of</tt> </tt>
<a name="L134"></a><tt class="py-lineno">134</tt>  <tt class="py-line"><tt class="py-string">    ``Activation`` objects, but can be set with only one function. In this case,</tt> </tt>
<a name="L135"></a><tt class="py-lineno">135</tt>  <tt class="py-line"><tt class="py-string">    the same function is used for every layer.'''</tt> </tt>
<a name="L136"></a><tt class="py-lineno">136</tt>  <tt class="py-line"> </tt>
<a name="L137"></a><tt class="py-lineno">137</tt>  <tt class="py-line"> </tt>
<a name="FeedForward.__call__"></a><div id="FeedForward.__call__-def"><a name="L138"></a><tt class="py-lineno">138</tt> <a class="py-toggle" href="#" id="FeedForward.__call__-toggle" onclick="return toggle('FeedForward.__call__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.FeedForward-class.html#__call__">__call__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">x</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="FeedForward.__call__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="FeedForward.__call__-expanded"><a name="L139"></a><tt class="py-lineno">139</tt>  <tt class="py-line">        <tt class="py-docstring">'''</tt> </tt>
<a name="L140"></a><tt class="py-lineno">140</tt>  <tt class="py-line"><tt class="py-docstring">        The feedforward method of the network.</tt> </tt>
<a name="L141"></a><tt class="py-lineno">141</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L142"></a><tt class="py-lineno">142</tt>  <tt class="py-line"><tt class="py-docstring">        The ``__call__`` interface should be called if the answer of the neuron</tt> </tt>
<a name="L143"></a><tt class="py-lineno">143</tt>  <tt class="py-line"><tt class="py-docstring">        network to a given input vector ``x`` is desired. *This method has</tt> </tt>
<a name="L144"></a><tt class="py-lineno">144</tt>  <tt class="py-line"><tt class="py-docstring">        collateral effects*, so beware. After the calling of this method, the</tt> </tt>
<a name="L145"></a><tt class="py-lineno">145</tt>  <tt class="py-line"><tt class="py-docstring">        ``y`` property is set with the activation potential and the answer of</tt> </tt>
<a name="L146"></a><tt class="py-lineno">146</tt>  <tt class="py-line"><tt class="py-docstring">        the neurons, respectivelly.</tt> </tt>
<a name="L147"></a><tt class="py-lineno">147</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L148"></a><tt class="py-lineno">148</tt>  <tt class="py-line"><tt class="py-docstring">        :Parameters:</tt> </tt>
<a name="L149"></a><tt class="py-lineno">149</tt>  <tt class="py-line"><tt class="py-docstring">          x</tt> </tt>
<a name="L150"></a><tt class="py-lineno">150</tt>  <tt class="py-line"><tt class="py-docstring">            The input vector to the network.</tt> </tt>
<a name="L151"></a><tt class="py-lineno">151</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L152"></a><tt class="py-lineno">152</tt>  <tt class="py-line"><tt class="py-docstring">        :Returns:</tt> </tt>
<a name="L153"></a><tt class="py-lineno">153</tt>  <tt class="py-line"><tt class="py-docstring">          The vector containing the answer of every neuron in the last layer, in</tt> </tt>
<a name="L154"></a><tt class="py-lineno">154</tt>  <tt class="py-line"><tt class="py-docstring">          the respective order.</tt> </tt>
<a name="L155"></a><tt class="py-lineno">155</tt>  <tt class="py-line"><tt class="py-docstring">        '''</tt> </tt>
<a name="L156"></a><tt class="py-lineno">156</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">w</tt> <tt class="py-keyword">in</tt> <tt class="py-name">self</tt><tt class="py-op">:</tt> </tt>
<a name="L157"></a><tt class="py-lineno">157</tt>  <tt class="py-line">            <tt id="link-32" class="py-name" targets="Variable peach.fuzzy.cmeans.FuzzyCMeans.x=peach.fuzzy.cmeans.FuzzyCMeans-class.html#x,Variable peach.optm.linear.Direct1D.x=peach.optm.linear.Direct1D-class.html#x,Variable peach.optm.linear.GoldenRule.x=peach.optm.linear.GoldenRule-class.html#x,Variable peach.optm.linear.Interpolation.x=peach.optm.linear.Interpolation-class.html#x,Variable peach.optm.multivar.Direct.x=peach.optm.multivar.Direct-class.html#x,Variable peach.optm.multivar.Gradient.x=peach.optm.multivar.Gradient-class.html#x,Variable peach.optm.multivar.MomentumGradient.x=peach.optm.multivar.MomentumGradient-class.html#x,Variable peach.optm.multivar.Newton.x=peach.optm.multivar.Newton-class.html#x,Variable peach.optm.quasinewton.DFP.x=peach.optm.quasinewton.DFP-class.html#x,Variable peach.optm.quasinewton.SR1.x=peach.optm.quasinewton.SR1-class.html#x,Variable peach.sa.base.BinarySA.x=peach.sa.base.BinarySA-class.html#x,Variable peach.sa.base.ContinuousSA.x=peach.sa.base.ContinuousSA-class.html#x"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-32', 'x', 'link-32');">x</a></tt> <tt class="py-op">=</tt> <tt class="py-name">w</tt><tt class="py-op">(</tt><tt id="link-33" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-33', 'x', 'link-32');">x</a></tt><tt class="py-op">)</tt> </tt>
<a name="L158"></a><tt class="py-lineno">158</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">[</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt id="link-34" class="py-name"><a title="peach.fuzzy.control.Controller.y
peach.nn.base.Layer.y
peach.nn.nnet.FeedForward.y
peach.nn.nnet.SOM.y
peach.nn.rbfn.RBFN.y" class="py-name" href="#" onclick="return doclink('link-34', 'y', 'link-21');">y</a></tt> </tt>
</div><a name="L159"></a><tt class="py-lineno">159</tt>  <tt class="py-line"> </tt>
<a name="L160"></a><tt class="py-lineno">160</tt>  <tt class="py-line"> </tt>
<a name="FeedForward.learn"></a><div id="FeedForward.learn-def"><a name="L161"></a><tt class="py-lineno">161</tt> <a class="py-toggle" href="#" id="FeedForward.learn-toggle" onclick="return toggle('FeedForward.learn');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.FeedForward-class.html#learn">learn</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">x</tt><tt class="py-op">,</tt> <tt class="py-param">d</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="FeedForward.learn-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="FeedForward.learn-expanded"><a name="L162"></a><tt class="py-lineno">162</tt>  <tt class="py-line">        <tt class="py-docstring">'''</tt> </tt>
<a name="L163"></a><tt class="py-lineno">163</tt>  <tt class="py-line"><tt class="py-docstring">        Applies one example of the training set to the network.</tt> </tt>
<a name="L164"></a><tt class="py-lineno">164</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L165"></a><tt class="py-lineno">165</tt>  <tt class="py-line"><tt class="py-docstring">        Using this method, one iteration of the learning procedure is made with</tt> </tt>
<a name="L166"></a><tt class="py-lineno">166</tt>  <tt class="py-line"><tt class="py-docstring">        the neurons of this network. This method presents one example (not</tt> </tt>
<a name="L167"></a><tt class="py-lineno">167</tt>  <tt class="py-line"><tt class="py-docstring">        necessarilly of a training set) and applies the learning rule over the</tt> </tt>
<a name="L168"></a><tt class="py-lineno">168</tt>  <tt class="py-line"><tt class="py-docstring">        network. The learning rule is defined in the initialization of the</tt> </tt>
<a name="L169"></a><tt class="py-lineno">169</tt>  <tt class="py-line"><tt class="py-docstring">        network, and some are implemented on the ``lrules`` method. New methods</tt> </tt>
<a name="L170"></a><tt class="py-lineno">170</tt>  <tt class="py-line"><tt class="py-docstring">        can be created, consult the ``lrules`` documentation but, for</tt> </tt>
<a name="L171"></a><tt class="py-lineno">171</tt>  <tt class="py-line"><tt class="py-docstring">        ``FeedForward`` instances, only ``FFLearning`` learning is allowed.</tt> </tt>
<a name="L172"></a><tt class="py-lineno">172</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L173"></a><tt class="py-lineno">173</tt>  <tt class="py-line"><tt class="py-docstring">        Also, notice that *this method only applies the learning method!* The</tt> </tt>
<a name="L174"></a><tt class="py-lineno">174</tt>  <tt class="py-line"><tt class="py-docstring">        network should be fed with the same input vector before trying to learn</tt> </tt>
<a name="L175"></a><tt class="py-lineno">175</tt>  <tt class="py-line"><tt class="py-docstring">        anything first. Consult the ``feed`` and ``train`` methods below for</tt> </tt>
<a name="L176"></a><tt class="py-lineno">176</tt>  <tt class="py-line"><tt class="py-docstring">        more ways to train a network.</tt> </tt>
<a name="L177"></a><tt class="py-lineno">177</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L178"></a><tt class="py-lineno">178</tt>  <tt class="py-line"><tt class="py-docstring">        :Parameters:</tt> </tt>
<a name="L179"></a><tt class="py-lineno">179</tt>  <tt class="py-line"><tt class="py-docstring">          x</tt> </tt>
<a name="L180"></a><tt class="py-lineno">180</tt>  <tt class="py-line"><tt class="py-docstring">            Input vector of the example. It should be a column vector of the</tt> </tt>
<a name="L181"></a><tt class="py-lineno">181</tt>  <tt class="py-line"><tt class="py-docstring">            correct dimension, that is, the number of input neurons.</tt> </tt>
<a name="L182"></a><tt class="py-lineno">182</tt>  <tt class="py-line"><tt class="py-docstring">          d</tt> </tt>
<a name="L183"></a><tt class="py-lineno">183</tt>  <tt class="py-line"><tt class="py-docstring">            The desired answer of the network for this particular input vector.</tt> </tt>
<a name="L184"></a><tt class="py-lineno">184</tt>  <tt class="py-line"><tt class="py-docstring">            Notice that the desired answer should have the same dimension of the</tt> </tt>
<a name="L185"></a><tt class="py-lineno">185</tt>  <tt class="py-line"><tt class="py-docstring">            last layer of the network. This means that a desired answer should</tt> </tt>
<a name="L186"></a><tt class="py-lineno">186</tt>  <tt class="py-line"><tt class="py-docstring">            be given for every output of the network.</tt> </tt>
<a name="L187"></a><tt class="py-lineno">187</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L188"></a><tt class="py-lineno">188</tt>  <tt class="py-line"><tt class="py-docstring">        :Returns:</tt> </tt>
<a name="L189"></a><tt class="py-lineno">189</tt>  <tt class="py-line"><tt class="py-docstring">          The error obtained by the network.</tt> </tt>
<a name="L190"></a><tt class="py-lineno">190</tt>  <tt class="py-line"><tt class="py-docstring">        '''</tt> </tt>
<a name="L191"></a><tt class="py-lineno">191</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__lrule</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt id="link-35" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-35', 'x', 'link-32');">x</a></tt><tt class="py-op">,</tt> <tt class="py-name">d</tt><tt class="py-op">)</tt> </tt>
<a name="L192"></a><tt class="py-lineno">192</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">sum</tt><tt class="py-op">(</tt><tt id="link-36" class="py-name"><a title="peach.nn.rbfn.abs
peach.pso.base.abs" class="py-name" href="#" onclick="return doclink('link-36', 'abs', 'link-1');">abs</a></tt><tt class="py-op">(</tt><tt class="py-name">d</tt> <tt class="py-op">-</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-37" class="py-name"><a title="peach.fuzzy.control.Controller.y
peach.nn.base.Layer.y
peach.nn.nnet.FeedForward.y
peach.nn.nnet.SOM.y
peach.nn.rbfn.RBFN.y" class="py-name" href="#" onclick="return doclink('link-37', 'y', 'link-21');">y</a></tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L193"></a><tt class="py-lineno">193</tt>  <tt class="py-line"> </tt>
<a name="L194"></a><tt class="py-lineno">194</tt>  <tt class="py-line"> </tt>
<a name="FeedForward.feed"></a><div id="FeedForward.feed-def"><a name="L195"></a><tt class="py-lineno">195</tt> <a class="py-toggle" href="#" id="FeedForward.feed-toggle" onclick="return toggle('FeedForward.feed');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.FeedForward-class.html#feed">feed</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">x</tt><tt class="py-op">,</tt> <tt class="py-param">d</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="FeedForward.feed-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="FeedForward.feed-expanded"><a name="L196"></a><tt class="py-lineno">196</tt>  <tt class="py-line">        <tt class="py-docstring">'''</tt> </tt>
<a name="L197"></a><tt class="py-lineno">197</tt>  <tt class="py-line"><tt class="py-docstring">        Feed the network and applies one example of the training set to the</tt> </tt>
<a name="L198"></a><tt class="py-lineno">198</tt>  <tt class="py-line"><tt class="py-docstring">        network.</tt> </tt>
<a name="L199"></a><tt class="py-lineno">199</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L200"></a><tt class="py-lineno">200</tt>  <tt class="py-line"><tt class="py-docstring">        Using this method, one iteration of the learning procedure is made with</tt> </tt>
<a name="L201"></a><tt class="py-lineno">201</tt>  <tt class="py-line"><tt class="py-docstring">        the neurons of this network. This method presents one example (not</tt> </tt>
<a name="L202"></a><tt class="py-lineno">202</tt>  <tt class="py-line"><tt class="py-docstring">        necessarilly of a training set) and applies the learning rule over the</tt> </tt>
<a name="L203"></a><tt class="py-lineno">203</tt>  <tt class="py-line"><tt class="py-docstring">        network. The learning rule is defined in the initialization of the</tt> </tt>
<a name="L204"></a><tt class="py-lineno">204</tt>  <tt class="py-line"><tt class="py-docstring">        network, and some are implemented on the ``lrules`` method. New methods</tt> </tt>
<a name="L205"></a><tt class="py-lineno">205</tt>  <tt class="py-line"><tt class="py-docstring">        can be created, consult the ``lrules`` documentation but, for</tt> </tt>
<a name="L206"></a><tt class="py-lineno">206</tt>  <tt class="py-line"><tt class="py-docstring">        ``FeedForward`` instances, only ``FFLearning`` learning is allowed.</tt> </tt>
<a name="L207"></a><tt class="py-lineno">207</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L208"></a><tt class="py-lineno">208</tt>  <tt class="py-line"><tt class="py-docstring">        Also, notice that *this method feeds the network* before applying the</tt> </tt>
<a name="L209"></a><tt class="py-lineno">209</tt>  <tt class="py-line"><tt class="py-docstring">        learning rule. Feeding the network has collateral effects, and some</tt> </tt>
<a name="L210"></a><tt class="py-lineno">210</tt>  <tt class="py-line"><tt class="py-docstring">        properties change when this happens. Namely, the ``y`` property is set.</tt> </tt>
<a name="L211"></a><tt class="py-lineno">211</tt>  <tt class="py-line"><tt class="py-docstring">        Please consult the ``__call__`` interface.</tt> </tt>
<a name="L212"></a><tt class="py-lineno">212</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L213"></a><tt class="py-lineno">213</tt>  <tt class="py-line"><tt class="py-docstring">        :Parameters:</tt> </tt>
<a name="L214"></a><tt class="py-lineno">214</tt>  <tt class="py-line"><tt class="py-docstring">          x</tt> </tt>
<a name="L215"></a><tt class="py-lineno">215</tt>  <tt class="py-line"><tt class="py-docstring">            Input vector of the example. It should be a column vector of the</tt> </tt>
<a name="L216"></a><tt class="py-lineno">216</tt>  <tt class="py-line"><tt class="py-docstring">            correct dimension, that is, the number of input neurons.</tt> </tt>
<a name="L217"></a><tt class="py-lineno">217</tt>  <tt class="py-line"><tt class="py-docstring">          d</tt> </tt>
<a name="L218"></a><tt class="py-lineno">218</tt>  <tt class="py-line"><tt class="py-docstring">            The desired answer of the network for this particular input vector.</tt> </tt>
<a name="L219"></a><tt class="py-lineno">219</tt>  <tt class="py-line"><tt class="py-docstring">            Notice that the desired answer should have the same dimension of the</tt> </tt>
<a name="L220"></a><tt class="py-lineno">220</tt>  <tt class="py-line"><tt class="py-docstring">            last layer of the network. This means that a desired answer should</tt> </tt>
<a name="L221"></a><tt class="py-lineno">221</tt>  <tt class="py-line"><tt class="py-docstring">            be given for every output of the network.</tt> </tt>
<a name="L222"></a><tt class="py-lineno">222</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L223"></a><tt class="py-lineno">223</tt>  <tt class="py-line"><tt class="py-docstring">        :Returns:</tt> </tt>
<a name="L224"></a><tt class="py-lineno">224</tt>  <tt class="py-line"><tt class="py-docstring">          The error obtained by the network.</tt> </tt>
<a name="L225"></a><tt class="py-lineno">225</tt>  <tt class="py-line"><tt class="py-docstring">        '''</tt> </tt>
<a name="L226"></a><tt class="py-lineno">226</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">(</tt><tt id="link-38" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-38', 'x', 'link-32');">x</a></tt><tt class="py-op">)</tt> </tt>
<a name="L227"></a><tt class="py-lineno">227</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-39" class="py-name" targets="Method peach.nn.mem.Hopfield.learn()=peach.nn.mem.Hopfield-class.html#learn,Method peach.nn.nnet.FeedForward.learn()=peach.nn.nnet.FeedForward-class.html#learn,Method peach.nn.nnet.SOM.learn()=peach.nn.nnet.SOM-class.html#learn,Method peach.nn.rbfn.RBFN.learn()=peach.nn.rbfn.RBFN-class.html#learn"><a title="peach.nn.mem.Hopfield.learn
peach.nn.nnet.FeedForward.learn
peach.nn.nnet.SOM.learn
peach.nn.rbfn.RBFN.learn" class="py-name" href="#" onclick="return doclink('link-39', 'learn', 'link-39');">learn</a></tt><tt class="py-op">(</tt><tt id="link-40" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-40', 'x', 'link-32');">x</a></tt><tt class="py-op">,</tt> <tt class="py-name">d</tt><tt class="py-op">)</tt> </tt>
</div><a name="L228"></a><tt class="py-lineno">228</tt>  <tt class="py-line"> </tt>
<a name="L229"></a><tt class="py-lineno">229</tt>  <tt class="py-line"> </tt>
<a name="FeedForward.train"></a><div id="FeedForward.train-def"><a name="L230"></a><tt class="py-lineno">230</tt> <a class="py-toggle" href="#" id="FeedForward.train-toggle" onclick="return toggle('FeedForward.train');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.FeedForward-class.html#train">train</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">train_set</tt><tt class="py-op">,</tt> <tt class="py-param">imax</tt><tt class="py-op">=</tt><tt class="py-number">2000</tt><tt class="py-op">,</tt> <tt class="py-param">emax</tt><tt class="py-op">=</tt><tt class="py-number">1e-5</tt><tt class="py-op">,</tt> <tt class="py-param">randomize</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="FeedForward.train-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="FeedForward.train-expanded"><a name="L231"></a><tt class="py-lineno">231</tt>  <tt class="py-line">        <tt class="py-docstring">'''</tt> </tt>
<a name="L232"></a><tt class="py-lineno">232</tt>  <tt class="py-line"><tt class="py-docstring">        Presents a training set to the network.</tt> </tt>
<a name="L233"></a><tt class="py-lineno">233</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L234"></a><tt class="py-lineno">234</tt>  <tt class="py-line"><tt class="py-docstring">        This method automatizes the training of the network. Given a training</tt> </tt>
<a name="L235"></a><tt class="py-lineno">235</tt>  <tt class="py-line"><tt class="py-docstring">        set, the examples are shown to the network (possibly in a randomized</tt> </tt>
<a name="L236"></a><tt class="py-lineno">236</tt>  <tt class="py-line"><tt class="py-docstring">        way). A maximum number of iterations or a maximum admitted error should</tt> </tt>
<a name="L237"></a><tt class="py-lineno">237</tt>  <tt class="py-line"><tt class="py-docstring">        be given as a stop condition.</tt> </tt>
<a name="L238"></a><tt class="py-lineno">238</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L239"></a><tt class="py-lineno">239</tt>  <tt class="py-line"><tt class="py-docstring">        :Parameters:</tt> </tt>
<a name="L240"></a><tt class="py-lineno">240</tt>  <tt class="py-line"><tt class="py-docstring">          train_set</tt> </tt>
<a name="L241"></a><tt class="py-lineno">241</tt>  <tt class="py-line"><tt class="py-docstring">            The training set is a list of examples. It can have any size and can</tt> </tt>
<a name="L242"></a><tt class="py-lineno">242</tt>  <tt class="py-line"><tt class="py-docstring">            contain repeated examples. In fact, the definition of the training</tt> </tt>
<a name="L243"></a><tt class="py-lineno">243</tt>  <tt class="py-line"><tt class="py-docstring">            set is open. Each element of the training set, however, should be a</tt> </tt>
<a name="L244"></a><tt class="py-lineno">244</tt>  <tt class="py-line"><tt class="py-docstring">            two-tuple ``(x, d)``, where ``x`` is the input vector, and ``d`` is</tt> </tt>
<a name="L245"></a><tt class="py-lineno">245</tt>  <tt class="py-line"><tt class="py-docstring">            the desired response of the network for this particular input. See</tt> </tt>
<a name="L246"></a><tt class="py-lineno">246</tt>  <tt class="py-line"><tt class="py-docstring">            the ``learn`` and ``feed`` for more information.</tt> </tt>
<a name="L247"></a><tt class="py-lineno">247</tt>  <tt class="py-line"><tt class="py-docstring">          imax</tt> </tt>
<a name="L248"></a><tt class="py-lineno">248</tt>  <tt class="py-line"><tt class="py-docstring">            The maximum number of iterations. Examples from the training set</tt> </tt>
<a name="L249"></a><tt class="py-lineno">249</tt>  <tt class="py-line"><tt class="py-docstring">            will be presented to the network while this limit is not reached.</tt> </tt>
<a name="L250"></a><tt class="py-lineno">250</tt>  <tt class="py-line"><tt class="py-docstring">            Defaults to 2000.</tt> </tt>
<a name="L251"></a><tt class="py-lineno">251</tt>  <tt class="py-line"><tt class="py-docstring">          emax</tt> </tt>
<a name="L252"></a><tt class="py-lineno">252</tt>  <tt class="py-line"><tt class="py-docstring">            The maximum admitted error. Examples from the training set will be</tt> </tt>
<a name="L253"></a><tt class="py-lineno">253</tt>  <tt class="py-line"><tt class="py-docstring">            presented to the network until the error obtained is lower than this</tt> </tt>
<a name="L254"></a><tt class="py-lineno">254</tt>  <tt class="py-line"><tt class="py-docstring">            limit. Defaults to 1e-5.</tt> </tt>
<a name="L255"></a><tt class="py-lineno">255</tt>  <tt class="py-line"><tt class="py-docstring">          randomize</tt> </tt>
<a name="L256"></a><tt class="py-lineno">256</tt>  <tt class="py-line"><tt class="py-docstring">            If this is ``True``, then the examples are shown in a randomized</tt> </tt>
<a name="L257"></a><tt class="py-lineno">257</tt>  <tt class="py-line"><tt class="py-docstring">            order. If ``False``, then the examples are shown in the same order</tt> </tt>
<a name="L258"></a><tt class="py-lineno">258</tt>  <tt class="py-line"><tt class="py-docstring">            that they appear in the ``train_set`` list. Defaults to ``False``.</tt> </tt>
<a name="L259"></a><tt class="py-lineno">259</tt>  <tt class="py-line"><tt class="py-docstring">        '''</tt> </tt>
<a name="L260"></a><tt class="py-lineno">260</tt>  <tt class="py-line">        <tt class="py-name">i</tt> <tt class="py-op">=</tt> <tt class="py-number">0</tt> </tt>
<a name="L261"></a><tt class="py-lineno">261</tt>  <tt class="py-line">        <tt class="py-name">error</tt> <tt class="py-op">=</tt> <tt class="py-number">1</tt> </tt>
<a name="L262"></a><tt class="py-lineno">262</tt>  <tt class="py-line">        <tt class="py-name">s</tt> <tt class="py-op">=</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">train_set</tt><tt class="py-op">)</tt> </tt>
<a name="L263"></a><tt class="py-lineno">263</tt>  <tt class="py-line">        <tt class="py-keyword">while</tt> <tt class="py-name">i</tt><tt class="py-op">&lt;</tt><tt class="py-name">imax</tt> <tt class="py-keyword">and</tt> <tt class="py-name">error</tt><tt class="py-op">&gt;</tt><tt class="py-name">emax</tt><tt class="py-op">:</tt> </tt>
<a name="L264"></a><tt class="py-lineno">264</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">randomize</tt><tt class="py-op">:</tt> </tt>
<a name="L265"></a><tt class="py-lineno">265</tt>  <tt class="py-line">                <tt id="link-41" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-41', 'x', 'link-32');">x</a></tt><tt class="py-op">,</tt> <tt class="py-name">d</tt> <tt class="py-op">=</tt> <tt class="py-name">random</tt><tt class="py-op">.</tt><tt class="py-name">choice</tt><tt class="py-op">(</tt><tt class="py-name">train_set</tt><tt class="py-op">)</tt> </tt>
<a name="L266"></a><tt class="py-lineno">266</tt>  <tt class="py-line">            <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L267"></a><tt class="py-lineno">267</tt>  <tt class="py-line">                <tt id="link-42" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-42', 'x', 'link-32');">x</a></tt><tt class="py-op">,</tt> <tt class="py-name">d</tt> <tt class="py-op">=</tt> <tt class="py-name">train_set</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">%</tt><tt class="py-name">s</tt><tt class="py-op">]</tt> </tt>
<a name="L268"></a><tt class="py-lineno">268</tt>  <tt class="py-line">            <tt class="py-name">error</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-43" class="py-name" targets="Method peach.nn.nnet.FeedForward.feed()=peach.nn.nnet.FeedForward-class.html#feed,Method peach.nn.nnet.SOM.feed()=peach.nn.nnet.SOM-class.html#feed,Method peach.nn.rbfn.RBFN.feed()=peach.nn.rbfn.RBFN-class.html#feed"><a title="peach.nn.nnet.FeedForward.feed
peach.nn.nnet.SOM.feed
peach.nn.rbfn.RBFN.feed" class="py-name" href="#" onclick="return doclink('link-43', 'feed', 'link-43');">feed</a></tt><tt class="py-op">(</tt><tt id="link-44" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-44', 'x', 'link-32');">x</a></tt><tt class="py-op">,</tt> <tt class="py-name">d</tt><tt class="py-op">)</tt> </tt>
<a name="L269"></a><tt class="py-lineno">269</tt>  <tt class="py-line">            <tt class="py-name">i</tt> <tt class="py-op">=</tt> <tt class="py-name">i</tt><tt class="py-op">+</tt><tt class="py-number">1</tt> </tt>
<a name="L270"></a><tt class="py-lineno">270</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">error</tt> </tt>
</div></div><a name="L271"></a><tt class="py-lineno">271</tt>  <tt class="py-line"> </tt>
<a name="L272"></a><tt class="py-lineno">272</tt>  <tt class="py-line"> </tt>
<a name="L273"></a><tt class="py-lineno">273</tt>  <tt class="py-line"><tt class="py-comment">################################################################################</tt> </tt>
<a name="SOM"></a><div id="SOM-def"><a name="L274"></a><tt class="py-lineno">274</tt> <a class="py-toggle" href="#" id="SOM-toggle" onclick="return toggle('SOM');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="peach.nn.nnet.SOM-class.html">SOM</a><tt class="py-op">(</tt><tt class="py-base-class">Layer</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SOM-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="SOM-expanded"><a name="L275"></a><tt class="py-lineno">275</tt>  <tt class="py-line">    <tt class="py-docstring">'''</tt> </tt>
<a name="L276"></a><tt class="py-lineno">276</tt>  <tt class="py-line"><tt class="py-docstring">    A Self-Organizing Map (SOM).</tt> </tt>
<a name="L277"></a><tt class="py-lineno">277</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L278"></a><tt class="py-lineno">278</tt>  <tt class="py-line"><tt class="py-docstring">    A self-organizing map is a type of neural network that is trained via</tt> </tt>
<a name="L279"></a><tt class="py-lineno">279</tt>  <tt class="py-line"><tt class="py-docstring">    unsupervised learning. In particular, the self-organizing map finds the</tt> </tt>
<a name="L280"></a><tt class="py-lineno">280</tt>  <tt class="py-line"><tt class="py-docstring">    neuron closest to an input vector -- this neuron is the winning neuron, and</tt> </tt>
<a name="L281"></a><tt class="py-lineno">281</tt>  <tt class="py-line"><tt class="py-docstring">    it is the answer of the network. Thus, the SOM is usually used for</tt> </tt>
<a name="L282"></a><tt class="py-lineno">282</tt>  <tt class="py-line"><tt class="py-docstring">    classification and pattern recognition.</tt> </tt>
<a name="L283"></a><tt class="py-lineno">283</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L284"></a><tt class="py-lineno">284</tt>  <tt class="py-line"><tt class="py-docstring">    The SOM is a single-layer network, so this class subclasses the ``Layer``</tt> </tt>
<a name="L285"></a><tt class="py-lineno">285</tt>  <tt class="py-line"><tt class="py-docstring">    class. But some of the properties of a ``Layer`` object are not available or</tt> </tt>
<a name="L286"></a><tt class="py-lineno">286</tt>  <tt class="py-line"><tt class="py-docstring">    make no sense in this context.</tt> </tt>
<a name="L287"></a><tt class="py-lineno">287</tt>  <tt class="py-line"><tt class="py-docstring">    '''</tt> </tt>
<a name="SOM.__init__"></a><div id="SOM.__init__-def"><a name="L288"></a><tt class="py-lineno">288</tt> <a class="py-toggle" href="#" id="SOM.__init__-toggle" onclick="return toggle('SOM.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.SOM-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">shape</tt><tt class="py-op">,</tt> <tt class="py-param">lrule</tt><tt class="py-op">=</tt><tt id="link-45" class="py-name" targets="Class peach.nn.lrules.Competitive=peach.nn.lrules.Competitive-class.html"><a title="peach.nn.lrules.Competitive" class="py-name" href="#" onclick="return doclink('link-45', 'Competitive', 'link-45');">Competitive</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SOM.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="SOM.__init__-expanded"><a name="L289"></a><tt class="py-lineno">289</tt>  <tt class="py-line">        <tt class="py-docstring">'''</tt> </tt>
<a name="L290"></a><tt class="py-lineno">290</tt>  <tt class="py-line"><tt class="py-docstring">        Initializes a self-organizing map.</tt> </tt>
<a name="L291"></a><tt class="py-lineno">291</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L292"></a><tt class="py-lineno">292</tt>  <tt class="py-line"><tt class="py-docstring">        A self-organizing map is implemented as a layer of neurons. There is no</tt> </tt>
<a name="L293"></a><tt class="py-lineno">293</tt>  <tt class="py-line"><tt class="py-docstring">        connection among the neurons. The answer to a given input is the neuron</tt> </tt>
<a name="L294"></a><tt class="py-lineno">294</tt>  <tt class="py-line"><tt class="py-docstring">        closer to the given input. ``phi`` (the activation function) ``v`` (the</tt> </tt>
<a name="L295"></a><tt class="py-lineno">295</tt>  <tt class="py-line"><tt class="py-docstring">        activation potential) and ``bias`` are not used.</tt> </tt>
<a name="L296"></a><tt class="py-lineno">296</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L297"></a><tt class="py-lineno">297</tt>  <tt class="py-line"><tt class="py-docstring">        :Parameters:</tt> </tt>
<a name="L298"></a><tt class="py-lineno">298</tt>  <tt class="py-line"><tt class="py-docstring">          shape</tt> </tt>
<a name="L299"></a><tt class="py-lineno">299</tt>  <tt class="py-line"><tt class="py-docstring">            Stablishes the size of the SOM. It must be a two-tuple of the</tt> </tt>
<a name="L300"></a><tt class="py-lineno">300</tt>  <tt class="py-line"><tt class="py-docstring">            format ``(m, n)``, where ``m`` is the number of neurons in the</tt> </tt>
<a name="L301"></a><tt class="py-lineno">301</tt>  <tt class="py-line"><tt class="py-docstring">            layer, and ``n`` is the number of inputs of each neuron. The neurons</tt> </tt>
<a name="L302"></a><tt class="py-lineno">302</tt>  <tt class="py-line"><tt class="py-docstring">            in the layer all have the same number of inputs.</tt> </tt>
<a name="L303"></a><tt class="py-lineno">303</tt>  <tt class="py-line"><tt class="py-docstring">          lrule</tt> </tt>
<a name="L304"></a><tt class="py-lineno">304</tt>  <tt class="py-line"><tt class="py-docstring">            The learning rule used. Only ``SOMLearning`` objects (instances of</tt> </tt>
<a name="L305"></a><tt class="py-lineno">305</tt>  <tt class="py-line"><tt class="py-docstring">            the class or of the subclasses) are allowed. Defaults to</tt> </tt>
<a name="L306"></a><tt class="py-lineno">306</tt>  <tt class="py-line"><tt class="py-docstring">            ``Competitive``. Check the ``lrules`` documentation for more</tt> </tt>
<a name="L307"></a><tt class="py-lineno">307</tt>  <tt class="py-line"><tt class="py-docstring">            information.</tt> </tt>
<a name="L308"></a><tt class="py-lineno">308</tt>  <tt class="py-line"><tt class="py-docstring">        '''</tt> </tt>
<a name="L309"></a><tt class="py-lineno">309</tt>  <tt class="py-line">        <tt id="link-46" class="py-name"><a title="peach.nn.base.Layer" class="py-name" href="#" onclick="return doclink('link-46', 'Layer', 'link-9');">Layer</a></tt><tt class="py-op">.</tt><tt id="link-47" class="py-name"><a title="peach.fuzzy.base.FuzzySet.__init__
peach.fuzzy.cmeans.FuzzyCMeans.__init__
peach.fuzzy.control.Controller.__init__
peach.fuzzy.control.Parametric.__init__
peach.fuzzy.mf.Bell.__init__
peach.fuzzy.mf.DecreasingRamp.__init__
peach.fuzzy.mf.DecreasingSigmoid.__init__
peach.fuzzy.mf.Gaussian.__init__
peach.fuzzy.mf.IncreasingRamp.__init__
peach.fuzzy.mf.IncreasingSigmoid.__init__
peach.fuzzy.mf.Membership.__init__
peach.fuzzy.mf.RaisedCosine.__init__
peach.fuzzy.mf.Smf.__init__
peach.fuzzy.mf.Trapezoid.__init__
peach.fuzzy.mf.Triangle.__init__
peach.fuzzy.mf.Zmf.__init__
peach.ga.base.GeneticAlgorithm.__init__
peach.ga.chromosome.Chromosome.__init__
peach.ga.crossover.OnePoint.__init__
peach.ga.crossover.TwoPoint.__init__
peach.ga.crossover.Uniform.__init__
peach.ga.fitness.Fitness.__init__
peach.ga.fitness.Ranking.__init__
peach.ga.mutation.BitToBit.__init__
peach.nn.af.Activation.__init__
peach.nn.af.ArcTan.__init__
peach.nn.af.Gaussian.__init__
peach.nn.af.Linear.__init__
peach.nn.af.Ramp.__init__
peach.nn.af.Sigmoid.__init__
peach.nn.af.Signum.__init__
peach.nn.af.TanH.__init__
peach.nn.af.Threshold.__init__
peach.nn.base.Layer.__init__
peach.nn.kmeans.KMeans.__init__
peach.nn.lrules.BackPropagation.__init__
peach.nn.lrules.Competitive.__init__
peach.nn.lrules.Cooperative.__init__
peach.nn.lrules.LMS.__init__
peach.nn.lrules.WinnerTakesAll.__init__
peach.nn.mem.Hopfield.__init__
peach.nn.nnet.FeedForward.__init__
peach.nn.nnet.GRNN.__init__
peach.nn.nnet.PNN.__init__
peach.nn.nnet.SOM.__init__
peach.nn.rbfn.RBFN.__init__
peach.optm.base.Optimizer.__init__
peach.optm.linear.Direct1D.__init__
peach.optm.linear.Fibonacci.__init__
peach.optm.linear.GoldenRule.__init__
peach.optm.linear.Interpolation.__init__
peach.optm.multivar.Direct.__init__
peach.optm.multivar.Gradient.__init__
peach.optm.multivar.MomentumGradient.__init__
peach.optm.multivar.Newton.__init__
peach.optm.quasinewton.BFGS.__init__
peach.optm.quasinewton.DFP.__init__
peach.optm.quasinewton.SR1.__init__
peach.optm.stochastic.CrossEntropy.__init__
peach.pso.acc.Accelerator.__init__
peach.pso.acc.StandardPSO.__init__
peach.pso.base.ParticleSwarmOptimizer.__init__
peach.sa.base.BinarySA.__init__
peach.sa.base.ContinuousSA.__init__
peach.sa.neighbor.BinaryNeighbor.__init__
peach.sa.neighbor.ContinuousNeighbor.__init__
peach.sa.neighbor.GaussianNeighbor.__init__
peach.sa.neighbor.InvertBitsNeighbor.__init__
peach.sa.neighbor.UniformNeighbor.__init__" class="py-name" href="#" onclick="return doclink('link-47', '__init__', 'link-8');">__init__</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt id="link-48" class="py-name" targets="Variable peach.nn.base.Layer.shape=peach.nn.base.Layer-class.html#shape"><a title="peach.nn.base.Layer.shape" class="py-name" href="#" onclick="return doclink('link-48', 'shape', 'link-48');">shape</a></tt><tt class="py-op">,</tt> <tt id="link-49" class="py-name"><a title="peach.nn.base.Layer.phi
peach.nn.nnet.FeedForward.phi
peach.nn.rbfn.RBFN.phi" class="py-name" href="#" onclick="return doclink('link-49', 'phi', 'link-12');">phi</a></tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> <tt id="link-50" class="py-name"><a title="peach.nn.base.Layer.bias
peach.nn.nnet.FeedForward.bias" class="py-name" href="#" onclick="return doclink('link-50', 'bias', 'link-10');">bias</a></tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt> </tt>
<a name="L310"></a><tt class="py-lineno">310</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__lrule</tt> <tt class="py-op">=</tt> <tt class="py-name">lrule</tt> </tt>
<a name="L311"></a><tt class="py-lineno">311</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__y</tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt> </tt>
<a name="L312"></a><tt class="py-lineno">312</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__phi</tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt> </tt>
<a name="L313"></a><tt class="py-lineno">313</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">lrule</tt><tt class="py-op">,</tt> <tt id="link-51" class="py-name" targets="Class peach.nn.lrules.SOMLearning=peach.nn.lrules.SOMLearning-class.html"><a title="peach.nn.lrules.SOMLearning" class="py-name" href="#" onclick="return doclink('link-51', 'SOMLearning', 'link-51');">SOMLearning</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L314"></a><tt class="py-lineno">314</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__lrule</tt> <tt class="py-op">=</tt> <tt class="py-name">lrule</tt> </tt>
<a name="L315"></a><tt class="py-lineno">315</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L316"></a><tt class="py-lineno">316</tt>  <tt class="py-line">            <tt class="py-keyword">try</tt><tt class="py-op">:</tt> </tt>
<a name="L317"></a><tt class="py-lineno">317</tt>  <tt class="py-line">                <tt class="py-name">issubclass</tt><tt class="py-op">(</tt><tt class="py-name">lrule</tt><tt class="py-op">,</tt> <tt id="link-52" class="py-name"><a title="peach.nn.lrules.SOMLearning" class="py-name" href="#" onclick="return doclink('link-52', 'SOMLearning', 'link-51');">SOMLearning</a></tt><tt class="py-op">)</tt> </tt>
<a name="L318"></a><tt class="py-lineno">318</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__lrule</tt> <tt class="py-op">=</tt> <tt class="py-name">lrule</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L319"></a><tt class="py-lineno">319</tt>  <tt class="py-line">            <tt class="py-keyword">except</tt> <tt class="py-name">TypeError</tt><tt class="py-op">:</tt> </tt>
<a name="L320"></a><tt class="py-lineno">320</tt>  <tt class="py-line">                <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">,</tt> <tt class="py-string">'uncompatible learning rule'</tt> </tt>
</div><a name="L321"></a><tt class="py-lineno">321</tt>  <tt class="py-line"> </tt>
<a name="L322"></a><tt class="py-lineno">322</tt>  <tt class="py-line"> </tt>
<a name="SOM.__gety"></a><div id="SOM.__gety-def"><a name="L323"></a><tt class="py-lineno">323</tt> <a class="py-toggle" href="#" id="SOM.__gety-toggle" onclick="return toggle('SOM.__gety');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.SOM-class.html#__gety">__gety</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SOM.__gety-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="SOM.__gety-expanded"><a name="L324"></a><tt class="py-lineno">324</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__y</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L325"></a><tt class="py-lineno">325</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">,</tt> <tt class="py-string">"activation unavailable"</tt> </tt>
<a name="L326"></a><tt class="py-lineno">326</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L327"></a><tt class="py-lineno">327</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__y</tt> </tt>
</div><a name="L328"></a><tt class="py-lineno">328</tt>  <tt class="py-line">    <tt id="link-53" class="py-name"><a title="peach.fuzzy.control.Controller.y
peach.nn.base.Layer.y
peach.nn.nnet.FeedForward.y
peach.nn.nnet.SOM.y
peach.nn.rbfn.RBFN.y" class="py-name" href="#" onclick="return doclink('link-53', 'y', 'link-21');">y</a></tt> <tt class="py-op">=</tt> <tt class="py-name">property</tt><tt class="py-op">(</tt><tt id="link-54" class="py-name"><a title="peach.fuzzy.control.Controller.__gety
peach.nn.base.Layer.__gety
peach.nn.nnet.FeedForward.__gety
peach.nn.nnet.SOM.__gety
peach.nn.rbfn.RBFN.__gety" class="py-name" href="#" onclick="return doclink('link-54', '__gety', 'link-23');">__gety</a></tt><tt class="py-op">,</tt> <tt class="py-name">None</tt><tt class="py-op">)</tt> </tt>
<a name="L329"></a><tt class="py-lineno">329</tt>  <tt class="py-line">    <tt class="py-string">'''The winning neuron for a given input, the answer of the network. This</tt> </tt>
<a name="L330"></a><tt class="py-lineno">330</tt>  <tt class="py-line"><tt class="py-string">    property is available only after the network is fed some input.'''</tt> </tt>
<a name="L331"></a><tt class="py-lineno">331</tt>  <tt class="py-line"> </tt>
<a name="L332"></a><tt class="py-lineno">332</tt>  <tt class="py-line"> </tt>
<a name="SOM.__call__"></a><div id="SOM.__call__-def"><a name="L333"></a><tt class="py-lineno">333</tt> <a class="py-toggle" href="#" id="SOM.__call__-toggle" onclick="return toggle('SOM.__call__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.SOM-class.html#__call__">__call__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">x</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SOM.__call__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="SOM.__call__-expanded"><a name="L334"></a><tt class="py-lineno">334</tt>  <tt class="py-line">        <tt class="py-docstring">'''</tt> </tt>
<a name="L335"></a><tt class="py-lineno">335</tt>  <tt class="py-line"><tt class="py-docstring">        The response of the network to a given input.</tt> </tt>
<a name="L336"></a><tt class="py-lineno">336</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L337"></a><tt class="py-lineno">337</tt>  <tt class="py-line"><tt class="py-docstring">        The ``__call__`` interface should be called if the answer of the neuron</tt> </tt>
<a name="L338"></a><tt class="py-lineno">338</tt>  <tt class="py-line"><tt class="py-docstring">        network to a given input vector ``x`` is desired. *This method has</tt> </tt>
<a name="L339"></a><tt class="py-lineno">339</tt>  <tt class="py-line"><tt class="py-docstring">        collateral effects*, so beware. After the calling of this method, the</tt> </tt>
<a name="L340"></a><tt class="py-lineno">340</tt>  <tt class="py-line"><tt class="py-docstring">        ``y`` property is set with the activation potential and the answer of</tt> </tt>
<a name="L341"></a><tt class="py-lineno">341</tt>  <tt class="py-line"><tt class="py-docstring">        the neurons, respectivelly.</tt> </tt>
<a name="L342"></a><tt class="py-lineno">342</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L343"></a><tt class="py-lineno">343</tt>  <tt class="py-line"><tt class="py-docstring">        :Parameters:</tt> </tt>
<a name="L344"></a><tt class="py-lineno">344</tt>  <tt class="py-line"><tt class="py-docstring">          x</tt> </tt>
<a name="L345"></a><tt class="py-lineno">345</tt>  <tt class="py-line"><tt class="py-docstring">            The input vector to the network.</tt> </tt>
<a name="L346"></a><tt class="py-lineno">346</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L347"></a><tt class="py-lineno">347</tt>  <tt class="py-line"><tt class="py-docstring">        :Returns:</tt> </tt>
<a name="L348"></a><tt class="py-lineno">348</tt>  <tt class="py-line"><tt class="py-docstring">          The winning neuron.</tt> </tt>
<a name="L349"></a><tt class="py-lineno">349</tt>  <tt class="py-line"><tt class="py-docstring">        '''</tt> </tt>
<a name="L350"></a><tt class="py-lineno">350</tt>  <tt class="py-line">        <tt id="link-55" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-55', 'x', 'link-32');">x</a></tt> <tt class="py-op">=</tt> <tt class="py-name">reshape</tt><tt class="py-op">(</tt><tt id="link-56" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-56', 'x', 'link-32');">x</a></tt><tt class="py-op">,</tt> <tt class="py-op">(</tt><tt class="py-number">1</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-57" class="py-name" targets="Variable peach.nn.base.Layer.inputs=peach.nn.base.Layer-class.html#inputs,Variable peach.nn.mem.Hopfield.inputs=peach.nn.mem.Hopfield-class.html#inputs"><a title="peach.nn.base.Layer.inputs
peach.nn.mem.Hopfield.inputs" class="py-name" href="#" onclick="return doclink('link-57', 'inputs', 'link-57');">inputs</a></tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L351"></a><tt class="py-lineno">351</tt>  <tt class="py-line">        <tt class="py-name">dist</tt> <tt class="py-op">=</tt> <tt id="link-58" class="py-name"><a title="peach.nn.rbfn.sqrt
peach.pso.base.sqrt" class="py-name" href="#" onclick="return doclink('link-58', 'sqrt', 'link-2');">sqrt</a></tt><tt class="py-op">(</tt><tt class="py-name">sum</tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt id="link-59" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-59', 'x', 'link-32');">x</a></tt> <tt class="py-op">-</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-60" class="py-name" targets="Variable peach.nn.base.Layer.weights=peach.nn.base.Layer-class.html#weights,Variable peach.nn.mem.Hopfield.weights=peach.nn.mem.Hopfield-class.html#weights,Variable peach.nn.rbfn.RBFN.weights=peach.nn.rbfn.RBFN-class.html#weights"><a title="peach.nn.base.Layer.weights
peach.nn.mem.Hopfield.weights
peach.nn.rbfn.RBFN.weights" class="py-name" href="#" onclick="return doclink('link-60', 'weights', 'link-60');">weights</a></tt><tt class="py-op">)</tt><tt class="py-op">**</tt><tt class="py-number">2</tt><tt class="py-op">,</tt> <tt class="py-name">axis</tt><tt class="py-op">=</tt><tt class="py-number">1</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L352"></a><tt class="py-lineno">352</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__y</tt> <tt class="py-op">=</tt> <tt class="py-name">argmin</tt><tt class="py-op">(</tt><tt class="py-name">dist</tt><tt class="py-op">)</tt> </tt>
<a name="L353"></a><tt class="py-lineno">353</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-61" class="py-name"><a title="peach.fuzzy.control.Controller.y
peach.nn.base.Layer.y
peach.nn.nnet.FeedForward.y
peach.nn.nnet.SOM.y
peach.nn.rbfn.RBFN.y" class="py-name" href="#" onclick="return doclink('link-61', 'y', 'link-21');">y</a></tt> </tt>
</div><a name="L354"></a><tt class="py-lineno">354</tt>  <tt class="py-line"> </tt>
<a name="L355"></a><tt class="py-lineno">355</tt>  <tt class="py-line"> </tt>
<a name="SOM.learn"></a><div id="SOM.learn-def"><a name="L356"></a><tt class="py-lineno">356</tt> <a class="py-toggle" href="#" id="SOM.learn-toggle" onclick="return toggle('SOM.learn');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.SOM-class.html#learn">learn</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">x</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SOM.learn-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="SOM.learn-expanded"><a name="L357"></a><tt class="py-lineno">357</tt>  <tt class="py-line">        <tt class="py-docstring">'''</tt> </tt>
<a name="L358"></a><tt class="py-lineno">358</tt>  <tt class="py-line"><tt class="py-docstring">        Applies one example of the training set to the network.</tt> </tt>
<a name="L359"></a><tt class="py-lineno">359</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L360"></a><tt class="py-lineno">360</tt>  <tt class="py-line"><tt class="py-docstring">        Using this method, one iteration of the learning procedure is made with</tt> </tt>
<a name="L361"></a><tt class="py-lineno">361</tt>  <tt class="py-line"><tt class="py-docstring">        the neurons of this network. This method presents one example (not</tt> </tt>
<a name="L362"></a><tt class="py-lineno">362</tt>  <tt class="py-line"><tt class="py-docstring">        necessarilly of a training set) and applies the learning rule over the</tt> </tt>
<a name="L363"></a><tt class="py-lineno">363</tt>  <tt class="py-line"><tt class="py-docstring">        network. The learning rule is defined in the initialization of the</tt> </tt>
<a name="L364"></a><tt class="py-lineno">364</tt>  <tt class="py-line"><tt class="py-docstring">        network, and some are implemented on the ``lrules`` method. New methods</tt> </tt>
<a name="L365"></a><tt class="py-lineno">365</tt>  <tt class="py-line"><tt class="py-docstring">        can be created, consult the ``lrules`` documentation but, for</tt> </tt>
<a name="L366"></a><tt class="py-lineno">366</tt>  <tt class="py-line"><tt class="py-docstring">        ``SOM`` instances, only ``SOMLearning`` learning is allowed.</tt> </tt>
<a name="L367"></a><tt class="py-lineno">367</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L368"></a><tt class="py-lineno">368</tt>  <tt class="py-line"><tt class="py-docstring">        Also, notice that *this method only applies the learning method!* The</tt> </tt>
<a name="L369"></a><tt class="py-lineno">369</tt>  <tt class="py-line"><tt class="py-docstring">        network should be fed with the same input vector before trying to learn</tt> </tt>
<a name="L370"></a><tt class="py-lineno">370</tt>  <tt class="py-line"><tt class="py-docstring">        anything first. Consult the ``feed`` and ``train`` methods below for</tt> </tt>
<a name="L371"></a><tt class="py-lineno">371</tt>  <tt class="py-line"><tt class="py-docstring">        more ways to train a network.</tt> </tt>
<a name="L372"></a><tt class="py-lineno">372</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L373"></a><tt class="py-lineno">373</tt>  <tt class="py-line"><tt class="py-docstring">        :Parameters:</tt> </tt>
<a name="L374"></a><tt class="py-lineno">374</tt>  <tt class="py-line"><tt class="py-docstring">          x</tt> </tt>
<a name="L375"></a><tt class="py-lineno">375</tt>  <tt class="py-line"><tt class="py-docstring">            Input vector of the example. It should be a column vector of the</tt> </tt>
<a name="L376"></a><tt class="py-lineno">376</tt>  <tt class="py-line"><tt class="py-docstring">            correct dimension, that is, the number of input neurons.</tt> </tt>
<a name="L377"></a><tt class="py-lineno">377</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L378"></a><tt class="py-lineno">378</tt>  <tt class="py-line"><tt class="py-docstring">        :Returns:</tt> </tt>
<a name="L379"></a><tt class="py-lineno">379</tt>  <tt class="py-line"><tt class="py-docstring">          The error obtained by the network.</tt> </tt>
<a name="L380"></a><tt class="py-lineno">380</tt>  <tt class="py-line"><tt class="py-docstring">        '''</tt> </tt>
<a name="L381"></a><tt class="py-lineno">381</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__lrule</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt id="link-62" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-62', 'x', 'link-32');">x</a></tt><tt class="py-op">)</tt> </tt>
<a name="L382"></a><tt class="py-lineno">382</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">sum</tt><tt class="py-op">(</tt><tt id="link-63" class="py-name"><a title="peach.nn.rbfn.abs
peach.pso.base.abs" class="py-name" href="#" onclick="return doclink('link-63', 'abs', 'link-1');">abs</a></tt><tt class="py-op">(</tt><tt id="link-64" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-64', 'x', 'link-32');">x</a></tt> <tt class="py-op">-</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-65" class="py-name"><a title="peach.fuzzy.control.Controller.y
peach.nn.base.Layer.y
peach.nn.nnet.FeedForward.y
peach.nn.nnet.SOM.y
peach.nn.rbfn.RBFN.y" class="py-name" href="#" onclick="return doclink('link-65', 'y', 'link-21');">y</a></tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L383"></a><tt class="py-lineno">383</tt>  <tt class="py-line"> </tt>
<a name="L384"></a><tt class="py-lineno">384</tt>  <tt class="py-line"> </tt>
<a name="SOM.feed"></a><div id="SOM.feed-def"><a name="L385"></a><tt class="py-lineno">385</tt> <a class="py-toggle" href="#" id="SOM.feed-toggle" onclick="return toggle('SOM.feed');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.SOM-class.html#feed">feed</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">x</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SOM.feed-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="SOM.feed-expanded"><a name="L386"></a><tt class="py-lineno">386</tt>  <tt class="py-line">        <tt class="py-docstring">'''</tt> </tt>
<a name="L387"></a><tt class="py-lineno">387</tt>  <tt class="py-line"><tt class="py-docstring">        Feed the network and applies one example of the training set to the</tt> </tt>
<a name="L388"></a><tt class="py-lineno">388</tt>  <tt class="py-line"><tt class="py-docstring">        network.</tt> </tt>
<a name="L389"></a><tt class="py-lineno">389</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L390"></a><tt class="py-lineno">390</tt>  <tt class="py-line"><tt class="py-docstring">        Using this method, one iteration of the learning procedure is made with</tt> </tt>
<a name="L391"></a><tt class="py-lineno">391</tt>  <tt class="py-line"><tt class="py-docstring">        the neurons of this network. This method presents one example (not</tt> </tt>
<a name="L392"></a><tt class="py-lineno">392</tt>  <tt class="py-line"><tt class="py-docstring">        necessarilly of a training set) and applies the learning rule over the</tt> </tt>
<a name="L393"></a><tt class="py-lineno">393</tt>  <tt class="py-line"><tt class="py-docstring">        network. The learning rule is defined in the initialization of the</tt> </tt>
<a name="L394"></a><tt class="py-lineno">394</tt>  <tt class="py-line"><tt class="py-docstring">        network, and some are implemented on the ``lrules`` method. New methods</tt> </tt>
<a name="L395"></a><tt class="py-lineno">395</tt>  <tt class="py-line"><tt class="py-docstring">        can be created, consult the ``lrules`` documentation but, for</tt> </tt>
<a name="L396"></a><tt class="py-lineno">396</tt>  <tt class="py-line"><tt class="py-docstring">        ``SOM`` instances, only ``SOMLearning`` learning is allowed.</tt> </tt>
<a name="L397"></a><tt class="py-lineno">397</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L398"></a><tt class="py-lineno">398</tt>  <tt class="py-line"><tt class="py-docstring">        Also, notice that *this method feeds the network* before applying the</tt> </tt>
<a name="L399"></a><tt class="py-lineno">399</tt>  <tt class="py-line"><tt class="py-docstring">        learning rule. Feeding the network has collateral effects, and some</tt> </tt>
<a name="L400"></a><tt class="py-lineno">400</tt>  <tt class="py-line"><tt class="py-docstring">        properties change when this happens. Namely, the ``y`` property is set.</tt> </tt>
<a name="L401"></a><tt class="py-lineno">401</tt>  <tt class="py-line"><tt class="py-docstring">        Please consult the ``__call__`` interface.</tt> </tt>
<a name="L402"></a><tt class="py-lineno">402</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L403"></a><tt class="py-lineno">403</tt>  <tt class="py-line"><tt class="py-docstring">        :Parameters:</tt> </tt>
<a name="L404"></a><tt class="py-lineno">404</tt>  <tt class="py-line"><tt class="py-docstring">          x</tt> </tt>
<a name="L405"></a><tt class="py-lineno">405</tt>  <tt class="py-line"><tt class="py-docstring">            Input vector of the example. It should be a column vector of the</tt> </tt>
<a name="L406"></a><tt class="py-lineno">406</tt>  <tt class="py-line"><tt class="py-docstring">            correct dimension, that is, the number of input neurons.</tt> </tt>
<a name="L407"></a><tt class="py-lineno">407</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L408"></a><tt class="py-lineno">408</tt>  <tt class="py-line"><tt class="py-docstring">        :Returns:</tt> </tt>
<a name="L409"></a><tt class="py-lineno">409</tt>  <tt class="py-line"><tt class="py-docstring">          The error obtained by the network.</tt> </tt>
<a name="L410"></a><tt class="py-lineno">410</tt>  <tt class="py-line"><tt class="py-docstring">        '''</tt> </tt>
<a name="L411"></a><tt class="py-lineno">411</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">(</tt><tt id="link-66" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-66', 'x', 'link-32');">x</a></tt><tt class="py-op">)</tt> </tt>
<a name="L412"></a><tt class="py-lineno">412</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-67" class="py-name"><a title="peach.nn.mem.Hopfield.learn
peach.nn.nnet.FeedForward.learn
peach.nn.nnet.SOM.learn
peach.nn.rbfn.RBFN.learn" class="py-name" href="#" onclick="return doclink('link-67', 'learn', 'link-39');">learn</a></tt><tt class="py-op">(</tt><tt id="link-68" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-68', 'x', 'link-32');">x</a></tt><tt class="py-op">)</tt> </tt>
</div><a name="L413"></a><tt class="py-lineno">413</tt>  <tt class="py-line"> </tt>
<a name="L414"></a><tt class="py-lineno">414</tt>  <tt class="py-line"> </tt>
<a name="SOM.train"></a><div id="SOM.train-def"><a name="L415"></a><tt class="py-lineno">415</tt> <a class="py-toggle" href="#" id="SOM.train-toggle" onclick="return toggle('SOM.train');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.SOM-class.html#train">train</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">train_set</tt><tt class="py-op">,</tt> <tt class="py-param">imax</tt><tt class="py-op">=</tt><tt class="py-number">2000</tt><tt class="py-op">,</tt> <tt class="py-param">emax</tt><tt class="py-op">=</tt><tt class="py-number">1e-5</tt><tt class="py-op">,</tt> <tt class="py-param">randomize</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SOM.train-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="SOM.train-expanded"><a name="L416"></a><tt class="py-lineno">416</tt>  <tt class="py-line">        <tt class="py-docstring">'''</tt> </tt>
<a name="L417"></a><tt class="py-lineno">417</tt>  <tt class="py-line"><tt class="py-docstring">        Presents a training set to the network.</tt> </tt>
<a name="L418"></a><tt class="py-lineno">418</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L419"></a><tt class="py-lineno">419</tt>  <tt class="py-line"><tt class="py-docstring">        This method automatizes the training of the network. Given a training</tt> </tt>
<a name="L420"></a><tt class="py-lineno">420</tt>  <tt class="py-line"><tt class="py-docstring">        set, the examples are shown to the network (possibly in a randomized</tt> </tt>
<a name="L421"></a><tt class="py-lineno">421</tt>  <tt class="py-line"><tt class="py-docstring">        way). A maximum number of iterations or a maximum admitted error should</tt> </tt>
<a name="L422"></a><tt class="py-lineno">422</tt>  <tt class="py-line"><tt class="py-docstring">        be given as a stop condition.</tt> </tt>
<a name="L423"></a><tt class="py-lineno">423</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L424"></a><tt class="py-lineno">424</tt>  <tt class="py-line"><tt class="py-docstring">        :Parameters:</tt> </tt>
<a name="L425"></a><tt class="py-lineno">425</tt>  <tt class="py-line"><tt class="py-docstring">          train_set</tt> </tt>
<a name="L426"></a><tt class="py-lineno">426</tt>  <tt class="py-line"><tt class="py-docstring">            The training set is a list of examples. It can have any size and can</tt> </tt>
<a name="L427"></a><tt class="py-lineno">427</tt>  <tt class="py-line"><tt class="py-docstring">            contain repeated examples. In fact, the definition of the training</tt> </tt>
<a name="L428"></a><tt class="py-lineno">428</tt>  <tt class="py-line"><tt class="py-docstring">            set is open. Each element of the training set, however, should be a</tt> </tt>
<a name="L429"></a><tt class="py-lineno">429</tt>  <tt class="py-line"><tt class="py-docstring">            input vector of the correct dimensions, See the ``learn`` and</tt> </tt>
<a name="L430"></a><tt class="py-lineno">430</tt>  <tt class="py-line"><tt class="py-docstring">            ``feed`` for more information.</tt> </tt>
<a name="L431"></a><tt class="py-lineno">431</tt>  <tt class="py-line"><tt class="py-docstring">          imax</tt> </tt>
<a name="L432"></a><tt class="py-lineno">432</tt>  <tt class="py-line"><tt class="py-docstring">            The maximum number of iterations. Examples from the training set</tt> </tt>
<a name="L433"></a><tt class="py-lineno">433</tt>  <tt class="py-line"><tt class="py-docstring">            will be presented to the network while this limit is not reached.</tt> </tt>
<a name="L434"></a><tt class="py-lineno">434</tt>  <tt class="py-line"><tt class="py-docstring">            Defaults to 2000.</tt> </tt>
<a name="L435"></a><tt class="py-lineno">435</tt>  <tt class="py-line"><tt class="py-docstring">          emax</tt> </tt>
<a name="L436"></a><tt class="py-lineno">436</tt>  <tt class="py-line"><tt class="py-docstring">            The maximum admitted error. Examples from the training set will be</tt> </tt>
<a name="L437"></a><tt class="py-lineno">437</tt>  <tt class="py-line"><tt class="py-docstring">            presented to the network until the error obtained is lower than this</tt> </tt>
<a name="L438"></a><tt class="py-lineno">438</tt>  <tt class="py-line"><tt class="py-docstring">            limit. Defaults to 1e-5.</tt> </tt>
<a name="L439"></a><tt class="py-lineno">439</tt>  <tt class="py-line"><tt class="py-docstring">          randomize</tt> </tt>
<a name="L440"></a><tt class="py-lineno">440</tt>  <tt class="py-line"><tt class="py-docstring">            If this is ``True``, then the examples are shown in a randomized</tt> </tt>
<a name="L441"></a><tt class="py-lineno">441</tt>  <tt class="py-line"><tt class="py-docstring">            order. If ``False``, then the examples are shown in the same order</tt> </tt>
<a name="L442"></a><tt class="py-lineno">442</tt>  <tt class="py-line"><tt class="py-docstring">            that they appear in the ``train_set`` list. Defaults to ``False``.</tt> </tt>
<a name="L443"></a><tt class="py-lineno">443</tt>  <tt class="py-line"><tt class="py-docstring">        '''</tt> </tt>
<a name="L444"></a><tt class="py-lineno">444</tt>  <tt class="py-line">        <tt class="py-name">i</tt> <tt class="py-op">=</tt> <tt class="py-number">0</tt> </tt>
<a name="L445"></a><tt class="py-lineno">445</tt>  <tt class="py-line">        <tt class="py-name">error</tt> <tt class="py-op">=</tt> <tt class="py-number">1</tt> </tt>
<a name="L446"></a><tt class="py-lineno">446</tt>  <tt class="py-line">        <tt class="py-name">s</tt> <tt class="py-op">=</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">train_set</tt><tt class="py-op">)</tt> </tt>
<a name="L447"></a><tt class="py-lineno">447</tt>  <tt class="py-line">        <tt class="py-keyword">while</tt> <tt class="py-name">i</tt><tt class="py-op">&lt;</tt><tt class="py-name">imax</tt> <tt class="py-keyword">and</tt> <tt class="py-name">error</tt><tt class="py-op">&gt;</tt><tt class="py-name">emax</tt><tt class="py-op">:</tt> </tt>
<a name="L448"></a><tt class="py-lineno">448</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">randomize</tt><tt class="py-op">:</tt> </tt>
<a name="L449"></a><tt class="py-lineno">449</tt>  <tt class="py-line">                <tt id="link-69" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-69', 'x', 'link-32');">x</a></tt> <tt class="py-op">=</tt> <tt class="py-name">random</tt><tt class="py-op">.</tt><tt class="py-name">choice</tt><tt class="py-op">(</tt><tt class="py-name">train_set</tt><tt class="py-op">)</tt> </tt>
<a name="L450"></a><tt class="py-lineno">450</tt>  <tt class="py-line">            <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L451"></a><tt class="py-lineno">451</tt>  <tt class="py-line">                <tt id="link-70" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-70', 'x', 'link-32');">x</a></tt> <tt class="py-op">=</tt> <tt class="py-name">train_set</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">%</tt><tt class="py-name">s</tt><tt class="py-op">]</tt> </tt>
<a name="L452"></a><tt class="py-lineno">452</tt>  <tt class="py-line">            <tt class="py-name">error</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-71" class="py-name"><a title="peach.nn.nnet.FeedForward.feed
peach.nn.nnet.SOM.feed
peach.nn.rbfn.RBFN.feed" class="py-name" href="#" onclick="return doclink('link-71', 'feed', 'link-43');">feed</a></tt><tt class="py-op">(</tt><tt id="link-72" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-72', 'x', 'link-32');">x</a></tt><tt class="py-op">)</tt> </tt>
<a name="L453"></a><tt class="py-lineno">453</tt>  <tt class="py-line">            <tt class="py-name">i</tt> <tt class="py-op">=</tt> <tt class="py-name">i</tt><tt class="py-op">+</tt><tt class="py-number">1</tt> </tt>
<a name="L454"></a><tt class="py-lineno">454</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">error</tt> </tt>
</div></div><a name="L455"></a><tt class="py-lineno">455</tt>  <tt class="py-line"> </tt>
<a name="L456"></a><tt class="py-lineno">456</tt>  <tt class="py-line"> </tt>
<a name="L457"></a><tt class="py-lineno">457</tt>  <tt class="py-line"><tt class="py-comment">################################################################################</tt> </tt>
<a name="GRNN"></a><div id="GRNN-def"><a name="L458"></a><tt class="py-lineno">458</tt> <a class="py-toggle" href="#" id="GRNN-toggle" onclick="return toggle('GRNN');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="peach.nn.nnet.GRNN-class.html">GRNN</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="GRNN-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="GRNN-expanded"><a name="L459"></a><tt class="py-lineno">459</tt>  <tt class="py-line">    <tt class="py-docstring">"""</tt> </tt>
<a name="L460"></a><tt class="py-lineno">460</tt>  <tt class="py-line"><tt class="py-docstring">    GRNN is the implementation of General Regression Neural Network, a kind of</tt> </tt>
<a name="L461"></a><tt class="py-lineno">461</tt>  <tt class="py-line"><tt class="py-docstring">    probabilistic neural network used in regression tasks.</tt> </tt>
<a name="L462"></a><tt class="py-lineno">462</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="GRNN.__init__"></a><div id="GRNN.__init__-def"><a name="L463"></a><tt class="py-lineno">463</tt> <a class="py-toggle" href="#" id="GRNN.__init__-toggle" onclick="return toggle('GRNN.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.GRNN-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">sigma</tt><tt class="py-op">=</tt><tt class="py-number">0.1</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="GRNN.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="GRNN.__init__-expanded"><a name="L464"></a><tt class="py-lineno">464</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L465"></a><tt class="py-lineno">465</tt>  <tt class="py-line"><tt class="py-docstring">        Initializes the network.</tt> </tt>
<a name="L466"></a><tt class="py-lineno">466</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L467"></a><tt class="py-lineno">467</tt>  <tt class="py-line"><tt class="py-docstring">        Is not necessary to inform the training set size, GRNN will do it by </tt> </tt>
<a name="L468"></a><tt class="py-lineno">468</tt>  <tt class="py-line"><tt class="py-docstring">        itself in ``train`` method.</tt> </tt>
<a name="L469"></a><tt class="py-lineno">469</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L470"></a><tt class="py-lineno">470</tt>  <tt class="py-line"><tt class="py-docstring">        :Parameters:</tt> </tt>
<a name="L471"></a><tt class="py-lineno">471</tt>  <tt class="py-line"><tt class="py-docstring">          sigma</tt> </tt>
<a name="L472"></a><tt class="py-lineno">472</tt>  <tt class="py-line"><tt class="py-docstring">            A real number. This value determines the spread of probability </tt> </tt>
<a name="L473"></a><tt class="py-lineno">473</tt>  <tt class="py-line"><tt class="py-docstring">            density function (i.e is the smoothness parameter). A great value</tt> </tt>
<a name="L474"></a><tt class="py-lineno">474</tt>  <tt class="py-line"><tt class="py-docstring">            for sigma will result in a large spread gaussian and the sample</tt> </tt>
<a name="L475"></a><tt class="py-lineno">475</tt>  <tt class="py-line"><tt class="py-docstring">            points will cover a wide range of inputs, while a small value will</tt> </tt>
<a name="L476"></a><tt class="py-lineno">476</tt>  <tt class="py-line"><tt class="py-docstring">            create a limited spread gaussian and the sample points will cover a </tt> </tt>
<a name="L477"></a><tt class="py-lineno">477</tt>  <tt class="py-line"><tt class="py-docstring">            small range of inputs</tt> </tt>
<a name="L478"></a><tt class="py-lineno">478</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L479"></a><tt class="py-lineno">479</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_samples</tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt> </tt>
<a name="L480"></a><tt class="py-lineno">480</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_targets</tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt> </tt>
<a name="L481"></a><tt class="py-lineno">481</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sigma</tt> <tt class="py-op">=</tt> <tt class="py-name">sigma</tt> </tt>
</div><a name="L482"></a><tt class="py-lineno">482</tt>  <tt class="py-line"> </tt>
<a name="GRNN._kernel"></a><div id="GRNN._kernel-def"><a name="L483"></a><tt class="py-lineno">483</tt> <a class="py-toggle" href="#" id="GRNN._kernel-toggle" onclick="return toggle('GRNN._kernel');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.GRNN-class.html#_kernel">_kernel</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">x1</tt><tt class="py-op">,</tt> <tt class="py-param">x2</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="GRNN._kernel-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="GRNN._kernel-expanded"><a name="L484"></a><tt class="py-lineno">484</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L485"></a><tt class="py-lineno">485</tt>  <tt class="py-line"><tt class="py-docstring">        This method gives a measure of how well a training sample can represent</tt> </tt>
<a name="L486"></a><tt class="py-lineno">486</tt>  <tt class="py-line"><tt class="py-docstring">        the position of prediction (i.e. how well x1 can represent x2, or vice</tt> </tt>
<a name="L487"></a><tt class="py-lineno">487</tt>  <tt class="py-line"><tt class="py-docstring">        versa). If the distance D between x1 and x2 is small, result becomes </tt> </tt>
<a name="L488"></a><tt class="py-lineno">488</tt>  <tt class="py-line"><tt class="py-docstring">        big. For distance 0 (i.e. x1 == x2), result becomes one and the sample </tt> </tt>
<a name="L489"></a><tt class="py-lineno">489</tt>  <tt class="py-line"><tt class="py-docstring">        point is the best representation of prediction point. </tt> </tt>
<a name="L490"></a><tt class="py-lineno">490</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L491"></a><tt class="py-lineno">491</tt>  <tt class="py-line"><tt class="py-docstring">        In the probabilistic view, this method calculates the probability </tt> </tt>
<a name="L492"></a><tt class="py-lineno">492</tt>  <tt class="py-line"><tt class="py-docstring">        distribution.</tt> </tt>
<a name="L493"></a><tt class="py-lineno">493</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L494"></a><tt class="py-lineno">494</tt>  <tt class="py-line">        <tt class="py-name">D</tt> <tt class="py-op">=</tt> <tt class="py-name">x1</tt><tt class="py-op">-</tt><tt class="py-name">x2</tt> </tt>
<a name="L495"></a><tt class="py-lineno">495</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-73" class="py-name" targets="Variable peach.fuzzy.control.exp=peach.fuzzy.control-module.html#exp,Variable peach.nn.mem.exp=peach.nn.mem-module.html#exp,Variable peach.nn.nnet.exp=peach.nn.nnet-module.html#exp,Variable peach.nn.rbfn.exp=peach.nn.rbfn-module.html#exp"><a title="peach.fuzzy.control.exp
peach.nn.mem.exp
peach.nn.nnet.exp
peach.nn.rbfn.exp" class="py-name" href="#" onclick="return doclink('link-73', 'exp', 'link-73');">exp</a></tt><tt class="py-op">(</tt><tt class="py-op">-</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">D</tt><tt class="py-op">,</tt> <tt class="py-name">D</tt><tt class="py-op">)</tt><tt class="py-op">/</tt><tt class="py-op">(</tt><tt class="py-number">2</tt><tt class="py-op">*</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sigma</tt><tt class="py-op">**</tt><tt class="py-number">2</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L496"></a><tt class="py-lineno">496</tt>  <tt class="py-line"> </tt>
<a name="GRNN.train"></a><div id="GRNN.train-def"><a name="L497"></a><tt class="py-lineno">497</tt> <a class="py-toggle" href="#" id="GRNN.train-toggle" onclick="return toggle('GRNN.train');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.GRNN-class.html#train">train</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">sampleInputs</tt><tt class="py-op">,</tt> <tt class="py-param">targets</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="GRNN.train-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="GRNN.train-expanded"><a name="L498"></a><tt class="py-lineno">498</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L499"></a><tt class="py-lineno">499</tt>  <tt class="py-line"><tt class="py-docstring">        Presents a training set to the network.</tt> </tt>
<a name="L500"></a><tt class="py-lineno">500</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L501"></a><tt class="py-lineno">501</tt>  <tt class="py-line"><tt class="py-docstring">        This method uses the sample inputs to set the size of network. </tt> </tt>
<a name="L502"></a><tt class="py-lineno">502</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L503"></a><tt class="py-lineno">503</tt>  <tt class="py-line"><tt class="py-docstring">        :Parameters:</tt> </tt>
<a name="L504"></a><tt class="py-lineno">504</tt>  <tt class="py-line"><tt class="py-docstring">          sampleInputs</tt> </tt>
<a name="L505"></a><tt class="py-lineno">505</tt>  <tt class="py-line"><tt class="py-docstring">            Should be a list of numbers or a list of ``numpy.array`` to set the</tt> </tt>
<a name="L506"></a><tt class="py-lineno">506</tt>  <tt class="py-line"><tt class="py-docstring">            sample inputs. These inputs are used to calculate the distance </tt> </tt>
<a name="L507"></a><tt class="py-lineno">507</tt>  <tt class="py-line"><tt class="py-docstring">            between prediction points.</tt> </tt>
<a name="L508"></a><tt class="py-lineno">508</tt>  <tt class="py-line"><tt class="py-docstring">          targets</tt> </tt>
<a name="L509"></a><tt class="py-lineno">509</tt>  <tt class="py-line"><tt class="py-docstring">            The target values of sample inputs. Should be a list of numbers.</tt> </tt>
<a name="L510"></a><tt class="py-lineno">510</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L511"></a><tt class="py-lineno">511</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_samples</tt> <tt class="py-op">=</tt> <tt class="py-name">array</tt><tt class="py-op">(</tt><tt class="py-name">sampleInputs</tt><tt class="py-op">)</tt> </tt>
<a name="L512"></a><tt class="py-lineno">512</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_targets</tt> <tt class="py-op">=</tt> <tt class="py-name">array</tt><tt class="py-op">(</tt><tt class="py-name">targets</tt><tt class="py-op">)</tt> </tt>
</div><a name="L513"></a><tt class="py-lineno">513</tt>  <tt class="py-line"> </tt>
<a name="GRNN.__call__"></a><div id="GRNN.__call__-def"><a name="L514"></a><tt class="py-lineno">514</tt> <a class="py-toggle" href="#" id="GRNN.__call__-toggle" onclick="return toggle('GRNN.__call__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.GRNN-class.html#__call__">__call__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">x</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="GRNN.__call__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="GRNN.__call__-expanded"><a name="L515"></a><tt class="py-lineno">515</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L516"></a><tt class="py-lineno">516</tt>  <tt class="py-line"><tt class="py-docstring">        The method to predict a value from input ``x``.</tt> </tt>
<a name="L517"></a><tt class="py-lineno">517</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L518"></a><tt class="py-lineno">518</tt>  <tt class="py-line"><tt class="py-docstring">        :Parameters:</tt> </tt>
<a name="L519"></a><tt class="py-lineno">519</tt>  <tt class="py-line"><tt class="py-docstring">          x</tt> </tt>
<a name="L520"></a><tt class="py-lineno">520</tt>  <tt class="py-line"><tt class="py-docstring">            The input vector to the network.</tt> </tt>
<a name="L521"></a><tt class="py-lineno">521</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L522"></a><tt class="py-lineno">522</tt>  <tt class="py-line"><tt class="py-docstring">        :Returns:</tt> </tt>
<a name="L523"></a><tt class="py-lineno">523</tt>  <tt class="py-line"><tt class="py-docstring">          The predicted value.</tt> </tt>
<a name="L524"></a><tt class="py-lineno">524</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L525"></a><tt class="py-lineno">525</tt>  <tt class="py-line">        <tt class="py-name">values</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-74" class="py-name" targets="Method peach.nn.nnet.GRNN._kernel()=peach.nn.nnet.GRNN-class.html#_kernel,Method peach.nn.nnet.PNN._kernel()=peach.nn.nnet.PNN-class.html#_kernel"><a title="peach.nn.nnet.GRNN._kernel
peach.nn.nnet.PNN._kernel" class="py-name" href="#" onclick="return doclink('link-74', '_kernel', 'link-74');">_kernel</a></tt><tt class="py-op">(</tt><tt id="link-75" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-75', 'x', 'link-32');">x</a></tt><tt class="py-op">,</tt> <tt class="py-name">x2</tt><tt class="py-op">)</tt> <tt class="py-keyword">for</tt> <tt class="py-name">x2</tt> <tt class="py-keyword">in</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_samples</tt><tt class="py-op">]</tt> </tt>
<a name="L526"></a><tt class="py-lineno">526</tt>  <tt class="py-line">        <tt class="py-name">regular</tt> <tt class="py-op">=</tt> <tt class="py-name">sum</tt><tt class="py-op">(</tt><tt class="py-name">values</tt><tt class="py-op">)</tt> </tt>
<a name="L527"></a><tt class="py-lineno">527</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">values</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_targets</tt><tt class="py-op">)</tt><tt class="py-op">/</tt><tt class="py-name">regular</tt> </tt>
</div></div><a name="L528"></a><tt class="py-lineno">528</tt>  <tt class="py-line"> </tt>
<a name="L529"></a><tt class="py-lineno">529</tt>  <tt class="py-line"> </tt>
<a name="PNN"></a><div id="PNN-def"><a name="L530"></a><tt class="py-lineno">530</tt> <a class="py-toggle" href="#" id="PNN-toggle" onclick="return toggle('PNN');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="peach.nn.nnet.PNN-class.html">PNN</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="PNN-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="PNN-expanded"><a name="L531"></a><tt class="py-lineno">531</tt>  <tt class="py-line">    <tt class="py-docstring">"""</tt> </tt>
<a name="L532"></a><tt class="py-lineno">532</tt>  <tt class="py-line"><tt class="py-docstring">    PNN is the implementation of Probabilistic Neural Network, a network used</tt> </tt>
<a name="L533"></a><tt class="py-lineno">533</tt>  <tt class="py-line"><tt class="py-docstring">    for classification tasks</tt> </tt>
<a name="L534"></a><tt class="py-lineno">534</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="PNN.__init__"></a><div id="PNN.__init__-def"><a name="L535"></a><tt class="py-lineno">535</tt> <a class="py-toggle" href="#" id="PNN.__init__-toggle" onclick="return toggle('PNN.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.PNN-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">sigma</tt><tt class="py-op">=</tt><tt class="py-number">0.1</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="PNN.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="PNN.__init__-expanded"><a name="L536"></a><tt class="py-lineno">536</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L537"></a><tt class="py-lineno">537</tt>  <tt class="py-line"><tt class="py-docstring">        Initializes the network.</tt> </tt>
<a name="L538"></a><tt class="py-lineno">538</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L539"></a><tt class="py-lineno">539</tt>  <tt class="py-line"><tt class="py-docstring">        Is not necessary to inform the training set size, PNN will do it by </tt> </tt>
<a name="L540"></a><tt class="py-lineno">540</tt>  <tt class="py-line"><tt class="py-docstring">        itself in ``train`` method.</tt> </tt>
<a name="L541"></a><tt class="py-lineno">541</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L542"></a><tt class="py-lineno">542</tt>  <tt class="py-line"><tt class="py-docstring">        :Parameters:</tt> </tt>
<a name="L543"></a><tt class="py-lineno">543</tt>  <tt class="py-line"><tt class="py-docstring">          sigma</tt> </tt>
<a name="L544"></a><tt class="py-lineno">544</tt>  <tt class="py-line"><tt class="py-docstring">            A real number. This value determines the spread of probability </tt> </tt>
<a name="L545"></a><tt class="py-lineno">545</tt>  <tt class="py-line"><tt class="py-docstring">            density function (i.e is the smoothness parameter). A great value</tt> </tt>
<a name="L546"></a><tt class="py-lineno">546</tt>  <tt class="py-line"><tt class="py-docstring">            for sigma will result in a large spread gaussian and the sample</tt> </tt>
<a name="L547"></a><tt class="py-lineno">547</tt>  <tt class="py-line"><tt class="py-docstring">            points will cover a wide range of inputs, while a small value will</tt> </tt>
<a name="L548"></a><tt class="py-lineno">548</tt>  <tt class="py-line"><tt class="py-docstring">            create a limited spread gaussian and the sample points will cover a </tt> </tt>
<a name="L549"></a><tt class="py-lineno">549</tt>  <tt class="py-line"><tt class="py-docstring">            small range of inputs</tt> </tt>
<a name="L550"></a><tt class="py-lineno">550</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L551"></a><tt class="py-lineno">551</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sigma</tt> <tt class="py-op">=</tt> <tt class="py-name">sigma</tt> </tt>
<a name="L552"></a><tt class="py-lineno">552</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_categorys</tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt> </tt>
</div><a name="L553"></a><tt class="py-lineno">553</tt>  <tt class="py-line">     </tt>
<a name="PNN._kernel"></a><div id="PNN._kernel-def"><a name="L554"></a><tt class="py-lineno">554</tt> <a class="py-toggle" href="#" id="PNN._kernel-toggle" onclick="return toggle('PNN._kernel');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.PNN-class.html#_kernel">_kernel</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">x1</tt><tt class="py-op">,</tt> <tt class="py-param">x2</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="PNN._kernel-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="PNN._kernel-expanded"><a name="L555"></a><tt class="py-lineno">555</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L556"></a><tt class="py-lineno">556</tt>  <tt class="py-line"><tt class="py-docstring">        This method gives a measure of how well a training sample can represent</tt> </tt>
<a name="L557"></a><tt class="py-lineno">557</tt>  <tt class="py-line"><tt class="py-docstring">        the position of evaluation (i.e. how well x1 can represent x2, or vice</tt> </tt>
<a name="L558"></a><tt class="py-lineno">558</tt>  <tt class="py-line"><tt class="py-docstring">        versa). If the distance D between x1 and x2 is small, result becomes </tt> </tt>
<a name="L559"></a><tt class="py-lineno">559</tt>  <tt class="py-line"><tt class="py-docstring">        big. For distance 0 (i.e. x1 == x2), result becomes one and the sample </tt> </tt>
<a name="L560"></a><tt class="py-lineno">560</tt>  <tt class="py-line"><tt class="py-docstring">        point is the best representation of evaluation point. </tt> </tt>
<a name="L561"></a><tt class="py-lineno">561</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L562"></a><tt class="py-lineno">562</tt>  <tt class="py-line"><tt class="py-docstring">        In the probabilistic view, this method calculates the probability </tt> </tt>
<a name="L563"></a><tt class="py-lineno">563</tt>  <tt class="py-line"><tt class="py-docstring">        distribution.</tt> </tt>
<a name="L564"></a><tt class="py-lineno">564</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L565"></a><tt class="py-lineno">565</tt>  <tt class="py-line">        <tt class="py-name">D</tt> <tt class="py-op">=</tt> <tt class="py-name">x1</tt><tt class="py-op">-</tt><tt class="py-name">x2</tt> </tt>
<a name="L566"></a><tt class="py-lineno">566</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-76" class="py-name"><a title="peach.fuzzy.control.exp
peach.nn.mem.exp
peach.nn.nnet.exp
peach.nn.rbfn.exp" class="py-name" href="#" onclick="return doclink('link-76', 'exp', 'link-73');">exp</a></tt><tt class="py-op">(</tt><tt class="py-op">-</tt><tt class="py-name">dot</tt><tt class="py-op">(</tt><tt class="py-name">D</tt><tt class="py-op">,</tt> <tt class="py-name">D</tt><tt class="py-op">)</tt><tt class="py-op">/</tt><tt class="py-op">(</tt><tt class="py-number">2</tt><tt class="py-op">*</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sigma</tt><tt class="py-op">**</tt><tt class="py-number">2</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L567"></a><tt class="py-lineno">567</tt>  <tt class="py-line">     </tt>
<a name="PNN.train"></a><div id="PNN.train-def"><a name="L568"></a><tt class="py-lineno">568</tt> <a class="py-toggle" href="#" id="PNN.train-toggle" onclick="return toggle('PNN.train');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.PNN-class.html#train">train</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">trainSet</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="PNN.train-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="PNN.train-expanded"><a name="L569"></a><tt class="py-lineno">569</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L570"></a><tt class="py-lineno">570</tt>  <tt class="py-line"><tt class="py-docstring">        Presents a training set to the network.</tt> </tt>
<a name="L571"></a><tt class="py-lineno">571</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L572"></a><tt class="py-lineno">572</tt>  <tt class="py-line"><tt class="py-docstring">        This method uses the sample inputs to set the size of network. </tt> </tt>
<a name="L573"></a><tt class="py-lineno">573</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L574"></a><tt class="py-lineno">574</tt>  <tt class="py-line"><tt class="py-docstring">        :Parameters:</tt> </tt>
<a name="L575"></a><tt class="py-lineno">575</tt>  <tt class="py-line"><tt class="py-docstring">          train_set</tt> </tt>
<a name="L576"></a><tt class="py-lineno">576</tt>  <tt class="py-line"><tt class="py-docstring">            The training set is a list of examples. It can have any size. In </tt> </tt>
<a name="L577"></a><tt class="py-lineno">577</tt>  <tt class="py-line"><tt class="py-docstring">            fact, the definition of the training set is open. Each element of </tt> </tt>
<a name="L578"></a><tt class="py-lineno">578</tt>  <tt class="py-line"><tt class="py-docstring">            the training set, however, should be a two-tuple ``(x, d)``, where </tt> </tt>
<a name="L579"></a><tt class="py-lineno">579</tt>  <tt class="py-line"><tt class="py-docstring">            ``x`` is the input vector, and ``d`` is the desired response of the </tt> </tt>
<a name="L580"></a><tt class="py-lineno">580</tt>  <tt class="py-line"><tt class="py-docstring">            network for this particular input, i.e the category of ``x`` </tt> </tt>
<a name="L581"></a><tt class="py-lineno">581</tt>  <tt class="py-line"><tt class="py-docstring">            pattern. </tt> </tt>
<a name="L582"></a><tt class="py-lineno">582</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L583"></a><tt class="py-lineno">583</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_categorys</tt> <tt class="py-op">=</tt> <tt class="py-op">{</tt><tt class="py-op">}</tt> </tt>
<a name="L584"></a><tt class="py-lineno">584</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">pattern</tt><tt class="py-op">,</tt> <tt class="py-name">category</tt> <tt class="py-keyword">in</tt> <tt class="py-name">trainSet</tt><tt class="py-op">:</tt> </tt>
<a name="L585"></a><tt class="py-lineno">585</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">category</tt> <tt class="py-keyword">not</tt> <tt class="py-keyword">in</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_categorys</tt><tt class="py-op">:</tt> </tt>
<a name="L586"></a><tt class="py-lineno">586</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_categorys</tt><tt class="py-op">[</tt><tt class="py-name">category</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-op">]</tt> </tt>
<a name="L587"></a><tt class="py-lineno">587</tt>  <tt class="py-line"> </tt>
<a name="L588"></a><tt class="py-lineno">588</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_categorys</tt><tt class="py-op">[</tt><tt class="py-name">category</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt class="py-name">array</tt><tt class="py-op">(</tt><tt class="py-name">pattern</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L589"></a><tt class="py-lineno">589</tt>  <tt class="py-line"> </tt>
<a name="PNN.__call__"></a><div id="PNN.__call__-def"><a name="L590"></a><tt class="py-lineno">590</tt> <a class="py-toggle" href="#" id="PNN.__call__-toggle" onclick="return toggle('PNN.__call__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="peach.nn.nnet.PNN-class.html#__call__">__call__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">x</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="PNN.__call__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="PNN.__call__-expanded"><a name="L591"></a><tt class="py-lineno">591</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L592"></a><tt class="py-lineno">592</tt>  <tt class="py-line"><tt class="py-docstring">        The method to classify the input ``x`` into one of trained category.</tt> </tt>
<a name="L593"></a><tt class="py-lineno">593</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L594"></a><tt class="py-lineno">594</tt>  <tt class="py-line"><tt class="py-docstring">        :Parameters:</tt> </tt>
<a name="L595"></a><tt class="py-lineno">595</tt>  <tt class="py-line"><tt class="py-docstring">          x</tt> </tt>
<a name="L596"></a><tt class="py-lineno">596</tt>  <tt class="py-line"><tt class="py-docstring">            The input vector to the network.</tt> </tt>
<a name="L597"></a><tt class="py-lineno">597</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L598"></a><tt class="py-lineno">598</tt>  <tt class="py-line"><tt class="py-docstring">        :Returns:</tt> </tt>
<a name="L599"></a><tt class="py-lineno">599</tt>  <tt class="py-line"><tt class="py-docstring">          The category that best represent the input vector.</tt> </tt>
<a name="L600"></a><tt class="py-lineno">600</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L601"></a><tt class="py-lineno">601</tt>  <tt class="py-line">        <tt class="py-name">sums</tt> <tt class="py-op">=</tt> <tt class="py-op">{</tt><tt class="py-op">}</tt> </tt>
<a name="L602"></a><tt class="py-lineno">602</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">category</tt> <tt class="py-keyword">in</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_categorys</tt><tt class="py-op">:</tt> </tt>
<a name="L603"></a><tt class="py-lineno">603</tt>  <tt class="py-line">            <tt class="py-name">patterns</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_categorys</tt><tt class="py-op">[</tt><tt class="py-name">category</tt><tt class="py-op">]</tt> </tt>
<a name="L604"></a><tt class="py-lineno">604</tt>  <tt class="py-line">            <tt class="py-name">sums</tt><tt class="py-op">[</tt><tt class="py-name">category</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">sum</tt><tt class="py-op">(</tt><tt class="py-op">[</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-77" class="py-name"><a title="peach.nn.nnet.GRNN._kernel
peach.nn.nnet.PNN._kernel" class="py-name" href="#" onclick="return doclink('link-77', '_kernel', 'link-74');">_kernel</a></tt><tt class="py-op">(</tt><tt id="link-78" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-78', 'x', 'link-32');">x</a></tt><tt class="py-op">,</tt> <tt class="py-name">x2</tt><tt class="py-op">)</tt> <tt class="py-keyword">for</tt> <tt class="py-name">x2</tt> <tt class="py-keyword">in</tt> <tt class="py-name">patterns</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L605"></a><tt class="py-lineno">605</tt>  <tt class="py-line">            <tt class="py-name">sums</tt><tt class="py-op">[</tt><tt class="py-name">category</tt><tt class="py-op">]</tt> <tt class="py-op">/=</tt> <tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">patterns</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L606"></a><tt class="py-lineno">606</tt>  <tt class="py-line"> </tt>
<a name="L607"></a><tt class="py-lineno">607</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">sums</tt><tt class="py-op">,</tt> <tt class="py-name">key</tt><tt class="py-op">=</tt><tt class="py-keyword">lambda</tt> <tt id="link-79" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-79', 'x', 'link-32');">x</a></tt><tt class="py-op">:</tt><tt class="py-name">sums</tt><tt class="py-op">[</tt><tt id="link-80" class="py-name"><a title="peach.fuzzy.cmeans.FuzzyCMeans.x
peach.optm.linear.Direct1D.x
peach.optm.linear.GoldenRule.x
peach.optm.linear.Interpolation.x
peach.optm.multivar.Direct.x
peach.optm.multivar.Gradient.x
peach.optm.multivar.MomentumGradient.x
peach.optm.multivar.Newton.x
peach.optm.quasinewton.DFP.x
peach.optm.quasinewton.SR1.x
peach.sa.base.BinarySA.x
peach.sa.base.ContinuousSA.x" class="py-name" href="#" onclick="return doclink('link-80', 'x', 'link-32');">x</a></tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L608"></a><tt class="py-lineno">608</tt>  <tt class="py-line"> </tt>
<a name="L609"></a><tt class="py-lineno">609</tt>  <tt class="py-line"> </tt>
<a name="L610"></a><tt class="py-lineno">610</tt>  <tt class="py-line"><tt class="py-comment">################################################################################</tt> </tt>
<a name="L611"></a><tt class="py-lineno">611</tt>  <tt class="py-line"><tt class="py-comment"># Test</tt> </tt>
<a name="L612"></a><tt class="py-lineno">612</tt>  <tt class="py-line"><tt class="py-keyword">if</tt> <tt class="py-name">__name__</tt> <tt class="py-op">==</tt> <tt class="py-string">"__main__"</tt><tt class="py-op">:</tt> </tt>
<a name="L613"></a><tt class="py-lineno">613</tt>  <tt class="py-line">    <tt class="py-keyword">pass</tt> </tt>
<a name="L614"></a><tt class="py-lineno">614</tt>  <tt class="py-line"> </tt><script type="text/javascript">
<!--
expandto(location.href);
// -->
</script>
</pre>
<br />
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="peach-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Project homepage -->
      <th class="navbar" align="right" width="100%">
        <table border="0" cellpadding="0" cellspacing="0">
          <tr><th class="navbar" align="center"
            ><a href="http://code.google.com/p/peach">Peach - Computational Intelligence for Python</a></th>
          </tr></table></th>
  </tr>
</table>
<table border="0" cellpadding="0" cellspacing="0" width="100%%">
  <tr>
    <td align="left" class="footer">
    Generated by Epydoc 3.0.1 on Sun Jul 31 16:59:50 2011
    </td>
    <td align="right" class="footer">
      <a target="mainFrame" href="http://epydoc.sourceforge.net"
        >http://epydoc.sourceforge.net</a>
    </td>
  </tr>
</table>

<script type="text/javascript">
  <!--
  // Private objects are initially displayed (because if
  // javascript is turned off then we want them to be
  // visible); but by default, we want to hide them.  So hide
  // them unless we have a cookie that says to show them.
  checkCookie();
  // -->
</script>
</body>
</html>
